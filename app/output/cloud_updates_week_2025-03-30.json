[
  {
    "source": "Azure",
    "title": "Generally Availability: AzAcSnap 11 — Azure Application Consistent Snapshot Tool Updates",
    "date": "03/28/2025",
    "content": "Version 11 of the AzAcSnap tool is now generally available.Azure Application Consistent Snapshot Tool(AzAcSnap) is a command-line tool that enables customers to simplify data protection for third-party databases in Linux and Windows environments. AzAcSnap 11 introduces the following new capabilities and improvements:Features      moved to GA (generally available):Microsoft       SQL Server 2022 on Windows.Dependency      updates:Updated to .NET 8( List of supported operation systems.NET 8 -       Supported OS versions.)Azure       SDK updated to Track 2 (latest security and significant performance improvements).Fixes and      Improvements:(NEW)       Configurable Data Volume backup attemptsBackup       (-c backup) changes: Storage snapshot retention management is now performed after the database exits \"backup-mode\" to minimize the duration the database remains in a \"backup-enabled\" state.",
    "link": "https://azure.microsoft.com/updates?id=487178",
    "summary": "AzacsNAP 도구의 버전 11은 일반적으로 사용할 수 있습니다. AZURE APPLICATION APPLICATION SPINSHOT TOOL (AZACSNAP)은 고객이 Linux 및 Windows 환경의 타사 데이터베이스에 대한 데이터 보호를 단순화 할 수있는 명령 줄 도구입니다. Azacsnap 11은 다음의 새로운 기능 및 개선 사항을 소개합니다. 기능은 GA로 이동했습니다 (일반적으로 사용 가능) : Windows의 Microsoft SQL Server 2022. 백업) 변경 : 데이터베이스가 \"백업 가능\"상태로 유지되는 기간을 최소화하기 위해 데이터베이스가 \"백업 모드\"를 종료 한 후 스토리지 스냅 샷 유지 관리가 수행됩니다."
  },
  {
    "source": "Azure",
    "title": "Generally Available: Reminder - End of Limited Time Promotional Discounts on Azure Databricks Serverless Compute Services",
    "date": "03/27/2025",
    "content": "The limited time discount for Azure Databricks Automated and Interactive Serverless Compute will end on April 30, 2025. Serverless compute provides rapid workload startup, automatic infrastructure scaling, and seamless version upgrades of the Azure Databricks runtime.Learn more.",
    "link": "https://azure.microsoft.com/updates?id=485518",
    "summary": "Azure Databricks 자동 및 대화식 서버리스 컴퓨팅에 대한 제한된 시간 할인은 2025 년 4 월 30 일에 종료됩니다. Serverless Compute는 빠른 워크로드 시작, 자동 인프라 스케일링 및 Azure Databricks Runtime.Luyn의 완벽한 버전 업그레이드를 제공합니다."
  },
  {
    "source": "Azure",
    "title": "Generally Available: Log Analytics Delete Data API",
    "date": "03/26/2025",
    "content": "The Delete Data API lets you make asynchronous requests to remove data, such as sensitive, personal, or corrupt from your Log Analytics workspace. This API is more performant than Purge API since tagging logs as deleted, rather than performing heady delete operation. It's recommended to use this API for all non-GDPR data deletion.Learn more.",
    "link": "https://azure.microsoft.com/updates?id=479041",
    "summary": "데이터 삭제 API를 사용하면 Log Analytics Worksce에서 민감한, 개인 또는 손상과 같은 데이터를 제거하기위한 비동기적인 요청을 할 수 있습니다. 이 API는 Heady Delete 작업을 수행하는 대신 로그를 삭제 한 것으로 태깅하기 때문에 Purge API보다 성능이 뛰어납니다. 모든 비 GDPR 데이터 삭제 에이 API를 사용하는 것이 좋습니다."
  },
  {
    "source": "Azure",
    "title": "Generally Available: Azure Chaos Studio Auto-Tagging of Experiment Resources for Private Networking Now Available",
    "date": "03/26/2025",
    "content": "We’re excited to announce a new feature in Azure Chaos Studio that enhances resource management and compliance for customers using private networking in their experiments. Previously, while customers could apply tags to their experiments, the underlying container and gateway resources created as part of the experiment execution were not taggable, leading to potential conflicts with Azure Policy enforcement. With this update, Chaos Studio will now automatically tag the resources we create on your behalf with the same tags applied to your experiment. This ensures seamless policy compliance, improved resource tracking, and better integration with existing governance frameworks. This feature is available only for customers using private networking, as Chaos Studio does not deploy resources for experiments without private networking enabled.",
    "link": "https://azure.microsoft.com/updates?id=486388",
    "summary": "Azure Chaos Studio의 새로운 기능을 발표하여 실험에서 개인 네트워킹을 사용하여 고객을위한 리소스 관리 및 규정 준수를 향상시키는 것을 기쁘게 생각합니다. 이전에는 고객이 실험에 태그를 적용 할 수 있지만 실험 실행의 일부로 생성 된 기본 컨테이너 및 게이트웨이 리소스는 태그가되지 않았으므로 Azure 정책 집행과의 잠재적 충돌로 이어졌습니다. 이 업데이트를 통해 Chaos Studio는 이제 실험에 적용되는 동일한 태그로 귀하를 대신하여 작성한 리소스에 자동으로 태그를 지정합니다. 이를 통해 원활한 정책 준수, 개선 된 리소스 추적 및 기존 거버넌스 프레임 워크와의 더 나은 통합을 보장합니다. Chaos Studio는 개인 네트워킹을 활성화하지 않고 실험을위한 리소스를 배포하지 않기 때문에이 기능은 개인 네트워킹을 사용하는 고객에게만 사용할 수 있습니다."
  },
  {
    "source": "Azure",
    "title": "Generally Available: On-Demand Backups for Azure Database for PostgreSQL – Flexible Server",
    "date": "03/26/2025",
    "content": "Now you can create physical snapshots of Azure Database for PostgreSQL – Flexible Server based on your business needs. This new feature complements the scheduled automated backups offered by the service, while adding the flexibility to delete the on-demand backups. You can manage costs more effectively as you support your scheduled refresh activities.Learn more.",
    "link": "https://azure.microsoft.com/updates?id=485508",
    "summary": "이제 비즈니스 요구를 기반으로 Flexible Server에 대한 Azure 데이터베이스의 물리적 스냅 샷을 만들 수 있습니다. 이 새로운 기능은 서비스가 제공하는 예정된 자동 백업을 보완하는 동시에 주문형 백업을 삭제하는 유연성을 추가합니다. 예정된 새로 고침 활동을 지원할 때 비용을보다 효과적으로 관리 할 수 ​​있습니다."
  },
  {
    "source": "Azure",
    "title": "Generally Available: Long-Term Backup Retention for Azure Database for PostgreSQL – Flexible Server",
    "date": "03/26/2025",
    "content": "Azure Database for PostgreSQL - Flexible Server now offers a backup solution for supporting long-term backup retention and improved compliance for your PostgreSQL databases using Azure Backup. This release enables you to take advantage of a rich set of capabilities, such as flexible database backup policies, management of individual backups, and streamlined configuration. Additionally, you can add policies to back up and retain data for up to 10 years for compliance.Learn more",
    "link": "https://azure.microsoft.com/updates?id=485513",
    "summary": "PostgreSQL 용 Azure 데이터베이스 - Flexible Server는 이제 장기 백업 유지를 지원하고 Azure 백업을 사용하여 PostgreSQL 데이터베이스에 대한 개선 된 준수를위한 백업 솔루션을 제공합니다. 이 릴리스를 사용하면 Flexible Database 백업 정책, 개별 백업 관리 및 간소화 된 구성과 같은 풍부한 기능 세트를 활용할 수 있습니다. 또한 규정 준수를 위해 최대 10 년 동안 데이터를 백업하고 데이터를 유지하기 위해 정책을 추가 할 수 있습니다."
  },
  {
    "source": "Azure",
    "title": "Generally Available: Anthropic Gen AI Models in Azure Databricks",
    "date": "03/26/2025",
    "content": "We are thrilled to announce that as of March 26, 2025, Microsoft Azure customers can access and use Anthropic models within their existing Azure Databricks workspaces.This integration is a collaborative effort between Microsoft and Databricks, aimed at enhancing your data and AI capabilities.Learn more.",
    "link": "https://azure.microsoft.com/updates?id=486507",
    "summary": "2025 년 3 월 26 일 현재 Microsoft Azure 고객은 기존 Azure Databricks Workspaces 내에서 인류 모델에 액세스하고 사용할 수 있다는 사실을 발표하게되어 기쁩니다.이 통합은 Microsoft와 Databricks 간의 협력적인 노력으로 데이터 및 AI 기능을 향상시키는 것을 목표로합니다."
  },
  {
    "source": "Azure",
    "title": "Generally Available: Azure Firewall Updates - Parallel IP Group Updates",
    "date": "03/24/2025",
    "content": "Parallel IP Group support: Admins can now update multiple IP Groups in parallel or simultaneously with their firewall or firewall policies.Key benefits:Faster & scalable updates – Update up to 20 IP Groups simultaneously, up to twice as fast as before.Improved visibility - With enhanced error messaging, you can quickly identify and address issues during updates. Even if one IP Group fails to update, the remaining changes continue smoothly, keeping overall system health intact.Learn more.",
    "link": "https://azure.microsoft.com/updates?id=486031",
    "summary": "병렬 IP 그룹 지원 : 관리자는 이제 방화벽 또는 방화벽 정책과 함께 여러 IP 그룹을 병렬로 또는 동시에 업데이트 할 수 있습니다. 키 혜택 : 더 빠르고 확장 가능한 업데이트- 최대 20 개의 IP 그룹을 동시에 동시에 두 배까지 업데이트합니다. 하나의 IP 그룹이 업데이트되지 않더라도 나머지 변경 사항은 원활하게 계속되어 전체 시스템 건강을 그대로 유지합니다."
  },
  {
    "source": "Azure",
    "title": "Generally Available: New Regions for Azure Front Door Premium with Private Link Enabled Origins",
    "date": "03/24/2025",
    "content": "You can now set West US 2 and South East Asia as regions for Private Link-enabled origins in your Front Door Premium profile. Private Link-enabled origins in Front Door allow you to deliver content to your end-users through public Front Door endpoints while ensuring that your origins remain inaccessible to the public internet.Learn more.",
    "link": "https://azure.microsoft.com/updates?id=479735",
    "summary": "이제 West US 2와 동남아시아를 정문 프리미엄 프로파일에서 개인 링크 지원 기원의 지역으로 설정할 수 있습니다. 전면 도어의 개인 링크 지원 기원을 사용하면 공개 정문 엔드 포인트를 통해 최종 사용자에게 컨텐츠를 전달할 수있게되면서 기원이 공개 인터넷에 접근 할 수 없도록합니다."
  },
  {
    "source": "GCP",
    "title": "Cloud Run (Feature)",
    "date": "2025-03-28",
    "content": "The ability to disable the Invoker IAM check for Cloud Run services is now at general availability (GA).",
    "link": "https://cloud.google.com/release-notes",
    "summary": "클라우드 실행 서비스에 대한 Invoker IAM Check를 비활성화하는 기능은 이제 GA (General Availability)에 있습니다."
  },
  {
    "source": "GCP",
    "title": "Dataproc (Announcement)",
    "date": "2025-03-28",
    "content": "New Dataproc Serverless for Spark runtime versions : 1.1.96 1.2.40 2.2.40 Changed Dataproc Serverless for Spark: All Dataproc serverless for spark runtimes now support hadoop native libraries by default.",
    "link": "https://cloud.google.com/release-notes",
    "summary": "스파크 런타임 버전에 대한 새로운 DatapRoc 서버리스 : 1.1.96 1.2.40 2.2.40 Spark 용 DatapRoc 서버리스 변경 : Spark Runtimes 용 모든 DatapRoc 서버리스는 이제 기본적으로 Hadoop 기본 라이브러리를 지원합니다."
  },
  {
    "source": "GCP",
    "title": "Filestore (Feature)",
    "date": "2025-03-28",
    "content": "Instance replication is now generally available ( GA ).",
    "link": "https://cloud.google.com/release-notes",
    "summary": "인스턴스 복제는 일반적으로 사용할 수 있습니다 (GA)."
  },
  {
    "source": "GCP",
    "title": "Gemini Code Assist (Feature)",
    "date": "2025-03-28",
    "content": "Local codebase awareness is now available for IntelliJ Gemini Code Assist. You can now include files from your local IDE project in the prompt context by typing @ in the chat prompt box. Feature You can now see what files are used by IntelliJ Gemini Code Assist chat and can customize the context as needed.",
    "link": "https://cloud.google.com/release-notes",
    "summary": "로컬 코드베이스 인식은 이제 Intellij Gemini Code Assist에서 사용할 수 있습니다. 이제 채팅 프롬프트 박스 기능에 @를 입력하여 Prompt Context에 로컬 IDE 프로젝트의 파일을 포함시킬 수 있습니다."
  },
  {
    "source": "GCP",
    "title": "Google Distributed Cloud (software only) for VMware (Announcement)",
    "date": "2025-03-28",
    "content": "Google Distributed Cloud (software only) for VMware 1.29.1200-gke.99 is now available for download . To upgrade, see Upgrade a cluster or a node pool . Google Distributed Cloud 1.29.1200-gke.99 runs on Kubernetes v1.29.13-gke.500. This is the final patch for the 1.29 minor release. If you are using a third-party storage vendor, check the GDC Ready storage partners document to make sure the storage vendor has already passed the qualification for this release. After a release, it takes approximately 7 to 14 days for the version to become available for use with GKE On-Prem API clients : the Google Cloud console, the gcloud CLI, and Terraform. Fixed The 1.29.1200-gke.99 release includes many vulnerability fixes. For a list of all vulnerabilities fixed in this release, see Vulnerability fixes .",
    "link": "https://cloud.google.com/release-notes",
    "summary": "VMware 1.29.1200-Gke.99 용 Google 분산 클라우드 (소프트웨어 전용) 99 번 다운로드 Google 분산 클라우드 1.29.1200-GKE.99 KUBERNETES V1.29.13-GKE.500 1.29 마이너 릴리스의 최종 패치입니다."
  },
  {
    "source": "GCP",
    "title": "Google Distributed Cloud (software only) for bare metal (Announcement)",
    "date": "2025-03-28",
    "content": "Release 1.29.1200-gke.98 Google Distributed Cloud for bare metal 1.29.1200-gke.98 is now available for download . To upgrade, see Upgrade clusters . Google Distributed Cloud for bare metal 1.29.1200-gke.98 runs on Kubernetes v1.29.13-gke.500. This is the final patch for the 1.29 minor release. After a release, it takes approximately 7 to 14 days for the version to become available for installations or upgrades with the GKE On-Prem API clients : the Google Cloud console, the gcloud CLI, and Terraform. If you use a third-party storage vendor, check the Ready storage partners document to make sure the storage vendor has already passed the qualification for this release of Google Distributed Cloud for bare metal. Changed Updated the cluster upgrade operation to keep only the three latest kubeadm backups of etcd and configuration information for a node. Previously, kubeadm kept node backups for every attempted upgrade. Fixed Fixed an issue that caused cluster creation to fail because kubelet restarted before required static pods are running. Fixed The 1.29.1200-gke.98 release includes many vulnerability fixes. For a list of all vulnerabilities fixed in this release, see Vulnerability fixes . Issue For information about the latest known issues, see Google Distributed Cloud for bare metal known issues in the Troubleshooting section.",
    "link": "https://cloud.google.com/release-notes",
    "summary": "릴리스 1.29.1200-GKE.98 베어 메탈 1.29.1200-GKE.98에 대한 Google 분산 클라우드는 이제 다운로드 할 수 있습니다. Google 분산 클라우드는 Bare Metal 1.29.1200-GKE.98 KUBERNETES v1.29.13-GKE에서 실행됩니다."
  },
  {
    "source": "GCP",
    "title": "Google Kubernetes Engine (Feature)",
    "date": "2025-03-28",
    "content": "In version 1.32.1-gke.1729000 and later, you can customize specific kubelet and Linux kernel parameters like sysctls and huge pages by using the nodeSystemConfig field in your GKE compute classes. Additionally, you can now specify default values for fields that are omitted in individual rules in a compute class by using the priorityDefaults field. For details, see About custom compute classes .",
    "link": "https://cloud.google.com/release-notes",
    "summary": "버전 1.32.1-gke.1729000 이상에서는 GKE Compute에서 NodesystemConfig 필드를 추가로 사용하여 SYSCTL 및 거대한 페이지와 같은 특정 큐렛 및 Linux 커널 매개 변수를 사용자 정의 할 수 있습니다."
  },
  {
    "source": "GCP",
    "title": "Spanner (Feature)",
    "date": "2025-03-28",
    "content": "Spanner vector index and approximate nearest neighbor (ANN) distance functions in the GoogleSQL-dialect are Generally Available. If you have a table with a large amount of vector data, you can use a vector index to accelerate similarity searches and nearest neighbor queries. Spanner now also supports the following: ALTER VECTOR INDEX DDL syntax Import and export databases that use ANN Use the STORING clause to store a copy of a column in the vector index to accelerate queries that filter by those columns Use ANN in instances smaller than one node or 1000 processing units For more information, see Find approximate nearest neighbors, create vector indexes, and query vector embeddings . Feature Spanner ANN indexes are now supported in Langchain. For more information, see LangChain Quickstart for Spanner .",
    "link": "https://cloud.google.com/release-notes",
    "summary": "스패너 벡터 인덱스 및 대략적인 가장 가까운 이웃 (ANN) 거리의 대략적인 googlesql-dialect의 대략적인 벡터 데이터가있는 테이블이있는 경우 일반적으로 사용할 수 있습니다. 벡터 인덱스를 사용하여 유사성 검색 및 가장 가까운 이웃 Queries Spanner를 가속화 할 수 있습니다. 이제 Alter Vector Index Ddl Syntax Import를 지원하고 ANN을 사용하여 ANN을 사용하여 CLASE를 사용하여 CORCING A AMPOUS를 사용하여 ANN을 사용합니다. 해당 열에서 필터링하는 쿼리 더 많은 정보는 하나의 노드 또는 1000 개의 처리 장치보다 작은 인스턴스에서 ANN을 사용하고 가장 가까운 이웃을 찾기, 벡터 인덱스 생성 및 쿼리 벡터 임베딩을 참조하십시오."
  },
  {
    "source": "GCP",
    "title": "Workflows (Feature)",
    "date": "2025-03-28",
    "content": "Support for a Kubernetes API connector is generally available ( GA ). The connector allows you to interact with Kubernetes objects in a Google Kubernetes Engine cluster. For more information, see Access Kubernetes API objects using a connector .",
    "link": "https://cloud.google.com/release-notes",
    "summary": "Kubernetes API 커넥터에 대한 지원은 일반적으로 사용할 수 있습니다 (GA) 커넥터를 사용하면 Google Kubernetes 엔진 클러스터에서 Kubernetes 객체와 상호 작용할 수 있습니다. 자세한 내용은 커넥터를 사용하는 Access Kubernetes API 객체를 참조하십시오."
  },
  {
    "source": "GCP",
    "title": "Apigee X (Announcement)",
    "date": "2025-03-27",
    "content": "On March 27, 2025, we released an updated version of Apigee. Feature Availability of client IP resolution functionality with Apigee hybrid. Client IP resolution functonality is now available with Apigee hybrid versions 1.14.0 and later. See Client IP resolution for information. Changed On March 26, 2025, we released an updated version of Apigee (1-14-0-apigee-5). This Apigee version applies only to organizations using the JavaCallout policy in production environments. Note: Rollouts of this release to production instances will begin within two business days and may take four or more business days to complete across all Google Cloud zones. Your instances may not have the features and fixes available until the rollout is complete. Fixed Bug ID Description N/A Updates to security infrastructure and libraries.",
    "link": "https://cloud.google.com/release-notes",
    "summary": "2025 년 3 월 27 일, Apigee Hybrid Client IP 해상도 기능을 사용하여 클라이언트 IP 해상도 기능의 업데이트 된 Apigee 기능 가용성을 발표했습니다. 이제 Apigee Hybrid 버전 1.14.0 이상에서 사용할 수 있습니다."
  },
  {
    "source": "GCP",
    "title": "Apigee hybrid (Announcement)",
    "date": "2025-03-27",
    "content": "On March 27, 2025, we released an updated version of Apigee. Feature Availability of client IP resolution functionality with Apigee hybrid. Client IP resolution functonality is now available with Apigee hybrid versions 1.14.0 and later. See Client IP resolution for information.",
    "link": "https://cloud.google.com/release-notes",
    "summary": "2025 년 3 월 27 일, Apigee Hybrid Client IP 해상도 기능을 사용하여 클라이언트 IP 해상도 기능의 업데이트 된 Apigee 기능 가용성을 발표했습니다. 이제 Apigee Hybrid 버전 1.14.0 이상에서 사용할 수 있습니다."
  },
  {
    "source": "GCP",
    "title": "BigQuery (Feature)",
    "date": "2025-03-27",
    "content": "You can now enable metadata caching for SQL translation , which can significantly reduce latency for subsequent translation requests. This feature is in preview . Cloud Build Changed In the filtering toolbar of the Build history page, you can now filter builds by region. The region drop-down has been removed. For more information, see View build results .",
    "link": "https://cloud.google.com/release-notes",
    "summary": "이제 SQL 번역에 대한 메타 데이터 캐싱을 활성화 할 수 있습니다. 이는 후속 번역 요청에 대한 대기 시간을 크게 줄일 수 있습니다. 클라우드 빌드 빌드 히스토리 페이지의 필터링 도구 모음에서 변경되었습니다. 이제 지역별로 빌드를 필터링 할 수 있습니다."
  },
  {
    "source": "GCP",
    "title": "Cloud Service Mesh (Announcement)",
    "date": "2025-03-27",
    "content": "1.24.3-asm.6 is now available for in-cluster Cloud Service Mesh. You can now download 1.24.3-asm.6 for in-cluster Cloud Service Mesh. It includes the features of Istio 1.24.3 subject to the list of supported features . Cloud Service Mesh version 1.24.3-asm.6 uses envoy v1.32.4-dev. For details on upgrading Cloud Service Mesh, see Upgrade Cloud Service Mesh . Announcement 1.23.5-asm.3 is now available for in-cluster Cloud Service Mesh. You can now download 1.23.5-asm.3 for in-cluster Cloud Service Mesh. It includes the features of Istio 1.23.5 subject to the list of supported features . Cloud Service Mesh version 1.23.5-asm.3 uses envoy v1.31.6-dev. For details on upgrading Cloud Service Mesh, see Upgrade Cloud Service Mesh . Announcement 1.22.8-asm.5 is now available for in-cluster Cloud Service Mesh. You can now download 1.22.8-asm.5 for in-cluster Cloud Service Mesh. It includes the features of Istio 1.22.8 subject to the list of supported features . Cloud Service Mesh version 1.22.8-asm.5 uses envoy v1.30.10-dev. For details on upgrading Cloud Service Mesh, see Upgrade Cloud Service Mesh . Announcement 1.21.5-asm.34 is now available for in-cluster Cloud Service Mesh. You can now download 1.21.5-asm.34 for in-cluster Cloud Service Mesh. It includes the features of Istio 1.21.5 subject to the list of supported features . Cloud Service Mesh version 1.21.5-asm.34 uses envoy v1.29.12-dev. For details on upgrading Cloud Service Mesh, see Upgrade Cloud Service Mesh .",
    "link": "https://cloud.google.com/release-notes",
    "summary": "1.24.3-ASM.6 이제 클러스터 내 클라우드 서비스 메쉬에 사용할 수 있습니다. 이제 클러스터 내 클라우드 서비스 메시의 경우 1.24.3-ASM을 다운로드 할 수 있습니다. 지원되는 기능 목록에 따라 ISTIO 1.24.3의 기능이 포함되어 있습니다."
  },
  {
    "source": "GCP",
    "title": "Cloud Workstations (Feature)",
    "date": "2025-03-27",
    "content": "Cloud Workstations is available in the me-central2 region (Dammam, Saudi Arabia, Middle East). For more information, see Locations . Google SecOps Changed Google SecOps is renaming Applied Threat Intelligence (ATI) rules to improve clarity and better reflect the associated UDM fields with each rule detection. Currently, multiple underlying ATI rules can appear with the same name in the Google SecOps console, even though the rules apply to different UDF fields. This change modifies the rule_name field in the customer metadata to specify the relevant UDM field for each rule. For example: Old rule name: ATI Active Breach Rule Match for File IoCs (SHA256) New rule name: ATI Active Breach Rule Match for File IoCs (about.file.sha256) If your integrations depend on current rule names (for example, parsing the rule_name field in API responses or SOAR playbooks), must update them accordingly. Google SecOps SIEM Changed Google SecOps is renaming Applied Threat Intelligence (ATI) rules to improve clarity and better reflect the associated UDM fields with each rule detection. Currently, multiple underlying ATI rules can appear with the same name in the Google SecOps console, even though the rules apply to different UDF fields. This change modifies the rule_name field in the customer metadata to specify the relevant UDM field for each rule. For example: Old rule name: ATI Active Breach Rule Match for File IoCs (SHA256) New rule name: ATI Active Breach Rule Match for File IoCs (about.file.sha256) If your integrations depend on current rule names (for example, parsing the rule_name field in API responses or SOAR playbooks), must update them accordingly. Network Connectivity Center Changed Site-to-site data transfer locations in the following countries have been added to Network Connectivity Center:",
    "link": "https://cloud.google.com/release-notes",
    "summary": "클라우드 워크 스테이션은 ME-Central2 지역 (Dammam, Saudi Arabia, Middle)에서 사용할 수 있습니다. Google Secops 변경 Google Secops는 ATI (Applied Threat Intelligence) 규칙을 변경하여 명확성을 향상시키고 각 규칙이 현재 각 규칙에 따라 동일한 이름으로 나타날 수 있습니다."
  },
  {
    "source": "GCP",
    "title": "Belgium Canada Chile Finland Israel Mexico Sweden Spanner (Feature)",
    "date": "2025-03-27",
    "content": "You can save and manage your SQL scripts in Spanner Studio. This feature is in preview . For more information, see Saved queries overview .",
    "link": "https://cloud.google.com/release-notes",
    "summary": "자세한 내용은 Spanner Studio에서 SQL 스크립트를 저장하고 관리 할 수 ​​있습니다. 저장된 쿼리 개요를 참조하십시오."
  },
  {
    "source": "GCP",
    "title": "API Gateway (Announcement)",
    "date": "2025-03-26",
    "content": "On March 26, 2025, we released an updated version of API Gateway. Feature With this release, customer data in API Gateway is now CMEK-compliant at rest. No configuration is required. For more information, see CMEK compliance in API Gateway . To  about CMEK, see Customer-managed encryption keys (CMEK) .",
    "link": "https://cloud.google.com/release-notes",
    "summary": "2025 년 3 월 26 일, 우리는이 릴리스와 함께 업데이트 된 API 게이트웨이 기능을 발표했으며, API 게이트웨이의 고객 데이터는 이제 CMEK 호환에 따라 API 게이트웨이의 CMEK 준수를 참조하십시오."
  },
  {
    "source": "GCP",
    "title": "BigQuery (Feature)",
    "date": "2025-03-26",
    "content": "You can now set the column granularity when you create a search index , which stores additional column information in your search index to further optimize your search query performance. This feature is in preview . Bigtable Changed The Monitoring page in the Google Cloud console for Bigtable has been renamed to System insights.",
    "link": "https://cloud.google.com/release-notes",
    "summary": "검색 인덱스를 만들 때 열 입상을 설정할 수 있습니다. 검색 인덱스에 추가 열 정보를 저장하여 검색 쿼리 성능을 추가로 최적화하기 위해 BigTable의 Google Cloud 콘솔에서 모니터링 페이지를 System Insights로 변경했습니다."
  },
  {
    "source": "GCP",
    "title": "Cloud Composer (Announcement)",
    "date": "2025-03-26",
    "content": "A new Cloud Composer release has started on March 26, 2025 . Get ready for upcoming changes and features as we roll out the new release to all regions. This release is in progress at the moment. Listed changes and features might not be available in some regions yet. Announcement All Cloud Composer environment's GKE clusters are set up with maintenance exclusions from March 27, 2025 to April 04, 2025. For more information, see Maintenance exclusions. Feature Data lineage in Cloud Composer now uses OpenLineage . Data lineage support for a specific Airflow operator is now provided by the provider package where the operator is located. See Supported classes in the apache-airflow-providers-openlineage documentation for a list of latest supported operators. For more information about data lineage in Cloud Composer, see Data lineage with Dataplex . This feature is gradually rolled out. It will be available in us-west1, us-south1, europe-north1, me-west1, asia-northeast2, asia-southeast2, and africa-south1 regions. We plan to provide this feature in other regions in future releases. Fixed (Available without upgrading) Fixed an issue with updating maintenance windows when there is an upcoming Cloud Composer 3 infrastructure operation. Breaking (Airflow 2.10.2 and 2.9.3) The apache-airflow-providers-google package was upgraded to version 14.0.0 in Cloud Composer 2 images and Cloud Composer 3 builds. This package is a new major version where many previously deprecated Airflow operators are removed . It is not possible to use these operators in your DAGs. Make sure that you update your DAGs to use up-to-date alternatives of the removed operators. For more information about removed and deprecated Airflow operators and their up-to-date alternatives, see Deprecated and removed Airflow operators . For more information about changes, see the apache-airflow-providers-google changelog from version 10.26.0 to version 14.0.0. Changed (Airflow 2.10.2 and 2.9.3) The apache-airflow-providers-cncf-kubernetes package was upgraded to version 10.3.0 in Cloud Composer 2 images and Cloud Composer 3 builds. For more information about changes, see the apache-airflow-providers-cncf-kubernetes changelog from version 10.1.0 to version 10.3.0. Changed (Airflow 2.10.2 and 2.9.3) Changes in preinstalled packages: apache-airflow-providers-postgres was upgraded to 6.1.0 from 5.14.0. apache-airflow-providers-smtp was upgraded to 2.0.0 from 1.9.0. types-requests was removed from preinstalled packages. Changed New Airflow builds are available in Cloud Composer 3: composer-3-airflow-2.10.2-build.12 (default) composer-3-airflow-2.9.3-build.19 Changed New images are available in Cloud Composer 2: composer-2.12.0-airflow-2.10.2 (default) composer-2.12.0-airflow-2.9.3 Deprecated Cloud Composer versions 2.6.4, 2.6.5, and 2.6.6 have reached their end of support period . Cloud Deploy Changed Cloud Deploy is now available in the following regions: northamerica-south1 (Mexico) europe-north2 (Stockholm) Cloud Run Changed Cloud Run services configured with Direct VPC egress now use only 2 times (2X) as many IP addresses as the number of instances for the duration of the instance plus up to 20 minutes, reduced from 4X as many IP addresses.",
    "link": "https://cloud.google.com/release-notes",
    "summary": "2025 년 3 월 26 일에 새로운 클라우드 작곡가 릴리스가 시작되었습니다. 모든 지역에서 새로운 릴리스를 출시 할 때 다가오는 변경 사항과 기능을 준비하십시오. 아직 일부 지역에서는 사용할 수 없습니다."
  },
  {
    "source": "GCP",
    "title": "Compute Engine (Feature)",
    "date": "2025-03-26",
    "content": "Generally available : You can use instant snapshots to take in-place backups of the following types of disks: Hyperdisk Balanced Hyperdisk Balanced High Availability Hyperdisk Extreme Instant snapshots are ideal for rapid data restoration only within the same location as the source disk. You can use an instant snapshot to create a new disk in under a minute. For more information, see About instant snapshots . Feature Generally available : You can specify a custom ephemeral internal IPv6 address when creating an instance. For more information, see Create instances that use IPv6 addresses . Feature Generally available : Asynchronous Replication is now generally available for Hyperdisk Balanced, Hyperdisk Balanced High Availability, and Hyperdisk Extreme disks. Asynchronous Replication provides low-RPO and low-RTO block storage replication for cross-region disaster recovery. For more information, see About Asynchronous Replication . Google Kubernetes Engine Changed (2025-R12) Version updates GKE cluster versions have been updated. New versions available for upgrades and new clusters. The following Kubernetes versions are now available for new clusters and for opt-in control plane upgrades and node upgrades for existing clusters. For more information on versioning and upgrades, see GKE versioning and support and Upgrades . Rapid channel Note: Your clusters might not have these versions available. Rollouts are already in progress when we publish the release notes, and can take multiple days to complete across all Google Cloud zones. The following versions are now available in the Rapid channel: 1.29.15-gke.1058000 1.30.10-gke.1227001 1.30.11-gke.1008001 1.31.6-gke.1221001 1.31.7-gke.1013001 1.32.2-gke.1652003 1.32.3-gke.1057001 Regular channel There are no new releases in the Regular channel. Stable channel Note: Your clusters might not have these versions available. Rollouts are already in progress when we publish the release notes, and can take multiple days to complete across all Google Cloud zones. The following versions are now available in the Stable channel: 1.30.10-gke.1070000 1.31.6-gke.1064000 1.32.2-gke.1182001 Extended channel Note: Your clusters might not have these versions available. Rollouts are already in progress when we publish the release notes, and can take multiple days to complete across all Google Cloud zones. The following versions are now available in the Extended channel: 1.27.16-gke.2595000 1.28.15-gke.2027000 No channel Note: Your clusters might not have these versions available. Rollouts are already in progress when we publish the release notes, and can take multiple days to complete across all Google Cloud zones. The following versions are now available: 1.29.15-gke.1058000 1.30.10-gke.1227001 1.30.11-gke.1008001 1.31.6-gke.1221001 1.31.7-gke.1013001 1.32.2-gke.1652003 1.32.3-gke.1057001 The following node versions are now available: 1.27.16-gke.2595000 1.28.15-gke.2027000 1.29.15-gke.1058000 1.30.10-gke.1227001 1.30.11-gke.1008001 1.31.6-gke.1221001 1.31.7-gke.1013001 1.32.2-gke.1652003 1.32.3-gke.1057001 Changed (2025-R12) Version updates Note: Your clusters might not have these versions available. Rollouts are already in progress when we publish the release notes, and can take multiple days to complete across all Google Cloud zones. The following versions are now available in the Rapid channel: 1.29.15-gke.1058000 1.30.10-gke.1227001 1.30.11-gke.1008001 1.31.6-gke.1221001 1.31.7-gke.1013001 1.32.2-gke.1652003 1.32.3-gke.1057001 Changed (2025-R12) Version updates There are no new releases in the Regular channel. Changed (2025-R12) Version updates Note: Your clusters might not have these versions available. Rollouts are already in progress when we publish the release notes, and can take multiple days to complete across all Google Cloud zones. The following versions are now available in the Stable channel: 1.30.10-gke.1070000 1.31.6-gke.1064000 1.32.2-gke.1182001 Changed (2025-R12) Version updates Note: Your clusters might not have these versions available. Rollouts are already in progress when we publish the release notes, and can take multiple days to complete across all Google Cloud zones. The following versions are now available in the Extended channel: 1.27.16-gke.2595000 1.28.15-gke.2027000 Changed (2025-R12) Version updates Note: Your clusters might not have these versions available. Rollouts are already in progress when we publish the release notes, and can take multiple days to complete across all Google Cloud zones. The following versions are now available: 1.29.15-gke.1058000 1.30.10-gke.1227001 1.30.11-gke.1008001 1.31.6-gke.1221001 1.31.7-gke.1013001 1.32.2-gke.1652003 1.32.3-gke.1057001 The following node versions are now available: 1.27.16-gke.2595000 1.28.15-gke.2027000 1.29.15-gke.1058000 1.30.10-gke.1227001 1.30.11-gke.1008001 1.31.6-gke.1221001 1.31.7-gke.1013001 1.32.2-gke.1652003 1.32.3-gke.1057001",
    "link": "https://cloud.google.com/release-notes",
    "summary": "일반적으로 사용 가능한 디스크 유형의 인스턴트 스냅 샷을 사용하여 다음 유형의 디스크를 가져갈 수 있습니다. 하이퍼 디스크 균형 잡힌 하이퍼 디스크 균형 고 가용성 고 가용성 고 가용성 고대 하이퍼 디스크 인스턴트 스냅 샷은 소스 디스크와 동일한 위치 내에서만 빠른 데이터 복원에만 이상적입니다."
  },
  {
    "source": "GCP",
    "title": "Google SecOps (Announcement)",
    "date": "2025-03-26",
    "content": "The managed BigQuery resources and API keys associated with the chronicle-tla Google Cloud project will be fully deprecated by April 30, 2025. This applies to non-Enterprise+ customers only.",
    "link": "https://cloud.google.com/release-notes",
    "summary": "Chronicle-TLA Google Cloud Project와 관련된 관리 된 BigQuery 리소스 및 API 키는 2025 년 4 월 30 일까지 완전히 더 이상 사용되지 않습니다."
  },
  {
    "source": "GCP",
    "title": "Google SecOps SIEM (Announcement)",
    "date": "2025-03-26",
    "content": "The managed BigQuery resources and API keys associated with the chronicle-tla Google Cloud project will be fully deprecated by April 30, 2025. This applies to non-Enterprise+ customers only.",
    "link": "https://cloud.google.com/release-notes",
    "summary": "Chronicle-TLA Google Cloud Project와 관련된 관리 된 BigQuery 리소스 및 API 키는 2025 년 4 월 30 일까지 완전히 더 이상 사용되지 않습니다."
  },
  {
    "source": "GCP",
    "title": "Resource Manager (Feature)",
    "date": "2025-03-26",
    "content": "Custom organization policies are now available in Preview for Cloud Resource Manager. For more information, see Manage resources with custom constraints .",
    "link": "https://cloud.google.com/release-notes",
    "summary": "클라우드 리소스 관리자의 미리보기에서 사용자 정의 조직 정책을 사용할 수 있습니다. 자세한 내용은 사용자 정의 제약 조건으로 리소스 관리를 참조하십시오."
  },
  {
    "source": "GCP",
    "title": "Vertex AI (Feature)",
    "date": "2025-03-26",
    "content": "Generally available : You can consume reservations of VMs that have GPUs attached with your custom training jobs or prediction jobs. Reservations of Compute Engine zonal resources help you gain a high level of assurance that your jobs have the necessary resources to run. For more information, see the following:",
    "link": "https://cloud.google.com/release-notes",
    "summary": "일반적으로 사용 가능 : 사용자 정의 교육 작업 또는 예측 작업에 GPU가 첨부 된 VM의 예약을 소비 할 수 있습니다. 엔진 리소스 컴퓨팅 예약 구역 자원 예약은 귀하의 작업이 실행하는 데 필요한 자원이 있다는 높은 수준의 보증을 얻는 데 도움이됩니다."
  },
  {
    "source": "GCP",
    "title": "Use reservations with training Use reservations with prediction Vertex AI Workbench (Feature)",
    "date": "2025-03-26",
    "content": "The ability to back up and restore data on a Vertex AI Workbench instance is now generally available . For more information, see Back up and restore data on an instance .",
    "link": "https://cloud.google.com/release-notes",
    "summary": "Vertex AI Workbench 인스턴스에서 데이터를 백업하고 복원하는 기능은 일반적으로 자세한 내용을 위해 사용할 수 있습니다. 인스턴스의 백업 및 복원을 참조하십시오."
  },
  {
    "source": "GCP",
    "title": "Virtual Private Cloud (Feature)",
    "date": "2025-03-26",
    "content": "Support for the following is available in General availability for dual-stack configurations: IPv6 static routes with a next hop internal passthrough Network Load Balancer ( next-hop-ilb ) IPv6 static routes with a next hop instance identified by address ( next-hop-address ) For more information, see Next hops and features in the static routes overview.",
    "link": "https://cloud.google.com/release-notes",
    "summary": "다음에 대한 지원은 듀얼 스택 구성에 대한 일반적인 가용성에서 사용할 수 있습니다. 다음 홉 내부 패스 스루 네트워크로드 밸런서 (Next-Hop-ILB) IPv6 정적 경로가있는 IPv6 정적 경로 다음 홉 인스턴스가있는 다음 홉 인스턴스가있는 다음 홉 인스턴스가있는 다음 홉과 특징을 참조하십시오. 정적 경로 개요의 다음 홉 및 기능을 참조하십시오."
  },
  {
    "source": "GCP",
    "title": "API Gateway (Announcement)",
    "date": "2025-03-25",
    "content": "On March 25, 2025, we released an updated version of API Gateway. Feature API Gateway now supports Workforce Identity Federation . Workforce Identity Federation lets you use an external identity provider (IdP) to authenticate and authorize a workforce — a group of users, such as employees, partners, and contractors — using Identity and Access Management (IAM) to access API Gateway services. See Identity federation: products and limitations for more information.",
    "link": "https://cloud.google.com/release-notes",
    "summary": "2025 년 3 월 25 일, 우리는 API 게이트웨이 기능의 업데이트 된 버전을 출시했습니다. API 게이트웨이는 이제 인력 신원 연합 인력 정체성 연맹을 지원하여 외부 ID (ID)를 사용하여 직원, 파트너 및 계약자와 같은 사용자 그룹을 인증하고 승인 할 수 있습니다."
  },
  {
    "source": "GCP",
    "title": "Apigee hybrid (Announcement)",
    "date": "2025-03-25",
    "content": "On March 25, 2025 we released an updated version of Advanced API Security. Changed New Advanced API Security support when using data residency (DRZ) with Apigee hybrid Advanced API Security is now available for Apigee hybrid orgs using DRZ, for hybrid versions 1.14.0 and later. See Using data residency with Apigee hybrid . See Introduction to data residency for information on DRZ and Advanced API Security support across organization types.",
    "link": "https://cloud.google.com/release-notes",
    "summary": "2025 년 3 월 25 일에 우리는 APIGEE 하이브리드 API 보안과 함께 DRZ (Data Residency)를 사용하여 DRZ를 사용하여 APIGEE 하이브리드 조직을 사용하여 DRZ (1.14.0)를 위해 DRZ 및 API 보안 지원에 대한 정보에 대한 정보 소개에 대한 APIGEE 하이브리드 API 보안을 사용할 때 DRZ (Apigee Hybrid Advanced API Security)를 사용할 때 새로운 고급 API 보안 지원을 변경 한 새로운 API 보안의 업데이트 된 버전을 출시했습니다."
  },
  {
    "source": "GCP",
    "title": "BigQuery (Feature)",
    "date": "2025-03-25",
    "content": "BigQuery ML now supports visualization of model monitoring metrics . This feature lets you use charts and graphs to analyze model monitoring function output . The following functions support metric visualization: ML.VALIDATE_DATA_SKEW : compute the statistics for a set of serving data, and then compare them to the statistics for the data used to train a BigQuery ML model in order to identify anomalous differences between the two data sets. ML.VALIDATE_DATA_DRIFT : compute and compare the statistics for two sets of serving data in order to identify anomalous differences between the two data sets. This feature is in preview .",
    "link": "https://cloud.google.com/release-notes",
    "summary": "BigQuery ML은 이제 모델 모니터링 메트릭의 시각화를 지원합니다.이 기능은 차트와 그래프를 사용하여 모델 모니터링 기능을 분석 할 수 있습니다. 다음 기능은 메트릭 시각화를 지원합니다. ML.Validate_Data_SKEW : ML.Validate_Data_SKEW : 다음 데이터 세트에 대한 통계를 계산하여 두 데이터 세트와 비교하여 두 가지 데이터 세트를 비교합니다."
  },
  {
    "source": "GCP",
    "title": "Cloud Run (Feature)",
    "date": "2025-03-25",
    "content": "New services using GPUs by default will have zonal redundancy turned on. However, you can now specify GPUs with zonal redundancy or without zonal redundancy , and request quota for either of these configurations. (",
    "link": "https://cloud.google.com/release-notes",
    "summary": "기본적으로 GPU를 사용하는 새로운 서비스는 구역 중복성을 켜지게되지만 이제 구역 중복성 또는 구역 중복성없이 GPU를 지정하고 이러한 구성 중 하나에 대한 할당량을 요청할 수 있습니다."
  },
  {
    "source": "GCP",
    "title": "In Preview) Cloud SQL for MySQL (Feature)",
    "date": "2025-03-25",
    "content": "Cloud SQL read pools provide operational simplicity and scaling for your large read workloads. Read pools provide a single endpoint in front of up to 20 read pool nodes and automatically load balance traffic. You can scale your read pool in several ways: Scale in or out : scale load balancing capacity horizontally by modifying the number of read pool nodes in the read pool. Each read pool supports up to 20 read pool nodes. Scale up or down : scale load balancing capacity vertically by modifying the machine type associated with a read pool node. Once defined, configuration is uniformly applied across each read pool node in the read pool. For more information, see About read pools .",
    "link": "https://cloud.google.com/release-notes",
    "summary": "클라우드 SQL 읽기 풀은 대규모 읽기 워크로드에 대한 작동 단순성 및 스케일링을 제공합니다. 읽기 풀 읽기 풀은 최대 20 개의 읽기 풀 노드 앞에서 단일 엔드 포인트를 제공하고 균형 균형 균형 트래픽을 자동으로로드 할 수 있습니다. 여러 가지 방법으로 읽기 풀을 스케일링 할 수 있습니다 : 스케일로드 밸런싱 용량은 읽기 풀에서 읽기 노드 수를 수정하여 수평으로 수평으로 밸런싱합니다."
  },
  {
    "source": "GCP",
    "title": "Cloud SQL for PostgreSQL (Feature)",
    "date": "2025-03-25",
    "content": "Cloud SQL read pools provide operational simplicity and scaling for your large read workloads. Read pools provide a single endpoint in front of up to 20 read pool nodes and automatically load balance traffic. You can scale your read pool in several ways: Scale in or out : scale load balancing capacity horizontally by modifying the number of read pool nodes in the read pool. Each read pool supports up to 20 read pool nodes. Scale up or down : scale load balancing capacity vertically by modifying the machine type associated with a read pool node. Once defined, configuration is uniformly applied across each read pool node in the read pool. For more information, see About read pools .",
    "link": "https://cloud.google.com/release-notes",
    "summary": "클라우드 SQL 읽기 풀은 대규모 읽기 워크로드에 대한 작동 단순성 및 스케일링을 제공합니다. 읽기 풀 읽기 풀은 최대 20 개의 읽기 풀 노드 앞에서 단일 엔드 포인트를 제공하고 균형 균형 균형 트래픽을 자동으로로드 할 수 있습니다. 여러 가지 방법으로 읽기 풀을 스케일링 할 수 있습니다 : 스케일로드 밸런싱 용량은 읽기 풀에서 읽기 노드 수를 수정하여 수평으로 수평으로 밸런싱합니다."
  },
  {
    "source": "GCP",
    "title": "Cloud Trace (Feature)",
    "date": "2025-03-25",
    "content": "To send trace data to your Google Cloud project, we recommend that you use the new Telemetry API, which implements the OpenTelemetry OTLP API and provides compatibility and support for the open source ecosystem. The limits for the Telemetry API are often more generous than those for the proprietary Cloud Trace API, which you can continue to use. The Telemetry API supports VPC Service Controls. For more information about the Telemetry API, see the following documents: Telemetry API overview Migrate from the Trace exporter to the OTLP endpoint Quotas and limits Compute Engine Fixed Resolved: Fixed the issue that caused Persistent Disks attached to VMs with n2d-standard-64 machine types to inconsistently reach the maximum performance limit of 100,000 IOPS. For more information, see Known issues . Confidential VM Changed On February 18, 2025, Google released a security fix for Confidential VM instances using AMD SEV-SNP on N2D machine types, which might result in performance degradation. The extent of the performance impact varies depending on the specific workload. Google Distributed Cloud (software only) for VMware Breaking Since release 1.30.0-gke.1930, the featureGates.enableGMPForSystemMetrics field in the stackdriver custom resource is always on and can't be disabled. It has been enabled by default since 1.16. If you have manually turned this feature off, upgrading clusters to version 1.30 means a breaking change in the format of some system metrics. For information on this feature, see Using Managed Service for Prometheus . Google Distributed Cloud (software only) for bare metal Breaking Since release 1.30.0-gke.1930, the featureGates.enableGMPForSystemMetrics field in the stackdriver custom resource is always on and can't be disabled. It has been enabled by default since 1.16. If you've manually turned this feature off, upgrading clusters to version 1.30 means a breaking change in the format of some system metrics. For information on this feature, see Use Google Cloud Managed Service for Prometheus for selected system components .",
    "link": "https://cloud.google.com/release-notes",
    "summary": "추적 데이터를 Google 클라우드 프로젝트로 보내려면 OpenTelemetry OTLP API를 구현하고 오픈 소스 생태계에 대한 호환성 및 지원을 제공하는 새로운 원격 측정 API를 사용하는 것이 좋습니다. 원격 소스 생태계에 대한 호환성 및 지원을 제공합니다. 원격 측정 API의 한도는 종종 텔레미티브 트레이스 API에 대한 정보보다 더 많은 정보를 얻을 수있는 API에 대한 더 많은 정보를 사용할 수 있습니다. 트레이스 수출 업체에서 OTLP 엔드 포인트 할당량 및 제한 엔진 컴퓨팅 엔진 고정 분해 : N2D-Standard-64 기계 유형으로 VM에 첨부 된 지속적인 디스크가 100,000 IOP의 최대 성능 제한에 도달하는 문제를 수정했습니다."
  },
  {
    "source": "GCP",
    "title": "NetApp Volumes (Feature)",
    "date": "2025-03-25",
    "content": "The backups feature for the Flex service level is now generally available. For more information, see About NetApp Volumes . Feature Google Cloud NetApp Volumes now supports cross-region backup vaults in Preview. For more information, see Backup vaults . Feature The Flex service level of Google Cloud NetApp Volumes now supports custom performance in Preview, enabling independent provisioning of capacity and performance with zonal pools in selected regions. For more information, see NetApp Volumes key features .",
    "link": "https://cloud.google.com/release-notes",
    "summary": "Flex 서비스 레벨의 백업 기능은 일반적으로 사용 가능한 기능입니다. Google Cloud Netapp Volumes는 이제 미리보기에서 크로스 지역 백업 공급을 지원합니다. 이제 Google Cloud NetApp 볼륨의 Flex 서비스 레벨은 미리보기에서 사용자 정의 성능을 지원하여 선택된 지역의 구역 풀에서 독립적 인 용량 및 성능 프로비저닝을 지원합니다."
  },
  {
    "source": "GCP",
    "title": "VPC Service Controls (Feature)",
    "date": "2025-03-25",
    "content": "Preview stage support for the following integration: Telemetry (OTLP) API",
    "link": "https://cloud.google.com/release-notes",
    "summary": "다음 통합을위한 미리보기 단계 지원 : 원격 측정 (OTLP) API"
  },
  {
    "source": "GCP",
    "title": "Apigee X (Announcement)",
    "date": "2025-03-24",
    "content": "On March 24, 2025, we released an updated version of Apigee. Feature Apigee Spaces is now generally available (GA) for use in Apigee organizations. Apigee Spaces enables identity-based isolation and grouping of API resources within an Apigee organization. With Apigee Spaces, you can have granular IAM control over access to your API proxies, shared flows, and API products. Spaces also provide the option of resource isolation at a team level, providing a clear separation of resources associated with different teams operating within the same Apigee organization. IAM policies can be applied at the Space level, eliminating the need to manage permissions individually for every API proxy, shared flow, and API product. Spaces are a brand new resource type with resource-level permissions. This means that Space permissions are not subject to the 64k limitation for project-level IAM conditions. Each space has its own 64k limit. To , see Apigee Spaces overview . BigQuery Libraries A weekly digest of client library updates from across the Cloud SDK . Node.js Changes for @google-cloud/bigquery 7.9.3 (2025-03-17) Bug Fixes Make sure to pass selectedFields to tabledata.list method ( #1449 ) ( 206aff9 ) Go Changes for bigquery/storage/apiv1beta1 1.67.0 (2025-03-14) Features bigquery/reservation: Add a new field enable_gemini_in_bigquery to .google.cloud.bigquery.reservation.v1.Assignment that indicates if \"Gemini in BigQuery\" ( 601e742 ) bigquery/reservation: Add a new field replication_status to .google.cloud.bigquery.reservation.v1.Reservation to provide visibility into errors that could arise during Disaster Recovery(DR) replication ( #11666 ) ( 601e742 ) bigquery/reservation: Add the CONTINUOUS Job type to .google.cloud.bigquery.reservation.v1.Assignment.JobType for continuous SQL jobs ( 601e742 ) bigquery: Support MetadataCacheMode for ExternalDataConfig ( #11803 ) ( af5174d ), refs #11802 Bug Fixes bigquery: Increase timeout for storage api test and remove usage of deprecated pkg ( #11810 ) ( f47e038 ), refs #11801 bigquery: Update golang.org/x/net to 0.37.0 ( 1144978 ) Documentation bigquery/reservation: Remove the section about EDITION_UNSPECIFIED in the comment for slot_capacity in .google.cloud.bigquery.reservation.v1.Reservation to clarify that ( 601e742 ) bigquery/reservation: Update the google.api.field_behavior for the .google.cloud.bigquery.reservation.v1.Reservation.primary_location and .google.cloud.bigquery.reservation.v1.Reservation.original_primary_location fields to clarify that they are OUTPUT_ONLY ( 601e742 ) Java Changes for google-cloud-bigquery 2.49.0 (2025-03-20) Features bigquery: Implement getArray in BigQueryResultImpl ( #3693 ) ( e2a3f2c ) Next release from main branch is 2.49.0 ( #3706 ) ( b46a6cc ) Bug Fixes Retry ExceptionHandler not retrying on IOException ( #3668 ) ( 83245b9 ) Dependencies Exclude io.netty:netty-common from org.apache.arrow:arrow-memor… ( #3715 ) ( 11b5809 ) Update actions/upload-artifact action to v4.6.2 ( #3724 ) ( 426a59b ) Update actions/upload-artifact action to v4.6.2 ( #3724 ) ( 483f930 ) Update dependency com.google.api.grpc:proto-google-cloud-bigqueryconnection-v1 to v2.61.0 ( #3703 ) ( 53b07b0 ) Update dependency com.google.api.grpc:proto-google-cloud-bigqueryconnection-v1 to v2.62.0 ( #3726 ) ( 38e004b ) Update dependency com.google.apis:google-api-services-bigquery to v2-rev20250302-2.0.0 ( #3720 ) ( c0b3902 ) Update dependency com.google.apis:google-api-services-bigquery to v2-rev20250313-2.0.0 ( #3723 ) ( b8875a8 ) Update dependency com.google.cloud:google-cloud-datacatalog-bom to v1.65.0 ( #3704 ) ( 53b68b1 ) Update dependency com.google.cloud:google-cloud-datacatalog-bom to v1.66.0 ( #3727 ) ( 7339f94 ) Update dependency com.google.cloud:sdk-platform-java-config to v3.45.1 ( #3714 ) ( e4512aa ) Update dependency com.google.oauth-client:google-oauth-client-java6 to v1.39.0 ( #3710 ) ( c0c6352 ) Update dependency com.google.oauth-client:google-oauth-client-jetty to v1.39.0 ( #3711 ) ( 43b86e9 ) Update dependency node to v22 ( #3713 ) ( 251def5 ) Update netty.version to v4.1.119.final ( #3717 ) ( 08a290a ) Documentation Update error handling comment to be more precise in samples ( #3712 ) ( 9eb555f ) Feature You can now use KLL quantile functions to efficiently compute approximate quantiles. This feature is in preview . Feature You can now set labels on reservations. These labels can be used to organize your reservations and for billing analysis. This feature is in preview . Feature The BigQuery Data Transfer Service can now transfer reporting and configuration data from Google Analytics 4 into BigQuery. This feature is in preview . Feature We have redesigned the Add Data dialog to guide you through loading data into BigQuery with a source-first experience and enhanced search and filtering capabilities. This feature is generally available (GA). Bigtable Libraries A weekly digest of client library updates from across the Cloud SDK . Java Changes for google-cloud-bigtable 2.56.0 (2025-03-18) Features bigtable: Add support for Logical Views in Admin API ( #2519 ) ( 6dac3fd ) bigtable: Add support for Materialized Views in Admin API ( #2511 ) ( 55cd719 ) Bug Fixes deps: Update the Java code generator (gapic-generator-java) to 2.55.1 ( 7992af0 ) Dependencies Sdk-platform-java-config 3.45.1 ( #2517 ) ( b2af258 ) Python Changes for google-cloud-bigtable 2.30.0 (2025-03-18) Features Update ExecuteQuery to use Prepare ( #1100 ) ( 8a7abc1 ) Bug Fixes Allow protobuf 6.x ( #1092 ) ( 1015fa8 ) Remove setup.cfg configuration for creating universal wheels ( #1097 ) ( 95f4b82 ) Cloud Logging Libraries A weekly digest of client library updates from across the Cloud SDK . Java Changes for google-cloud-logging 3.22.0 (2025-03-18) Features Next release from main branch is 3.22.0 ( #1776 ) ( 7736073 ) Bug Fixes deps: Update the Java code generator (gapic-generator-java) to 2.55.1 ( dd25992 ) Dependencies Update dependency com.google.cloud:sdk-platform-java-config to v3.45.1 ( #1779 ) ( a643ab0 ) Update googleapis/sdk-platform-java action to v2.55.1 ( #1780 ) ( 505557e )",
    "link": "https://cloud.google.com/release-notes",
    "summary": "2025 년 3 월 24 일, 우리는 Apigee 조직에서 사용할 수있는 Apigee Feature Apigee Spaces의 업데이트 된 버전을 출시했습니다. Apigee 조직에서 사용할 수 있습니다."
  },
  {
    "source": "GCP",
    "title": "Cloud SQL for MySQL (Feature)",
    "date": "2025-03-24",
    "content": "Cloud SQL now lets you retain existing backups after an instance is deleted. These consist of on-demand and automatic backups created when the instance was live. For more information, see Retained backups .",
    "link": "https://cloud.google.com/release-notes",
    "summary": "Cloud SQL은 이제 인스턴스가 삭제 된 후 기존 백업을 유지할 수 있습니다. 이들은 인스턴스가 라이브로 만들 때 생성 된 주문형 및 자동 백업으로 구성됩니다."
  },
  {
    "source": "GCP",
    "title": "Cloud SQL for PostgreSQL (Feature)",
    "date": "2025-03-24",
    "content": "Cloud SQL now lets you retain existing backups after an instance is deleted. These consist of on-demand and automatic backups created when the instance was live. For more information, see Retained backups .",
    "link": "https://cloud.google.com/release-notes",
    "summary": "Cloud SQL은 이제 인스턴스가 삭제 된 후 기존 백업을 유지할 수 있습니다. 이들은 인스턴스가 라이브로 만들 때 생성 된 주문형 및 자동 백업으로 구성됩니다."
  },
  {
    "source": "GCP",
    "title": "Cloud SQL for SQL Server (Feature)",
    "date": "2025-03-24",
    "content": "You can export the transaction logs for all Cloud SQL for SQL Server instances that have point-in-time recovery (PITR) enabled and their logs stored in Cloud Storage . Feature Cloud SQL now lets you retain existing backups after an instance is deleted. These consist of on-demand and automatic backups created when the instance was live. For more information, see Retained backups .",
    "link": "https://cloud.google.com/release-notes",
    "summary": "PITR (Point-in-Time Recovery)가 활성화 된 SQL Server 인스턴스에 대한 모든 클라우드 SQL에 대한 트랜잭션 로그를 내보내고 클라우드 스토리지 기능 클라우드 SQL에 저장된 로그는 이제 인스턴스가 삭제 된 후에는 기존 백업을 삭제할 수 있습니다."
  },
  {
    "source": "GCP",
    "title": "Firestore (Feature)",
    "date": "2025-03-24",
    "content": "Cloud Firestore now supports multi-region nam7 United States (Central and East), which consists of regions us-central1 (Iowa) and us-east4 (Northern Virginia). For a full list of supported locations, see Locations .",
    "link": "https://cloud.google.com/release-notes",
    "summary": "Cloud Firestore는 현재 지원되는 위치 목록을 보려면 미국 중앙 (Iowa) 및 US-East4 (Northern Virginia)로 구성된 다중 지역 NAM7 미국 (중앙 및 동부)을 지원합니다."
  },
  {
    "source": "GCP",
    "title": "Firestore in Datastore mode (Feature)",
    "date": "2025-03-24",
    "content": "Firestore in Datastore mode now supports multi-region nam7 United States (Central and East), which consists of regions us-central1 (Iowa) and us-east4 (Northern Virginia). For a full list of supported locations, see Locations . Libraries A weekly digest of client library updates from across the Cloud SDK . Java Changes for google-cloud-datastore 2.27.1 (2025-03-18) Bug Fixes deps: Update the Java code generator (gapic-generator-java) to 2.55.1 ( ba1ad98 ) Dependencies Update dependency com.google.cloud:sdk-platform-java-config to v3.45.1 ( #1791 ) ( ab5ac8e ) Google SecOps Changed Purging of expired raw logs and normalized events is now based on the Ingestion Timestamp instead of the Event Timestamp . Google SecOps SIEM Changed Purging of expired raw logs and normalized events is now based on the Ingestion Timestamp instead of the Event Timestamp .",
    "link": "https://cloud.google.com/release-notes",
    "summary": "Datastore 모드의 Firestore는 이제 지원되는 위치의 전체 목록을 위해 US-Central1 (Iowa) 및 US-East4 (Northern Virginia)로 구성된 다중 지역 NAM7 미국 (중앙 및 동부)을 지원합니다. Cloud SDK 전반에 걸쳐 고객 라이브러리 업데이트의 매주 소화 된 위치 라이브러리를 참조하십시오."
  },
  {
    "source": "GCP",
    "title": "Looker (Feature)",
    "date": "2025-03-24",
    "content": "The following features have been added to Studio in Looker, which is available in preview: The Looker connector can now connect to a private IP (private services access) only Looker (Google Cloud core) instance or to a private IP (Private Service Connect) Looker (Google Cloud core) instance using the Looker instance ID . The Looker connector now supports Looker export, download, and scheduling permissions . Looker System Activity now includes usage, historical, and performance information about Looker reports . You can now enable Studio in Looker on Looker instances that use Google OAuth authentication. The Looker connector now supports some calculated field functions.",
    "link": "https://cloud.google.com/release-notes",
    "summary": "다음과 같은 기능은 미리보기에서 사용할 수있는 Studio에 추가되었습니다. Looker 커넥터는 이제 Looker 인스턴스 ID를 사용하는 Looker Export, 다운로드 및 스케줄링 투과 시스템 활동을 지원하는 Looker 인스턴스 ID를 사용하는 Looker 인스턴스 ID (Private Service Access) 전용 Looker (Google Cloud Core) 인스턴스 또는 개인 IP (Private Service Connect) 룩커 (Google Cloud Core) 인스턴스에 연결할 수 있습니다."
  },
  {
    "source": "GCP",
    "title": "Looker Studio (Feature)",
    "date": "2025-03-24",
    "content": "Looker connector enhancements The following enhancements to the Looker connector are available in Preview : The Looker connector can now connect to a private IP (private services access) only Looker (Google Cloud core) instance or to a private IP (Private Service Connect) Looker (Google Cloud core) instance using the Looker instance ID . The Looker connector now supports some calculated field functions . Announcement Partner connection launch update The following partner connectors have been added to the Looker Studio Connector Gallery :",
    "link": "https://cloud.google.com/release-notes",
    "summary": "Looker Connector 향상 Looker 커넥터에 대한 다음 개선 사항은 미리보기에서 사용할 수 있습니다. Looker 커넥터는 이제 개인 IP (개인 서비스 액세스) 전용 IP (Google Cloud Core) 인스턴스 (Google Cloud Core) 인스턴스 또는 개인 IP (Private Service Connect) Looker (Google Cloud Core) 인스턴스에 연결할 수 있습니다. Looker 인스턴스를 사용하는 Looker Connector는 이제 파트너 커넥터가 추가 된 파트너 커넥터를 지원했습니다."
  },
  {
    "source": "GCP",
    "title": "SEMSTORM Reports by SEMSTORM Pango by Pango Solutions AB AppsFlyer by Dataslayer Vista Social by Vista Social Linkedin Pages -Free by Data Bloo WooCommerce - Free by Data Bloo Media CDN (Feature)",
    "date": "2025-03-24",
    "content": "Media CDN supports dynamic compression in General Availability . Pub/Sub Libraries A weekly digest of client library updates from across the Cloud SDK . Python Changes for google-cloud-pubsub 2.29.0 (2025-03-19) Features Add REST Interceptors which support reading metadata ( 4363179 ) Add support for opt-in debug logging ( 4363179 ) Deprecate enabled field for message transforms and add disabled field ( 4363179 ) Bug Fixes Allow logs to propagate upstream for caplog testing ( #1374 ) ( fa39b0e ) Allow Protobuf 6.x ( #1369 ) ( c95b7a5 ) Fix typing issue with gRPC metadata when key ends in -bin ( 4363179 ) Documentation A comment for field code in message .google.pubsub.v1.JavaScriptUDF is changed ( 4363179 ) Add samples and test for ingestion from Kafka sources ( #1354 ) ( 820f986 ) Deprecate enabled field for message transforms and add disabled field ( 4363179 ) samples: Increase example max_bytes setting for cloud storage subscriptions to encourage more performant subscribe ( #1324 ) ( cb760a7 )",
    "link": "https://cloud.google.com/release-notes",
    "summary": "Media CDN은 일반 가용성 펍/서브 라이브러리의 동적 압축을 지원합니다. 클라우드 전반에 걸쳐 클라이언트 라이브러리 업데이트의 매주 다이제스트 Google-Cloud-Pubsub 2.29.0 (2025-03-19)의 기능을 추가로 읽기 메타 데이터 (4363179)를 지원하는 레게 인터셉터 (436317)에 대한 지원을 추가하여 OPT-In Debug Logging (436317)에 대한 추가 필드에 대한 지원을 추가합니다. 4363179) 버그 수정은 캡 플로그 테스트 ( #1374) (FA39B0E)를 위해 로그가 상류를 전파 할 수 있도록 허용합니다. Protobuf 6.x ( #1369) (C95B7A5) Key -Bin (4363179) 문서의 댓글에 대한 주석 A IS 메시지. 변경 (4363179) 샘플을 추가하고 Kafka 소스 ( #1354) (820F986)의 섭취를 테스트하고 메시지 변환에 대한 활성화 된 필드 및 장애인 필드 추가 (4363179) 샘플 : 클라우드 스토리지 구독에 대한 최대 _BYTES 설정을 높이기 위해 최대 _BYTES 설정 (CB760A7) (CB760A7)."
  },
  {
    "source": "GCP",
    "title": "VPC Service Controls (Feature)",
    "date": "2025-03-24",
    "content": "Preview stage support for the following integration: Parameter Manager",
    "link": "https://cloud.google.com/release-notes",
    "summary": "다음 통합을위한 미리보기 단계 지원 : 매개 변수 관리자"
  },
  {
    "source": "AWS",
    "title": "AWS Identity and Access Management now supports dual-stack (IPv4 and IPv6) environments",
    "date": "2025-03-28",
    "content": "AWS Identity and Access Management (IAM) announces a new dual-stack public endpoint, enabling customers to connect to IAM over the public internet using IPv6, IPv4, or dual-stack clients. Dual-stack support is also available when customers access the new IAM endpoint privately from their Amazon Virtual Private Cloud (VPC) using AWS PrivateLink . With simultaneous support for both IPv4 and IPv6 clients on IAM endpoint, customers can gradually transition from IPv4 to IPv6-based systems and applications. Support for dual-stack IAM endpoint is available in all commercial AWS Regions, the AWS GovCloud (US) Regions, and the China Regions. For more information about IAM dual-stack public endpoint, please see the IAM User Guide .",
    "link": "https://aws.amazon.com/about-aws/whats-new/2025/03/aws-identity-access-management-dual-stack-ipv4-ipv6-environments",
    "summary": "AWS Identity and Access Management (IAM)는 새로운 듀얼 스택 공개 엔드 포인트를 발표하여 고객이 IPv6, IPv4 또는 듀얼 스택 클라이언트를 사용하여 공개 인터넷을 통해 IAM에 연결할 수 있도록합니다. 고객이 AWS Privatelink를 사용하여 Amazon Virtual Private Cloud (VPC)에서 새로운 IAM Endpoint에 개인적으로 새로운 IAM Endpoint에 액세스 할 때 듀얼 스택 지원을 사용할 수 있습니다. IAM Endpoint에서 IPv4 및 IPv6 클라이언트를 모두 동시에 지원함으로써 고객은 IPv4에서 IPv6 기반 시스템 및 응용 프로그램으로 점차 전환 할 수 있습니다. 듀얼 스택 IAM 엔드 포인트에 대한 지원은 모든 상업용 AWS 지역, AWS Govcloud (미국) 지역 및 중국 지역에서 제공됩니다. IAM Dual-Stack Public Endpoint에 대한 자세한 내용은 IAM 사용자 안내서를 참조하십시오."
  },
  {
    "source": "AWS",
    "title": "Amazon Bedrock Guardrails announces the general availability of industry-leading image content filters",
    "date": "2025-03-28",
    "content": "Amazon Bedrock Guardrails announces the general availability of image content filters - offering industry-leading text and image content safeguards that help customers block up to 88% of harmful multi modal content. This new capability removes the heavy lifting required by customers to build their own safeguards for image content or spend cycles with manual content moderation that can be error-prone and tedious. Bedrock Guardrails provides configurable safeguards to detect and block harmful content and prompt attacks, define topics to deny and disallow specific topics, redact personally identifiable information (PII) such as personal data, block specific words, along with contextual grounding checks to detect and block model hallucinations and to identify the relevance of model responses and claims, and identify, correct, and explain factual claims in model responses using Automated Reasoning checks. Guardrails can be applied across any foundation model including those hosted with Amazon Bedrock, self-hosted models, and third-party models outside Bedrock using the ApplyGuardrail API , providing a consistent user experience and helping to standardize safety and privacy controls. Image content filters can be applied to all categories within the content filter policy of Bedrock Guardrails including hate, insults, sexual, violence, misconduct, and prompt attack. With this new capability, customers have the flexibility to choose either image or text content, or both, and build safe generative AI applications adhering to their responsible AI policies. This new capability is generally available in US East (N. Virginia), US West (Oregon), Europe (Frankfurt), and Asia Pacific (Tokyo) AWS regions. To learn more, see the blog , technical documentation , and the Bedrock Guardrails product page.",
    "link": "https://aws.amazon.com/about-aws/whats-new/2025/03/amazon-bedrock-guardrails-general-availability-image-content-filters",
    "summary": "Amazon Bedrock Guardrails는 이미지 컨텐츠 필터의 일반적인 가용성을 발표합니다. 이는 업계 최고의 텍스트 및 이미지 컨텐츠 보호 장치를 제공하여 고객이 유해한 멀티 모달 컨텐츠의 최대 88%를 차단할 수 있도록 도와줍니다. 이 새로운 기능은 고객이 이미지 컨텐츠에 대한 자체 보호 조치를 구축하거나 오류가 발생하고 지루할 수있는 수동 콘텐츠 중재로주기를 사용하는 데 필요한 무거운 리프팅을 제거합니다. Bedrock Guardrails는 유해한 컨텐츠 및 프롬프트 공격을 감지하고 차단하고 특정 주제를 거부하고 허용하는 주제를 정의하고 개인 데이터와 같은 개인 식별 정보 (PII)를 정의하고 개인 데이터를 차단하고, 모델과 블록의 환영 및 모델 및 주장 및 설명의 관련성을 식별하기위한 상황에 대한 접지 점검과 함께 개인 식별 정보 (PII)를 정의하고 개인 식별 정보 (PII)를 정의하는 구성 가능한 보호 조치를 제공합니다. 수표. Guardrails는 ApplyGuardRail API를 사용하여 Amazon Bedrock, 자체 호스팅 모델 및 Bedrock 외부의 타사 모델과 함께 호스팅 된 제품을 포함하여 모든 기초 모델에 적용하여 일관된 사용자 경험을 제공하고 안전 및 개인 정보 보호 제어를 표준화하는 데 도움을 줄 수 있습니다. 이미지 컨텐츠 필터는 증오, 모욕, 성적, 폭력, 위법 행위 및 신속한 공격을 포함한 기반암 가드 레일의 컨텐츠 필터 정책 내의 모든 범주에 적용될 수 있습니다. 이 새로운 기능을 통해 고객은 이미지 또는 텍스트 컨텐츠 또는 둘 다를 선택하고 책임있는 AI 정책을 준수하는 안전한 생성 AI 애플리케이션을 구축 할 수있는 유연성이 있습니다. 이 새로운 기능은 일반적으로 미국 동부 (N. 버지니아), 미국 웨스트 (오레곤), 유럽 (프랑크푸르트) 및 아시아 태평양 (도쿄) AWS 지역에서 구입할 수 있습니다. 자세한 내용은 블로그, 기술 문서 및 Bedrock Guardrails 제품 페이지를 참조하십시오."
  },
  {
    "source": "AWS",
    "title": "Amazon EC2 now supports more bandwidth and jumbo frames to select destinations",
    "date": "2025-03-28",
    "content": "Amazon EC2 now supports up to the full EC2 instance bandwidth for inter-region VPC peering traffic and to AWS Direct Connect. Additionally, EC2 supports jumbo frames up to 8500 Bytes for cross region VPC peering. Before today, the egress bandwidth for EC2 instances was limited to 50% of the aggregate bandwidth limit for instances with 32 or more vCPUs, and 5 Gbps for smaller instances. Cross region peering supported up to 1500 bytes. Now, customers can send bandwidth from EC2 between regions or towards AWS Direct Connect at the full instance baseline specification or 5Gbps, whichever is greater and customers can use jumbo frames across regions for peered VPCs. Customers transferring data between regions or from EC2 to their on-premises network via AWS Direct Connect now have access to the full instance bandwidth capabilities. Before today, customers sending traffic to any destination not in the same region had a lower bandwidth limit. With this change, the lower limit has been removed for destinations between AWS regions and to on-premises through AWS Direct Connect, allowing for faster transfers. Additionally, supporting jumbo frames for peering makes sending large volumes of data faster than before. This capability is available in all AWS commercial regions, the AWS GovCloud (US) Regions, and the Amazon Web Services China (Beijing) Region, operated by Sinnet and Amazon Web Services China (Ningxia) Region, operated by NWCD. Customers can take advantage of this capability without any additional changes. To learn more about EC2 bandwidth capabilities, please review our user guide .",
    "link": "https://aws.amazon.com/about-aws/whats-new/2025/03/amazon-ec2-bandwidth-jumbo-frames",
    "summary": "Amazon EC2는 이제 지역 간 VPC 피어링 트래픽 및 AWS Direct Connect의 전체 EC2 인스턴스 대역폭을 지원합니다. 또한 EC2는 크로스 영역 VPC 피어링을 위해 최대 8500 바이트의 점보 프레임을 지원합니다. 오늘 이전에 EC2 인스턴스의 EGRESS 대역폭은 32 개 이상의 VCPU가있는 인스턴스의 경우 집계 대역폭 한계의 50%, 더 작은 인스턴스의 경우 5Gbps로 제한되었습니다. 크로스 지역 피어링은 최대 1500 바이트를 지원했습니다. 이제 고객은 EC2에서 지역 간 또는 전체 인스턴스 기준선 사양 또는 5GBPS에서 AWS 직접 연결을 통해 대역폭을 보낼 수 있으며 고객은 피어링 된 VPC에 지역에서 점보 프레임을 사용할 수 있습니다. AWS Direct Connect를 통해 지역 또는 EC2에서 온 프레미스 네트워크로 데이터를 전송하는 고객은 이제 전체 인스턴스 대역폭 기능에 액세스 할 수 있습니다. 오늘 이전에는 같은 지역이 아닌 목적지로 트래픽을 보내는 고객의 대역폭 제한이 낮았습니다. 이러한 변화로 인해 AWS 지역 간의 목적지와 AWS Direct Connect를 통해 온-프레미스로 하한이 제거되어 더 빠른 전송이 가능합니다. 또한, 피어링을위한 점보 프레임을 지원하면 전보다 많은 양의 데이터를 더 빨리 전송할 수 있습니다. 이 기능은 NWCD가 운영하는 Sinnet 및 Amazon Web Services China (Ningxia) 지역에서 운영하는 모든 AWS 상업 지역, AWS Govcloud (미국) 지역 및 Amazon Web Services China (Beijing) 지역에서 제공됩니다. 고객은 추가 변경 없이이 기능을 활용할 수 있습니다. EC2 대역폭 기능에 대한 자세한 내용은 사용자 안내서를 검토하십시오."
  },
  {
    "source": "AWS",
    "title": "Amazon DataZone now supports metadata rules for publishing",
    "date": "2025-03-28",
    "content": "Amazon DataZone is a data management service that makes it faster and easier for customers to catalog, discover, share, and govern data stored across AWS, on premises, and third-party sources. Amazon DataZone now supports metadata rules for data publishing workflows, in addition to existing support for subscription workflows. This enhancement allows organizations to enforce metadata standards consistently across both producer and consumer workflows. By standardizing metadata practices, organizations can improve compliance, enhance audit readiness, and streamline workflows for greater efficiency and control. With metadata rules, domain owners can define mandatory metadata fields that data users must complete when publishing assets to the catalog or requesting access to data. For example, a financial services organization can require producers to classify data before publication, and consumers to provide project details and compliance evidence as part of an access request. Healthcare providers can use metadata rules to enforce metadata standards to align with patient data regulations. Metadata rules also enable the creation of custom approval workflows for subscriptions to assets, using collected metadata to facilitate access decisions or auto-fulfillment—outside of Amazon DataZone. To get started with metadata rules— Read the user guide for creating rules in the publishing workflow Read the user guide for creating rules in subscription requests",
    "link": "https://aws.amazon.com/about-aws/whats-new/2025/03/amazon-datazone-metadata-rules-publishing",
    "summary": "Amazon Datazone은 고객이 AWS, 구내 및 타사 소스에 저장된 데이터를 카탈로그, 발견, 공유 및 관리하는 데 더 빠르고 쉽게 데이터 관리 서비스입니다. Amazon Datazone은 이제 구독 워크 플로에 대한 기존 지원 외에도 데이터 게시 워크 플로우에 대한 메타 데이터 규칙을 지원합니다. 이 향상을 통해 조직은 생산자와 소비자 워크 플로에서 메타 데이터 표준을 지속적으로 시행 할 수 있습니다. 메타 데이터 관행을 표준화함으로써 조직은 규정 준수를 향상시키고 감사 준비를 향상 시키며 효율성과 제어를 위해 워크 플로를 간소화 할 수 있습니다. 메타 데이터 규칙을 사용하면 도메인 소유자는 자산을 카탈로그에 게시하거나 데이터에 대한 액세스를 요청할 때 데이터 사용자가 완료 해야하는 필수 메타 데이터 필드를 정의 할 수 있습니다. 예를 들어, 금융 서비스 조직은 생산자가 출판 전에 데이터를 분류 할 것을 요구할 수 있으며 소비자는 액세스 요청의 일부로 프로젝트 세부 사항 및 규정 준수 증거를 제공하도록 요구할 수 있습니다. 의료 서비스 제공자는 메타 데이터 규칙을 사용하여 메타 데이터 표준을 시행하여 환자 데이터 규정과 일치 할 수 있습니다. 메타 데이터 규칙을 사용하면 수집 된 메타 데이터를 사용하여 Amazon Datazone의 아웃 사이드 (Amazon Datazone)를 용이하게하기 위해 수집 된 메타 데이터를 사용하여 자산 구독에 대한 맞춤 승인 워크 플로우를 생성 할 수 있습니다. 메타 데이터 규칙을 시작하려면 - 게시 워크 플로에서 규칙을 작성하려면 사용자 안내서를 읽으십시오. 구독 요청에서 규칙을 작성하려면 사용자 안내서를 읽으십시오."
  },
  {
    "source": "AWS",
    "title": "Amazon SageMaker introduces metadata rules to enforce standards and improve data governance",
    "date": "2025-03-28",
    "content": "The next generation of SageMaker brings together widely adopted AWS machine learning and analytics capabilities, delivering an integrated experience with unified access to all data. Amazon SageMaker Lakehouse supports unified data access, and Amazon SageMaker Catalog, built on Amazon DataZone, offers catalog and governance features to meet enterprise security needs. Amazon SageMaker Catalog now supports metadata rules, allowing organizations to enforce metadata standards across data publishing and subscription workflows. By standardizing metadata practices, organizations can improve compliance, enhance audit readiness, and streamline access workflows for greater efficiency and control. With metadata rules, domain owners can define mandatory metadata fields that data users must complete when publishing assets to the catalog or requesting access to data. For example, a financial services organization can require producers to classify data before publication, and consumers to provide project details and compliance evidence as part of an access request. Healthcare providers can use metadata rules to enforce metadata standards to align with patient data regulations. Metadata rules also enable the creation of custom approval workflows for subscriptions to assets, using collected metadata to facilitate access decisions or auto-fulfillment—outside of Amazon SageMaker. To get started with metadata rules— Read the user guide for creating rules in the publishing workflow Read the user guide for creating rules in subscription requests",
    "link": "https://aws.amazon.com/about-aws/whats-new/2025/03/amazon-sagemaker-metadata-rules-standards-improve-data-governance",
    "summary": "차세대 Sagemaker는 널리 채택 된 AWS 머신 러닝 및 분석 기능을 제공하여 모든 데이터에 대한 통합 액세스와 통합 경험을 제공합니다. Amazon Sagemaker Lakehouse는 통합 데이터 액세스를 지원하며 Amazon Datazone을 기반으로 한 Amazon Sagemaker 카탈로그는 엔터프라이즈 보안 요구를 충족시키기위한 카탈로그 및 거버넌스 기능을 제공합니다. Amazon Sagemaker 카탈로그는 이제 메타 데이터 규칙을 지원하여 조직이 데이터 게시 및 구독 워크 플로에서 메타 데이터 표준을 시행 할 수 있도록합니다. 메타 데이터 관행을 표준화함으로써 조직은 규정 준수를 향상시키고 감사 준비를 향상 시키며 액세스 워크 플로우를 간소화하여 효율성과 제어를 강화할 수 있습니다. 메타 데이터 규칙을 사용하면 도메인 소유자는 자산을 카탈로그에 게시하거나 데이터에 대한 액세스를 요청할 때 데이터 사용자가 완료 해야하는 필수 메타 데이터 필드를 정의 할 수 있습니다. 예를 들어, 금융 서비스 조직은 생산자가 출판 전에 데이터를 분류 할 것을 요구할 수 있으며 소비자는 액세스 요청의 일부로 프로젝트 세부 사항 및 규정 준수 증거를 제공하도록 요구할 수 있습니다. 의료 서비스 제공자는 메타 데이터 규칙을 사용하여 메타 데이터 표준을 시행하여 환자 데이터 규정과 일치 할 수 있습니다. 메타 데이터 규칙을 사용하면 수집 된 메타 데이터를 사용하여 Amazon Sagemaker의 아웃 사이드를 용이하게하기 위해 수집 된 메타 데이터를 사용하여 자산 구독에 대한 맞춤 승인 워크 플로우를 생성 할 수 있습니다. 메타 데이터 규칙을 시작하려면 - 게시 워크 플로에서 규칙을 작성하려면 사용자 안내서를 읽으십시오. 구독 요청에서 규칙을 작성하려면 사용자 안내서를 읽으십시오."
  },
  {
    "source": "AWS",
    "title": "Amazon ElastiCache now supports AWS PrivateLink in AWS Asia Pacific (Jakarta) and Asia Pacific (Hyderabad) Regions",
    "date": "2025-03-28",
    "content": "You can now use AWS PrivateLink to privately access Amazon ElastiCache from your Amazon Virtual Private Cloud (Amazon VPC). AWS PrivateLink provides private connectivity between VPCs, AWS services, and on-premises networks, without exposing traffic to the public internet and securing your network traffic. The Amazon ElastiCache API supports AWS PrivateLink in AWS Asia Pacific (Jakarta) and Asia Pacific (Hyderabad) Regions. To use AWS PrivateLink with Amazon ElastiCache, you create an interface VPC endpoint for Amazon ElastiCache in your VPC using the Amazon VPC console, AWS SDK, or AWS CLI. With an interface VPC endpoint, you can privately access the Amazon ElastiCache APIs from applications inside your Amazon VPC. You can also access the VPC endpoint from other VPCs using VPC Peering or your on-premises environments using AWS VPN or AWS Direct Connect. To learn more, read the documentation , or get started in the Amazon VPC Console .",
    "link": "https://aws.amazon.com/about-aws/whats-new/2025/03/amazon-elasticache-aws-privatelink-asia-pacific-jakarta-asia-pacific-hyderabad-regions",
    "summary": "이제 AWS Privatelink를 사용하여 Amazon Virtual Private Cloud (Amazon VPC)에서 Amazon Elasticache에 개인적으로 액세스 할 수 있습니다. AWS Privatelink는 공개 인터넷에 트래픽을 노출시키고 네트워크 트래픽을 확보하지 않고 VPC, AWS 서비스 및 온 프레미스 네트워크간에 개인 연결을 제공합니다. Amazon Elasticache API는 AWS Asia Pacific (Jakarta) 및 Asia Pacific (Hyderabad) 지역의 AWS Privatelink를 지원합니다. Amazon Elasticache와 함께 AWS PrivateLink를 사용하려면 Amazon VPC 콘솔, AWS SDK 또는 AWS CLI를 사용하여 VPC에서 Amazon Elasticache에 대한 인터페이스 VPC 엔드 포인트를 만듭니다. 인터페이스 VPC 엔드 포인트를 사용하면 Amazon VPC 내부의 응용 프로그램에서 Amazon Elasticache API에 개인적으로 액세스 할 수 있습니다. VPC 피어링 또는 AWS VPN 또는 AWS Direct Connect를 사용하여 온 프레미스 환경을 사용하여 다른 VPC의 VPC 엔드 포인트에 액세스 할 수 있습니다. 자세한 내용은 문서를 읽거나 Amazon VPC 콘솔에서 시작하십시오."
  },
  {
    "source": "AWS",
    "title": "AWS CodeBuild now supports custom cache keys for S3 caching",
    "date": "2025-03-28",
    "content": "AWS CodeBuild now supports an enhanced S3 caching experience. You can now define custom cache keys for more granular cache management and improved cache persistence across your builds. You can also share the cache keys across projects to use a common dependency cache to speed up your builds. AWS CodeBuild is a fully managed continuous integration service that compiles source code, runs tests, and produces software packages ready for deployment. Additionally, CodeBuild added support for fallback keys, which allows partial matches when an exact cache key is not found. This capability enables efficient caching sharing between similar builds, such as builds with common dependencies, without needing to rebuild everything. You can also specify an optional action to skip the cache save or restore step for a more flexible cache management. These caching enhancements are available in all AWS Regions where CodeBuild is offered. To learn more, please visit our documentation . To get started with CodeBuild, visit the AWS CodeBuild product page .",
    "link": "https://aws.amazon.com/about-aws/whats-new/2025/03/aws-codebuild-custom-cache-keys-s3-caching",
    "summary": "AWS CodeBuild는 이제 향상된 S3 캐싱 경험을 지원합니다. 이제보다 세분화 된 캐시 관리 및 빌드 전체에서 개선 된 캐시 지속성을 위해 사용자 정의 캐시 키를 정의 할 수 있습니다. 또한 프로젝트 전체에서 캐시 키를 공유하여 공통 종속성 캐시를 사용하여 빌드 속도를 높일 수 있습니다. AWS CodeBuild는 소스 코드를 컴파일하고 테스트를 실행하며 배포 할 준비가 된 소프트웨어 패키지를 생성하는 완전히 관리되는 연속 통합 서비스입니다. 또한 CodeBuild는 폴백 키에 대한 지원을 추가하여 정확한 캐시 키를 찾을 수없는 경우 부분 일치를 허용합니다. 이 기능을 통해 모든 것을 재건 할 필요없이 공통 의존성이있는 빌드와 같은 유사한 빌드간에 효율적인 캐싱 공유가 가능합니다. 보다 유연한 캐시 관리를 위해 캐시 저장 또는 복원 단계를 건너 뛰는 선택적 조치를 지정할 수도 있습니다. 이러한 캐싱 향상은 CodeBuild가 제공되는 모든 AWS 지역에서 제공됩니다. 자세한 내용은 문서를 방문하십시오. CodeBuild를 시작하려면 AWS CodeBuild 제품 페이지를 방문하십시오."
  },
  {
    "source": "AWS",
    "title": "Amazon EBS launches gp3 and io1 volumes for AWS Dedicated Local Zones",
    "date": "2025-03-28",
    "content": "You can now use Amazon EBS gp3 and io1 volumes in AWS Dedicated Local Zones . Dedicated Local Zones are a type of AWS infrastructure that are fully managed by AWS, built for exclusive use by you or your community, and placed in a location or data center specified by you to help you comply with regulatory requirements. In Dedicated Local Zones, these volumes are purpose-built to store data in a specific data perimeter, helping to support your data isolation and data residency use cases. The latest generation of General Purpose SSD volumes (gp3) enable customers to provision performance independently of storage capacity, providing up to 20% lower price point per GB than existing gp2 volumes. Provisioned IOPS SSD (io1) volumes are designed to meet the needs of I/O-intensive and latency-sensitive transactional workloads like databases. You can manage gp3 and io1 volumes using the AWS Management Console, the AWS Command Line Interface (CLI), or the AWS SDKs. For more information on gp3 and io1 volumes, see the product overview page .",
    "link": "https://aws.amazon.com/about-aws/whats-new/2025/03/amazon-ebs-gp3-io1-volumes-aws-dedicated-local-zones",
    "summary": "이제 AWS 전용 지역 영역에서 Amazon EBS GP3 및 IO1 볼륨을 사용할 수 있습니다. 전용 지역 영역은 AWS가 완전히 관리하고 귀하 또는 귀하의 커뮤니티가 독점적으로 사용하기 위해 구축 된 AWS 인프라 유형이며 규제 요구 사항을 준수 할 수 있도록 귀하가 지정한 위치 또는 데이터 센터에 배치합니다. 전용 지역 영역에서 이러한 볼륨은 데이터를 특정 데이터 주변에 저장하기 위해 목적으로 작성되어 데이터 격리 및 데이터 레지던트 사용 사례를 지원하는 데 도움이됩니다. 최신 세대의 범용 SSD 볼륨 (GP3)을 통해 고객은 저장 용량과 독립적으로 성능을 제공 할 수 있으므로 기존 GP2 볼륨보다 GB 당 최대 20% 저렴한 가격대를 제공합니다. 프로비저닝 된 IOPS SSD (IO1) 볼륨은 데이터베이스와 같은 I/O 집약적 및 대기 시간에 민감한 트랜잭션 워크로드의 요구를 충족하도록 설계되었습니다. AWS 관리 콘솔, AWS 명령 줄 인터페이스 (CLI) 또는 AWS SDK를 사용하여 GP3 및 IO1 볼륨을 관리 할 수 ​​있습니다. GP3 및 IO1 볼륨에 대한 자세한 내용은 제품 개요 페이지를 참조하십시오."
  },
  {
    "source": "AWS",
    "title": "Amazon SageMaker AI is now available in Asia Pacific (Thailand)",
    "date": "2025-03-28",
    "content": "Starting today, you can build, train, and deploy machine learning (ML) models in Asia Pacific (Thailand). Amazon SageMaker AI is a fully managed platform that provides every developer and data scientist with the ability to build, train, and deploy machine learning (ML) models quickly. SageMaker AI removes the heavy lifting from each step of the machine learning process to make it easier to develop high quality models. To learn more and get started, see SageMaker AI documentation and pricing page.",
    "link": "https://aws.amazon.com/about-aws/whats-new/2025/03/amazon-sagemaker-ai-asia-pacific-thailand/",
    "summary": "오늘부터 아시아 태평양 (태국)에서 머신 러닝 (ML) 모델을 구축, 훈련 및 배포 할 수 있습니다. Amazon Sagemaker AI는 모든 개발자와 데이터 과학자에게 머신 러닝 (ML) 모델을 신속하게 구축, 훈련 및 배포 할 수있는 기능을 제공하는 완전히 관리되는 플랫폼입니다. SAGEMAKER AI는 기계 학습 프로세스의 각 단계에서 무거운 리프팅을 제거하여 고품질 모델을보다 쉽게 ​​개발할 수 있습니다. 자세한 내용을 배우고 시작하려면 Sagemaker AI 문서 및 가격 페이지를 참조하십시오."
  },
  {
    "source": "AWS",
    "title": "Amazon SageMaker AI is now available in Mexico (Central)",
    "date": "2025-03-28",
    "content": "Starting today, you can build, train, and deploy machine learning (ML) models in Mexico (Central). Amazon SageMaker AI is a fully managed platform that provides every developer and data scientist with the ability to build, train, and deploy machine learning (ML) models quickly. SageMaker AI removes the heavy lifting from each step of the machine learning process to make it easier to develop high quality models. To learn more and get started, see SageMaker AI documentation and pricing page.",
    "link": "https://aws.amazon.com/about-aws/whats-new/2025/03/amazon-sagemaker-ai-mexico-central/",
    "summary": "오늘부터 멕시코 (Central)에서 머신 러닝 (ML) 모델을 구축, 훈련 및 배포 할 수 있습니다. Amazon Sagemaker AI는 모든 개발자와 데이터 과학자에게 머신 러닝 (ML) 모델을 신속하게 구축, 훈련 및 배포 할 수있는 기능을 제공하는 완전히 관리되는 플랫폼입니다. SAGEMAKER AI는 기계 학습 프로세스의 각 단계에서 무거운 리프팅을 제거하여 고품질 모델을보다 쉽게 ​​개발할 수 있습니다. 자세한 내용을 배우고 시작하려면 Sagemaker AI 문서 및 가격 페이지를 참조하십시오."
  },
  {
    "source": "AWS",
    "title": "Amazon EC2 C8g instances now available in AWS Asia Pacific (Tokyo)",
    "date": "2025-03-28",
    "content": "Starting today, Amazon Elastic Compute Cloud (Amazon EC2) C8g instances are available in AWS Asia Pacific (Tokyo) region. These instances are powered by AWS Graviton4 processors and deliver up to 30% better performance compared to AWS Graviton3-based instances. Amazon EC2 C8g instances are built for compute-intensive workloads, such as high performance computing (HPC), batch processing, gaming, video encoding, scientific modeling, distributed analytics, CPU-based machine learning (ML) inference, and ad serving. These instances are built on the AWS Nitro System , which oﬄoads CPU virtualization, storage, and networking functions to dedicated hardware and software to enhance the performance and security of your workloads. AWS Graviton4-based Amazon EC2 instances deliver the best performance and energy efficiency for a broad range of workloads running on Amazon EC2. These instances offer larger instance sizes with up to 3x more vCPUs and memory compared to Graviton3-based Amazon C7g instances. AWS Graviton4 processors are up to 40% faster for databases, 30% faster for web applications, and 45% faster for large Java applications than AWS Graviton3 processors. C8g instances are available in 12 different instance sizes, including two bare metal sizes. They offer up to 50 Gbps enhanced networking bandwidth and up to 40 Gbps of bandwidth to the Amazon Elastic Block Store (Amazon EBS). To learn more, see Amazon EC2 C8g Instances . To explore how to migrate your workloads to Graviton-based instances, see AWS Graviton Fast Start program and Porting Advisor for Graviton . To get started, see the AWS Management Console .",
    "link": "https://aws.amazon.com/about-aws/whats-new/2025/03/amazon-ec2-c8g-asia-pacific-tokyo/",
    "summary": "오늘부터 Amazon Elastic Compute Cloud (Amazon EC2) C8G 인스턴스는 AWS Asia Pacific (Tokyo) 지역에서 제공됩니다. 이러한 인스턴스는 AWS Graviton4 프로세서로 구동되며 AWS Graviton3 기반 인스턴스에 비해 최대 30% 더 나은 성능을 제공합니다. Amazon EC2 C8G 인스턴스는 고성능 컴퓨팅 (HPC), 배치 프로세스, 게임, 비디오 인코딩, 과학 모델링, 분산 분석, CPU 기반 기계 학습 (ML) 추론과 같은 컴퓨팅 집약적 인 워크로드를 위해 구축되었습니다. 이러한 인스턴스는 CPU 가상화, 스토리지 및 네트워킹 기능을 전용 하드웨어 및 소프트웨어에 사용하여 작업 부하의 성능 및 보안을 향상시키는 AWS Nitro 시스템을 기반으로합니다. AWS Graviton4 기반 Amazon EC2 인스턴스는 Amazon EC2에서 실행되는 광범위한 워크로드에 대한 최상의 성능 및 에너지 효율을 제공합니다. 이 인스턴스는 Graviton3 기반 Amazon C7G 인스턴스에 비해 최대 3 배 더 많은 VCPU 및 메모리를 가진 더 큰 인스턴스 크기를 제공합니다. AWS Graviton4 프로세서는 데이터베이스의 경우 최대 40% 더 빠르고 웹 응용 프로그램의 경우 30% 빠르며 AWS Graviton3 프로세서보다 대형 Java 응용 프로그램의 경우 45% 빠릅니다. C8G 인스턴스는 두 가지 베어 메탈 크기를 포함하여 12 가지 인스턴스 크기로 제공됩니다. Amazon Elastic Block Store (Amazon EBS)에 최대 50 개의 GBPS 강화 네트워킹 대역폭과 최대 40Gbps 대역폭을 제공합니다. 자세한 내용은 Amazon EC2 C8G 인스턴스를 참조하십시오. 작업량을 Graviton 기반 인스턴스로 마이그레이션하는 방법을 살펴 보려면 AWS Graviton Fast Start Program 및 Graviton 용 고문을 참조하십시오. 시작하려면 AWS 관리 콘솔을 참조하십시오."
  },
  {
    "source": "AWS",
    "title": "Amazon EC2 R8g instances now available in AWS US West (N. California)",
    "date": "2025-03-28",
    "content": "Starting today, Amazon Elastic Compute Cloud (Amazon EC2) R8g instances are available in AWS US West (N. California) region. These instances are powered by AWS Graviton4 processors and deliver up to 30% better performance compared to AWS Graviton3-based instances. Amazon EC2 R8g instances are ideal for memory-intensive workloads such as databases, in-memory caches, and real-time big data analytics. These instances are built on the AWS Nitro System , which oﬄoads CPU virtualization, storage, and networking functions to dedicated hardware and software to enhance the performance and security of your workloads. AWS Graviton4-based Amazon EC2 instances deliver the best performance and energy efficiency for a broad range of workloads running on Amazon EC2. AWS Graviton4-based R8g instances offer larger instance sizes with up to 3x more vCPU (up to 48xlarge) and memory (up to 1.5TB) than Graviton3-based R7g instances. These instances are up to 30% faster for web applications, 40% faster for databases, and 45% faster for large Java applications compared to AWS Graviton3-based R7g instances. R8g instances are available in 12 different instance sizes, including two bare metal sizes. They offer up to 50 Gbps enhanced networking bandwidth and up to 40 Gbps of bandwidth to the Amazon Elastic Block Store (Amazon EBS). To learn more, see Amazon EC2 R8g Instances . To explore how to migrate your workloads to Graviton-based instances, see AWS Graviton Fast Start program and Porting Advisor for Graviton . To get started, see the AWS Management Console .",
    "link": "https://aws.amazon.com/about-aws/whats-new/2025/03/amazon-ec2-r8g-instances-us-west-n-california/",
    "summary": "오늘부터 Amazon Elastic Compute Cloud (Amazon EC2) R8G 인스턴스는 AWS US West (N. California) 지역에서 제공됩니다. 이러한 인스턴스는 AWS Graviton4 프로세서로 구동되며 AWS Graviton3 기반 인스턴스에 비해 최대 30% 더 나은 성능을 제공합니다. Amazon EC2 R8G 인스턴스는 데이터베이스, 메모리 인 캐시 및 실시간 빅 데이터 분석과 같은 메모리 집약적 인 워크로드에 이상적입니다. 이러한 인스턴스는 CPU 가상화, 스토리지 및 네트워킹 기능을 전용 하드웨어 및 소프트웨어에 사용하여 작업 부하의 성능 및 보안을 향상시키는 AWS Nitro 시스템을 기반으로합니다. AWS Graviton4 기반 Amazon EC2 인스턴스는 Amazon EC2에서 실행되는 광범위한 워크로드에 대한 최상의 성능 및 에너지 효율을 제공합니다. AWS Graviton4 기반 R8G 인스턴스는 Graviton3 기반 R7G 인스턴스보다 최대 3 배 더 많은 VCPU (최대 48xlarge) 및 메모리 (최대 1.5TB)의 더 큰 인스턴스 크기를 제공합니다. 이러한 인스턴스는 웹 애플리케이션의 경우 최대 30% 더 빠르고 데이터베이스의 경우 40% 빠르며 AWS Graviton3 기반 R7G 인스턴스에 비해 대형 Java 응용 프로그램의 경우 45% 빠릅니다. R8G 인스턴스는 두 가지 베어 메탈 크기를 포함하여 12 가지 인스턴스 크기로 제공됩니다. Amazon Elastic Block Store (Amazon EBS)에 최대 50 개의 GBPS 강화 네트워킹 대역폭과 최대 40Gbps 대역폭을 제공합니다. 자세한 내용은 Amazon EC2 R8G 인스턴스를 참조하십시오. 작업량을 Graviton 기반 인스턴스로 마이그레이션하는 방법을 살펴 보려면 AWS Graviton Fast Start Program 및 Graviton 용 고문을 참조하십시오. 시작하려면 AWS 관리 콘솔을 참조하십시오."
  },
  {
    "source": "AWS",
    "title": "AWS Lambda adds support for Ruby 3.4",
    "date": "2025-03-27",
    "content": "AWS Lambda now supports creating serverless applications using Ruby 3.4. Developers can use Ruby 3.4 as both a managed runtime and a container base image, and AWS will automatically apply updates to the managed runtime and base image as they become available. Ruby 3.4 is the latest long-term support (LTS) release of Ruby and is expected to be supported for security and bug fixes until March 2028. In addition to providing access to the latest Ruby language features, the Lambda Runtime for Ruby 3.4 uses an updated runtime interface client, the package used to integrate your function code with the Lambda service. This updated client has been released as open source on Github . Customers building custom container images can also consume this updated package from RubyGems . The Ruby 3.4 runtime is available in all AWS Regions, including China and the AWS GovCloud (US) Regions. You can use the full range of AWS deployment tools, including the Lambda console, AWS CLI, AWS Serverless Application Model (AWS SAM), CDK, and AWS CloudFormation to deploy and manage serverless applications written in Ruby 3.4. For more information on using Ruby 3.4 in Lambda, see our documentation . For more information about AWS Lambda, visit our product page .",
    "link": "https://aws.amazon.com/about-aws/whats-new/2025/03/aws-lambda-support-ruby-3-4",
    "summary": "AWS Lambda는 이제 Ruby 3.4를 사용하여 서버리스 응용 프로그램 작성을 지원합니다. 개발자는 Ruby 3.4를 관리 런타임과 컨테이너 기본 이미지로 사용할 수 있으며 AWS는 관리되는 런타임 및 기본 이미지에 대한 업데이트를 자동으로 적용 할 수 있습니다. Ruby 3.4는 Ruby의 최신 장기 지원 (LTS) 릴리스이며 2028 년 3 월까지 보안 및 버그 수정을 지원할 것으로 예상됩니다. 최신 Ruby 언어 기능에 대한 액세스를 제공하는 것 외에도 Ruby 3.4의 Lambda 런타임은 업데이트 된 런타임 인터페이스 클라이언트 인 Lambda 서비스와 통합하는 데 사용되는 패키지를 사용합니다. 이 업데이트 된 클라이언트는 Github에서 오픈 소스로 출시되었습니다. 맞춤형 컨테이너 이미지를 구축하는 고객은 Rubygems 에서이 업데이트 된 패키지를 소비 할 수도 있습니다. Ruby 3.4 런타임은 중국 및 AWS Govcloud (미국) 지역을 포함한 모든 AWS 지역에서 제공됩니다. Lambda Console, AWS CLI, AWS Serverless Application Model (AWS SAM), CDK 및 AWS CloudFormation을 포함한 모든 AWS 배포 도구를 사용하여 Ruby 3.4로 작성된 서버리스 응용 프로그램을 배포하고 관리 할 수 ​​있습니다. Lambda에서 Ruby 3.4 사용에 대한 자세한 내용은 문서를 참조하십시오. AWS Lambda에 대한 자세한 내용은 제품 페이지를 방문하십시오."
  },
  {
    "source": "AWS",
    "title": "Amazon GameLift Servers expands instance support with next-generation EC2 instance families",
    "date": "2025-03-27",
    "content": "Amazon GameLift Servers now supports Amazon EC2 5th through 8th generation instances, offering enhanced price-performance, efficiency, and flexibility for game server hosting. This update allows developers to leverage the latest advancements in EC2 compute, memory, and networking across three main instance families: General Purpose (M-series): Balanced CPU, memory, and networking for a wide range of game workloads. Compute Optimized (C-series): High-performance compute instances with a 2:1 memory ratio, ideal for CPU-intensive game servers. Memory Optimized (R-Series): Optimized for high-memory workloads with an 8:1 memory ratio, supporting complex simulations and large player sessions. Each new EC2 generation brings significant improvements: 5th Gen: Proven reliability with Intel processors with balanced performance 6th Gen: Includes AWS Graviton2 ARM-based options alongside Intel and AMD variants offering enhanced price-performance efficiency. 7th Gen: The latest evolution featuring DDR5 memory, enhanced networking, and offering significant performance gains over previous generations. 8th Gen: Cutting-edge AWS Graviton4 and Intel Xeon-based instances for demanding workloads Customers can also choose variants with local storage (d), enhanced networking (n), and different processor architectures (Intel, AMD, Graviton – i/a/g). This update empowers developers with greater flexibility, scalability, and cost efficiency to optimize game server performance. Customers can now seamlessly transition workloads to newer EC2 generations, leveraging AWS's continuous innovation for building, scaling, and operating multiplayer games globally. These next-generation instances are available in Amazon GameLift Servers supported regions, except AWS China. For more information on launching fleets with next-generation EC2 instances, visit the Amazon GameLift Servers documentation and EC2 Instance Types overview .",
    "link": "https://aws.amazon.com/about-aws/whats-new/2025/03/amazon-gamelift-servers-expands-instance-support",
    "summary": "Amazon Gamelift 서버는 이제 Amazon EC2 5 ~ 8 세대 인스턴스를 지원하여 게임 서버 호스팅을위한 성능 향상, 효율성 및 유연성을 제공합니다. 이 업데이트를 통해 개발자는 EC2 컴퓨팅, 메모리 및 네트워킹의 최신 발전을 세 가지 주요 인스턴스 패밀리 (M-Series)에서 균형 잡힌 CPU, 메모리 및 광범위한 게임 워크로드를위한 네트워킹을 활용할 수 있습니다. Compute Optimized (C-Series) : 2 : 1 메모리 비율의 고성능 컴퓨팅 인스턴스, CPU 집약적 인 게임 서버에 이상적입니다. 메모리 최적화 (R-Series) : 8 : 1 메모리 비율의 고 메모리 워크로드, 복잡한 시뮬레이션 및 대형 플레이어 세션을 지원합니다. 각각의 새로운 EC2 세대는 상당한 개선 사항을 제공합니다. 5 세대 : 균형 잡힌 성능을 가진 인텔 프로세서와의 입증 된 신뢰성 6 세대 : AWS Graviton2 ARM 기반 옵션과 AMD 변형이 강화 된 가격 성능 효율성을 제공합니다. 7 세대 : DDR5 메모리, 향상된 네트워킹 및 이전 세대에 비해 상당한 성능을 제공하는 최신 진화. 8 세대 : 최첨단 AWS Graviton4 및 Intel Xeon 기반 인스턴스가 필요합니다. 고객은 로컬 스토리지 (D), 향상된 네트워킹 (N) 및 다양한 프로세서 아키텍처 (Intel, AMD, Graviton-I/A/G)가있는 변형을 선택할 수 있습니다. 이 업데이트는 개발자가 유연성, 확장 성 및 비용 효율성을 높이기 위해 게임 서버 성능을 최적화 할 수 있습니다. 고객은 이제 Workload를 새로운 EC2 세대로 원활하게 전환하여 AWS의 지속적인 혁신을 전 세계적으로 구축, 스케일링 및 운영하는 혁신을 활용할 수 있습니다. 이러한 차세대 인스턴스는 AWS 중국을 제외한 Amazon Gamelift 서버 지원 지역에서 제공됩니다. 차세대 EC2 인스턴스가있는 차량 출시에 대한 자세한 내용은 Amazon Gamelift 서버 문서 및 EC2 인스턴스 유형 개요를 방문하십시오."
  },
  {
    "source": "AWS",
    "title": "AWS Network Manager and AWS Cloud WAN now support AWS PrivateLink and IPv6",
    "date": "2025-03-27",
    "content": "AWS Network Manager and AWS Cloud WAN now support AWS PrivateLink and IPv6 based connectivity to the management endpoint of these services. Using PrivateLink, customers can now access AWS Network Manager or AWS Cloud WAN privately on the AWS network, without going through the public Internet. Additionally, customers can now access these services over IPv6 using dual-stack endpoints. With AWS Cloud WAN, you can use a central dashboard and network policies to create a global network that spans multiple locations and networks, allowing you to configure and manage different networks using the same technology. The Cloud WAN central dashboard, powered by AWS Network Manager, generates a complete view of the network to help you monitor network health, security, and performance. AWS Network Manager reduces the operational complexity of managing global networks across AWS and on-premises locations. Previously, you could access AWS Cloud WAN and AWS Network Manager using public IPv4 endpoints only. With this launch, you can now access these services’ APIs/CLI privately, without going through the public Internet. Additionally, these services now support IPv6 endpoints. To learn more about AWS Network Manager, refer documentation , and for AWS Cloud WAN, refer documentation .",
    "link": "https://aws.amazon.com/about-aws/whats-new/2025/03/aws-network-manager-cloud-wan-privatelink-ipv6",
    "summary": "AWS Network Manager 및 AWS Cloud WAN은 이제 AWS Privatelink 및 IPv6 기반이 서비스의 관리 엔드 포인트에 대한 연결을 지원합니다. PrivateLink를 사용하여 고객은 공개 인터넷을 통과하지 않고 AWS 네트워크에서 AWS 네트워크 관리자 또는 AWS Cloud WAN에 개인적으로 액세스 할 수 있습니다. 또한 고객은 이제 듀얼 스택 엔드 포인트를 사용하여 IPv6을 통해 이러한 서비스에 액세스 할 수 있습니다. AWS Cloud WAN을 사용하면 중앙 대시 보드 및 네트워크 정책을 사용하여 여러 위치 및 네트워크에 걸쳐있는 글로벌 네트워크를 만들어 동일한 기술을 사용하여 다양한 네트워크를 구성하고 관리 할 수 ​​있습니다. AWS Network Manager가 구동하는 Cloud WAN Central Dashboard는 네트워크 건강, 보안 및 성능을 모니터링 할 수 있도록 네트워크를 완전히 볼 수 있습니다. AWS Network Manager는 AWS 및 온 프레미스 위치에서 글로벌 네트워크를 관리하는 운영 복잡성을 줄입니다. 이전에는 공개 IPv4 엔드 포인트 만 사용하여 AWS Cloud WAN 및 AWS 네트워크 관리자에 액세스 할 수 있습니다. 이번 출시를 통해 공개 인터넷을 통과하지 않고도 이러한 서비스의 API/CLI에 개인적으로 액세스 할 수 있습니다. 또한이 서비스는 이제 IPv6 엔드 포인트를 지원합니다. AWS 네트워크 관리자에 대한 자세한 내용은 문서를 참조하고 AWS Cloud WAN을 참조하십시오. 문서를 참조하십시오."
  },
  {
    "source": "AWS",
    "title": "AWS Network Firewall adds pass action rule alerts and JA4 filtering",
    "date": "2025-03-27",
    "content": "Today, AWS announces new features for AWS Network Firewall: The ability to generate alerts on traffic that matches pass action rules and JA4 fingerprinting support in firewall rules. AWS Network Firewall is a stateful, managed, network firewall and intrusion detection and prevention service for your virtual private cloud (VPC). These new capabilities enhance the security and visibility of your network traffic, allowing for more granular control and improved threat detection. The ability to generate alert log events on traffic that matches pass action rules provides enhanced visibility into your network traffic without a need to add an alert action rule before the pass action rule. This can help you detect anomalies or potential security issues in traffic that would otherwise be permitted without additional scrutiny. JA4 filtering rules enables AWS Network Firewall to analyze network traffic based on JA4 fingerprints, which are used to identify client and server applications. This feature allows for more precise traffic identification and control, helping you to better secure your network against potential threats. Pass action rule alert and JA4 filtering rules are available in all AWS Regions where AWS Network Firewall is offered. To see which regions AWS Network Firewall is available in, visit the AWS Region Table . To learn more about these new features and how to implement them in your AWS Network Firewall setup, visit the AWS Network Firewall documentation . You can start using these new capabilities today to enhance your network security posture and gain deeper insights into your VPC traffic patterns.",
    "link": "https://aws.amazon.com/about-aws/whats-new/2025/03/aws-network-firewall-pass-action-rule-alerts-ja4-filtering",
    "summary": "오늘 AWS는 AWS 네트워크 방화벽 : 패스 액션 규칙과 방화벽 규칙의 JA4 지문 지원과 일치하는 트래픽에 대한 경고를 생성하는 기능을 발표합니다. AWS 네트워크 방화벽은 가상 프라이빗 클라우드 (VPC)를위한 상태가 풍부하고 관리되는 네트워크 방화벽 및 침입 탐지 및 예방 서비스입니다. 이러한 새로운 기능은 네트워크 트래픽의 보안 및 가시성을 향상시켜보다 세분화 된 제어와 위협 감지를 개선 할 수 있습니다. 패스 조치 규칙과 일치하는 트래픽에서 경보 로그 이벤트를 생성하는 기능은 패스 조치 규칙 전에 경보 조치 규칙을 추가 할 필요없이 네트워크 트래픽에 대한 가시성을 향상시킵니다. 이를 통해 추가 조사없이 허용되는 트래픽의 이상 또는 잠재적 보안 문제를 감지하는 데 도움이됩니다. JA4 필터링 규칙을 통해 AWS 네트워크 방화벽은 클라이언트 및 서버 응용 프로그램을 식별하는 데 사용되는 JA4 지문을 기반으로 네트워크 트래픽을 분석 할 수 있습니다. 이 기능을 통해보다 정확한 트래픽 식별 및 제어를 가능하게하여 잠재적 인 위협에 대해 네트워크를 더 잘 보호 할 수 있습니다. Pass Action Rule Alert 및 JA4 필터링 규칙은 AWS 네트워크 방화벽이 제공되는 모든 AWS 지역에서 제공됩니다. AWS 네트워크 방화벽이 어떤 지역에 있는지 확인하려면 AWS 지역 테이블을 방문하십시오. 이러한 새로운 기능과 AWS 네트워크 방화벽 설정에서 구현하는 방법에 대한 자세한 내용은 AWS 네트워크 방화벽 문서를 방문하십시오. 오늘이 새로운 기능을 사용하여 네트워크 보안 자세를 향상시키고 VPC 트래픽 패턴에 대한 더 깊은 통찰력을 얻을 수 있습니다."
  },
  {
    "source": "AWS",
    "title": "AWS Marketplace introduces new seller experiences for Machine Learning products",
    "date": "2025-03-27",
    "content": "Today, we are excited to announce a set of improvements to the seller management experience for Machine Learning (ML) products in AWS Marketplace. Sellers can now quickly publish and update ML listings with a new self-service experience in the AWS Marketplace Management Portal. Additionally, sellers can now create, view, and manage private offers for ML products through a guided step-by-step process in the AWS Marketplace Management Portal, making it easier for them to extend custom pricing terms to their customers. To help improve operational efficiency, sellers can now utilize AWS Marketplace Catalog APIs to automate creating and updating ML product listings and private offers. These three features help streamline the process of listing and managing ML products in AWS Marketplace, offering a more seamless experience for ML sellers and enabling them to bring their innovative ML solutions to customers faster and more efficiently. With the new self-service experience, sellers can perform all listing creation and management actions and publish private offers in minutes, all without requiring help from AWS Marketplace support. With access to APIs, ML sellers can automate their listing creation and update processes by integrating directly with AWS Marketplace from within their model publishing pipelines. To get started, visit the Machine Learning product page in the AWS Marketplace Management Portal. To learn more, access the AWS Marketplace Seller Guide .",
    "link": "https://aws.amazon.com/about-aws/whats-new/2025/03/aws-marketplace-seller-experiences-machine-learning-products/",
    "summary": "오늘날 AWS 마켓 플레이스의 ML (Machine Learning) 제품 판매자 관리 경험 (ML) 제품에 대한 일련의 개선을 발표하게되어 기쁩니다. 판매자는 이제 AWS Marketplace Management Portal에서 새로운 셀프 서비스 경험으로 ML 목록을 신속하게 게시하고 업데이트 할 수 있습니다. 또한 판매자는 이제 AWS Marketplace Management Portal의 가이드 단계별 프로세스를 통해 ML 제품에 대한 개인 제안을 만들고보고 및 관리 할 수 ​​있으므로 고객에게 사용자 정의 가격 용어를보다 쉽게 ​​확장 할 수 있습니다. 운영 효율성을 향상시키기 위해 판매자는 이제 AWS Marketplace Catalog API를 활용하여 ML 제품 목록 및 개인 제안 작성 및 업데이트를 자동화 할 수 있습니다. 이 세 가지 기능은 AWS 마켓 플레이스에서 ML 제품을 목록 및 관리하는 프로세스를 간소화하여 ML 판매자에게보다 완벽한 경험을 제공하고 고객에게 더 빠르고 효율적으로 혁신적인 ML 솔루션을 제공 할 수 있습니다. 새로운 셀프 서비스 경험을 통해 판매자는 AWS Marketplace 지원의 도움을 필요없이 모든 상장 제작 및 관리 작업을 수행하고 개인 제안을 몇 분 안에 게시 할 수 있습니다. API에 액세스하면 ML 판매자는 모델 게시 파이프 라인 내에서 AWS Marketplace와 직접 통합하여 목록 작성 및 업데이트 프로세스를 자동화 할 수 있습니다. 시작하려면 AWS Marketplace Management Portal의 기계 학습 제품 페이지를 방문하십시오. 자세한 내용은 AWS Marketplace 판매자 가이드에 액세스하십시오."
  },
  {
    "source": "AWS",
    "title": "Amazon Bedrock Knowledge Bases now supports Amazon OpenSearch Managed Cluster for vector storage",
    "date": "2025-03-27",
    "content": "We are announcing the support of Amazon OpenSearch Managed cluster as a vector store in Amazon Bedrock Knowledge Bases. Amazon Bedrock Knowledge Bases securely connects foundation models (FMs) to internal company data sources for Retrieval Augmented Generation (RAG), to deliver more relevant and accurate responses. Amazon Bedrock Knowledge Bases’ native integration with vector databases allows you to mitigate the need to build custom data source integrations. With this launch, you can use OpenSearch managed cluster as the vector database to take advantage of the suite of features available in Bedrock Knowledge Bases. This integration adds to the list of vector databases supported by Bedrock Knowledge Bases, including Amazon OpenSearch Serverless, Amazon Aurora, Amazon Neptune Analytics, Pinecone, MongoDB Atlas, and Redis. The OpenSearch Managed cluster integration for Amazon Bedrock Knowledge Bases is now generally available in all existing Amazon Bedrock Knowledge Base and OpenSearch service regions. To learn more, refer to the Knowledge Bases documentation.",
    "link": "https://aws.amazon.com/about-aws/whats-new/2025/03/amazon-bedrock-knowledge-bases-opensearch-cluster-vector-storage/",
    "summary": "우리는 Amazon Bedrock Knowledge Base의 벡터 매장으로 Amazon OpenSearch Managed Cluster의 지원을 발표하고 있습니다. Amazon Bedrock Knowledge Base는보다 관련성 있고 정확한 응답을 제공하기 위해 검색 증강 생성 (RAG)을 위해 FMS (Foundation Model)를 내부 회사 데이터 소스에 단단히 연결합니다. Amazon Bedrock Knowledge Base의 벡터 데이터베이스와의 기본 통합을 통해 사용자 정의 데이터 소스 통합을 구축 할 필요성을 완화 할 수 있습니다. 이 출시를 통해 OpenSearch Managed Cluster를 벡터 데이터베이스로 사용하여 기반암 지식 기반에서 사용할 수있는 기능을 활용할 수 있습니다. 이 통합은 Amazon OpenSearch Serverless, Amazon Aurora, Amazon Neptune Analytics, Pinecone, MongoDB Atlas 및 Redis를 포함하여 Bedrock Knowledge Base에서 지원하는 벡터 데이터베이스 목록에 추가됩니다. Amazon Bedrock Knowledge Bases 용 OpenSearch Managed Cluster 통합은 일반적으로 기존의 모든 Amazon Bedrock Knowledge Base 및 OpenSearch Service Region에서 사용할 수 있습니다. 자세한 내용은 지식 기반 문서를 참조하십시오."
  },
  {
    "source": "AWS",
    "title": "Amazon EKS now enforces upgrade insights checks as part of cluster upgrades",
    "date": "2025-03-27",
    "content": "Today, Amazon Elastic Kubernetes Service (EKS) announced a new control to prevent accidental cluster upgrades when issues are already detected that may impact application compatibility with the next Kubernetes version. This feature leverages EKS upgrade insights and is significant step towards giving cluster administrators confidence with Kubernetes version upgrades. EKS upgrade insights automatically scan clusters against a list of potential Kubernetes version upgrade impacting issues such as deprecated Kubernetes API usage. EKS periodically updates the list of insight checks to perform, based on evaluations of changes in the Kubernetes project, as well as changes introduced in the EKS service along with new versions. With this new control, EKS will prevent you from upgrading the EKS clusters if there are any Kubernetes version upgrade impacting issues surfaced by EKS upgrade insights. Once the upgrade impacting issues are resolved, you will be able to upgrade the Kubernetes version of your cluster. EKS has also introduced an override flag which you can use to bypass upgrade insights checks on upgrades, which can useful for example in dev environments. This feature is available in all AWS Regions, except the AWS GovCloud (US) Regions. To learn more visit the EKS documentation .",
    "link": "https://aws.amazon.com/about-aws/whats-new/2025/03/amazon-eks-enforces-upgrade-insights-check-cluster-upgrades",
    "summary": "오늘 Amazon Elastic Kubernetes Service (EKS)는 다음 Kubernetes 버전과의 응용 프로그램 호환성에 영향을 줄 수있는 문제가 이미 감지 될 때 우발적 인 클러스터 업그레이드를 방지하기위한 새로운 컨트롤을 발표했습니다. 이 기능은 EKS 업그레이드 통찰력을 활용하며 클러스터 관리자에게 Kubernetes 버전 업그레이드에 대한 신뢰를 제공하는 중요한 단계입니다. EKS 업그레이드 Insights는 감가 상각 된 Kubernetes API 사용과 같은 문제에 영향을 미치는 잠재적 Kubernetes 버전 업그레이드 목록에 대해 클러스터를 자동으로 스캔합니다. EKS는 Kubernetes 프로젝트의 변경 평가와 새로운 버전과 함께 EKS 서비스에 도입 된 변경 사항을 기반으로 수행 할 통찰력 검사 목록을 정기적으로 업데이트합니다. 이 새로운 제어를 통해 EKS는 EKS 업그레이드 통찰력으로 표시된 Kubernetes 버전 업그레이드 문제가 있으면 EKS 클러스터를 업그레이드하지 못하게합니다. 업그레이드 영향 문제가 해결되면 클러스터의 Kubernetes 버전을 업그레이드 할 수 있습니다. EKS는 또한 업그레이드에 대한 Insights Checks를 우회하는 데 사용할 수있는 Override 플래그를 도입했습니다. 예를 들어 DEV 환경에서 유용 할 수 있습니다. 이 기능은 AWS Govcloud (US) 지역을 제외한 모든 AWS 지역에서 제공됩니다. 자세한 내용은 EKS 문서를 방문하십시오."
  },
  {
    "source": "AWS",
    "title": "Amazon EC2 P5en instances are now available in US East (N. Virginia) and Asia Pacific (Jakarta)",
    "date": "2025-03-27",
    "content": "Starting today, Amazon Elastic Compute Cloud (Amazon EC2) P5en instances powered by NVIDIA H200 GPUs are available in US East (N. Virginia) and Asia Pacific (Jakarta) regions. These instances are optimized for generative AI and high performance computing (HPC) applications. P5en instances feature 8 H200 GPUs which have 1.7x GPU memory size and 1.4x GPU memory bandwidth than H100 GPUs featured in P5 instances. P5en instances pair the H200 GPUs with high performance custom 4 th Generation Intel Xeon Scalable processors, enabling Gen5 PCIe between CPU and GPU which provides up to 4x the bandwidth between CPU and GPU and boosts AI training and inference performance. P5en, with up to 3200 Gbps of third generation of EFA using Nitro v5, shows up to 35% improvement in latency compared to P5 that uses the previous generation of EFA and Nitro. This helps improve collective communications performance for distributed training workloads such as deep learning, generative AI, real-time data processing, and high-performance computing (HPC) applications. To address customer needs for large scale at low latency, P5en instances are deployed in Amazon EC2 UltraClusters, and provide market-leading scale-out capabilities for distributed training and tightly coupled HPC workloads. With these additional regions, P5en instances are now available in the US East (N. Virginia, Ohio), US West (Oregon), Europe (Spain) and Asia Pacific (Jakarta, Mumbai, Seoul, Tokyo and Seoul) AWS Regions and US East (Atlanta) Local Zone us-east-1-atl-2a in the p5en.48xlarge size. To learn more about P5en instances, see Amazon EC2 P5en Instances .",
    "link": "https://aws.amazon.com/about-aws/whats-new/2025/03/amazon-ec2-p5en-instances-n-virginia-jakarta/",
    "summary": "오늘부터 NVIDIA H200 GPU가 구동하는 Amazon Elastic Compute Cloud (Amazon EC2) P5EN 인스턴스는 미국 동부 (N. Virginia) 및 Asia Pacific (Jakarta) 지역에서 제공됩니다. 이러한 인스턴스는 생성 AI 및 고성능 컴퓨팅 (HPC) 애플리케이션에 최적화됩니다. P5EN 인스턴스는 P5 인스턴스에 등장한 H100 GPU보다 1.7 배 GPU 메모리 크기와 1.4 배의 GPU 메모리 대역폭을 갖는 8 H200 GPU를 특징으로합니다. P5EN 인스턴스는 H200 GPU를 고성능 커스텀 4 TH 세대 Intel Xeon 확장 가능한 프로세서와 짝을 이루어 CPU와 GPU 사이의 Gen5 PCIE를 가능하게하며 CPU와 GPU 사이의 대역폭을 최대 4 배, AI 교육 및 추론 성능을 향상시킵니다. Nitro V5를 사용하여 최대 3200Gbps의 3 세대 EFA의 P5EN은 이전 세대의 EFA 및 Nitro를 사용하는 P5에 비해 대기 시간이 최대 35% 향상됩니다. 이를 통해 딥 러닝, 생성 AI, 실시간 데이터 처리 및 고성능 컴퓨팅 (HPC) 애플리케이션과 같은 분산 교육 워크로드의 집단 커뮤니케이션 성능을 향상시킵니다. 낮은 대기 시간에서 대규모에 대한 고객 요구를 해결하기 위해 P5EN 인스턴스는 Amazon EC2 Ultraclusters에 배포되며 분산 교육 및 엄격하게 결합 된 HPC 워크로드를위한 시장 최고의 스케일 아웃 기능을 제공합니다. 이러한 추가 지역을 통해 P5EN 인스턴스는 현재 미국 동부 (오하이오 주 N. 버지니아), 미국 서부 (오레곤), 유럽 (스페인) 및 아시아 태평양 (자카르타, 뭄바이, 서울, 도쿄 및 서울) AWS 지역 및 미국 동부 지역 US-1-ATL-2A에서 P5EN.48XLARGE 크기로 제공됩니다. P5EN 인스턴스에 대한 자세한 내용은 Amazon EC2 P5EN 인스턴스를 참조하십시오."
  },
  {
    "source": "AWS",
    "title": "Announcing 3 new features on Connected Mobility Solution on AWS",
    "date": "2025-03-27",
    "content": "Today AWS announced role-based access control, multi-account and multi-region support, and Fleet Management Portal (Preview) for the Connected Mobility Solution (CMS) on AWS. Role-based access control enables customers to manage and restrict access to developer portal of CMS based on security roles assigned to users. In addition, customers can use CMS to deploy AWS and partner provided software components in multiple accounts and multiple regions based on customer’s organization structure and various lifecycle stage of the features. Lastly, customers can use the CMS Fleet Management Portal to visualize fleet data collected using AWS IoT FleetWise, making it easier to assemble a holistic view of fleet events, and easily integrate and visualize AWS and AWS partner provided software components. You can restrict access to CMS’s developer portal by defining roles and permissions with appropriate level of access within your organization, ensuring access is granted to users based on the ‘principle of least privilege’ to reduce security risks. You can easily deploy AWS and AWS partner provided connected mobility software components across multiple accounts and regions to enable alignment with your organizational requirements and enhance scalability and resilience. You can accelerate the build of your fleet management solution, visualize consolidated fleet data, and quickly integrate insights and analytics solutions provided by AWS and connected mobility partners using the CMS-provided API Gateway and Smithy Framework. CMS is available in the following AWS regions: Asia-Pacific (Tokyo, Sydney), Europe (Frankfurt, Ireland), US-East (N.Virginia, Ohio), US-West (Oregon). Visit CMS on AWS Product Page to learn more.",
    "link": "https://aws.amazon.com/about-aws/whats-new/2025/03/3-new-features-connected-mobility-solution/",
    "summary": "오늘 AWS는 AWS의 연결된 이동성 솔루션 (CMS)을위한 역할 기반 액세스 제어, 멀티 카운트 및 다중 지역 지원 및 Fleet Management Portal (미리보기)을 발표했습니다. 역할 기반 액세스 컨트롤을 통해 고객은 사용자에게 할당 된 보안 역할을 기반으로 CMS의 개발자 포털에 대한 액세스를 관리하고 제한 할 수 있습니다. 또한 고객은 CMS를 사용하여 고객의 조직 구조 및 다양한 수명주기 단계를 기반으로 여러 계정 및 여러 지역의 AWS 및 파트너 제공 소프트웨어 구성 요소를 배포 할 수 있습니다. 마지막으로 고객은 CMS Fleet Management Portal을 사용하여 AWS IoT Fleetwise를 사용하여 수집 된 차량 데이터를 시각화하여 차량 이벤트의 전체적인 관점을보다 쉽게 ​​조립하고 AWS 및 AWS 파트너가 제공 한 소프트웨어 구성 요소를 쉽게 통합하고 시각화 할 수 있습니다. 조직 내에서 적절한 수준의 액세스 수준으로 역할 및 권한을 정의하여 CMS 개발자 포털에 대한 액세스를 제한하여 보안 위험을 줄이기 위해 '최소 특권의 원칙'을 기반으로 사용자에게 액세스 권한을 부여 할 수 있습니다. 여러 계정 및 지역에서 연결된 이동성 소프트웨어 구성 요소를 제공 한 AWS 및 AWS 파트너를 쉽게 배포하여 조직 요구 사항과 조정하고 확장 성 및 탄력성을 향상시킬 수 있습니다. 차량 관리 솔루션의 빌드를 가속화하고, 통합 차량 데이터를 시각화하며, CMS 제공 API 게이트웨이 및 Smithy 프레임 워크를 사용하여 AWS 및 Connected Mobility Partners가 제공하는 통찰력 및 분석 솔루션을 신속하게 통합 할 수 있습니다. CMS는 Asia-Pacific (도쿄, 시드니), 유럽 (프랑크푸르트, 아일랜드), US-East (N.Virginia, Ohio), US- WEST (Oregon)와 같은 AWS 지역에서 구입할 수 있습니다. AWS 제품 페이지의 CMS를 방문하여 자세한 내용을 알아보십시오."
  },
  {
    "source": "AWS",
    "title": "Amazon DynamoDB now supports percentile statistics for request latency",
    "date": "2025-03-27",
    "content": "Amazon DynamoDB now supports percentile statistics for the SuccessfulRequestLatency Amazon CloudWatch metric. The percentile statistic enables you to understand the latency distribution of your successful requests to DynamoDB, complementing the existing average, minimum, and maximum statistics. The SuccessfulRequestLatency metric only measures latency which is internal to the Amazon DynamoDB service - client side activity and network trip times are not included. It’s normal to see some variability in this metric. When analyzing your latency, it’s best to consider your end-to-end latency which includes client side activity. To factor in your client side activity, you can enable latency metric logging in your AWS SDK. The new percentile statistic is available in all commercial AWS Regions, the AWS GovCloud (US) Regions, and the China Regions. To learn more about the percentile statistic and troubleshooting latency on DynamoDB, see the following: DynamoDB Metrics and Dimensions in the DynamoDB Developer Guide Troubleshooting latency issues in Amazon DynamoDB in the DynamoDB Developer Guide",
    "link": "https://aws.amazon.com/about-aws/whats-new/2025/03/amazon-dynamodb-percentile-statistics-request-latency/",
    "summary": "Amazon DynamoDB는 이제 성공적인 요청 Amazon CloudWatch Metric의 백분위 수 통계를 지원합니다. 백분위 수 통계를 통해 DynamODB에 대한 성공적인 요청의 대기 시간 분포를 이해하여 기존 평균, 최소 및 최대 통계를 보완 할 수 있습니다. 성공적인 보고서 메트릭은 Amazon DynamoDB 서비스 내부의 대기 시간 만 측정합니다. 클라이언트 측 활동 및 네트워크 트립 시간은 포함되지 않습니다. 이 메트릭에서 약간의 변동성을 보는 것은 정상입니다. 대기 시간을 분석 할 때는 클라이언트 측면 활동이 포함 된 엔드 투 엔드 대기 시간을 고려하는 것이 가장 좋습니다. 클라이언트 측 활동을 고려하기 위해 AWS SDK에서 대기 시간 메트릭 로깅을 활성화 할 수 있습니다. 새로운 백분위 수 통계는 모든 상업용 AWS 지역, AWS Govcloud (US) 지역 및 중국 지역에서 사용할 수 있습니다. DynamoDB의 백분위 수 통계 및 문제 해결 대기 시간에 대한 자세한 내용은 다음을 참조하십시오. DynamoDB 개발자 안내서의 DynamoDB Metrics 및 DynamoDB의 대기 시간 문제 해결 DynamODB 개발자 안내서의 대기 시간 문제 해결"
  },
  {
    "source": "AWS",
    "title": "Amazon Q Business now available in AWS Asia Pacific (Sydney) Region",
    "date": "2025-03-27",
    "content": "Starting today, Amazon Q Business is available in Asia Pacific (Sydney) AWS Region. Amazon Q Business revolutionizes the way that employees interact with organizational knowledge and enterprise systems. Q Business customers in this region can get answers from enterprise RAG knowledge bases and uploaded files (e.g. pdf's, images) and run tabular search on small tables. Customers can also get answers from LLM knowledge and generate content using their Q Business assistant. Amazon Q Business connects seamlessly to over 40 popular enterprise systems, including Amazon Simple Storage Service (Amazon S3), Microsoft 365, and Salesforce. It ensures that users access content securely with their existing credentials using single sign-on, according to their permissions, and enterprise-level access controls. With this regional expansion, Amazon Q is now available in the following regions: US East (N. Virginia), US West (Oregon), Europe West (Ireland), and Asia Pacific Southeast (Sydney) AWS Regions . To learn more about the Amazon Q Business features available in this region, go to Q Business service regions . For more information, see Amazon Q Business .",
    "link": "https://aws.amazon.com/about-aws/whats-new/2025/03/amazon-q-business-asia-pacific-sydney-region/",
    "summary": "오늘부터 Amazon Q Business는 아시아 태평양 (시드니) AWS 지역에서 구입할 수 있습니다. Amazon Q Business는 직원들이 조직 지식 및 엔터프라이즈 시스템과 상호 작용하는 방식을 혁신합니다. 이 지역의 Q 비즈니스 고객은 Enterprise Rag Knowledge Base 및 업로드 된 파일 (예 : PDF, 이미지)으로부터 답변을 얻을 수 있으며 작은 테이블에서 테이블 검색을 실행할 수 있습니다. 고객은 LLM 지식으로부터 답변을 받고 Q 비즈니스 어시스턴트를 사용하여 콘텐츠를 생성 할 수 있습니다. Amazon Q Business는 Amazon Simple Storage Service (Amazon S3), Microsoft 365 및 Salesforce를 포함한 40 가지가 넘는 인기있는 엔터프라이즈 시스템에 원활하게 연결됩니다. 이를 통해 사용자는 권한 및 엔터프라이즈 수준의 액세스 컨트롤에 따라 단일 사인온을 사용하여 기존 자격 증명으로 콘텐츠에 안전하게 액세스 할 수 있습니다. 이 지역 확장으로 Amazon Q는 현재 US East (N. Virginia), US West (Oregon), Europe West (아일랜드) 및 Asia Pacific Southeast (Sydney) AWS 지역에서 다음과 같은 지역에서 제공됩니다. 이 지역에서 제공되는 Amazon Q 비즈니스 기능에 대한 자세한 내용은 Q 비즈니스 서비스 지역으로 이동하십시오. 자세한 내용은 Amazon Q 비즈니스를 참조하십시오."
  },
  {
    "source": "AWS",
    "title": "Amazon VPC IP Address Manager is now available in two additional AWS Regions",
    "date": "2025-03-27",
    "content": "Amazon Virtual Private Cloud IP Address Manager (Amazon VPC IPAM) that makes it easier for you to plan, track, and monitor IP addresses for your AWS workloads, is now available in Asia Pacific (Thailand) and Mexico (Central) Regions. Amazon VPC IPAM allows you to easily organize your IP addresses based on your routing and security needs, and set simple business rules to govern IP address assignments. Using VPC IPAM, you can automate IP address assignment to Amazon VPCs and VPC Subnets, eliminating the need to use spreadsheet-based or homegrown IP address planning applications, which can be hard to maintain and time-consuming. With this expansion, Amazon VPC IPAM is available in all AWS Regions , including China (Beijing, operated by Sinnet), and China (Ningxia, operated by NWCD), and the AWS GovCloud (US) Regions. To learn more about IPAM, view the IPAM documentation . For details on pricing, refer to the IPAM tab on the Amazon VPC Pricing Page .",
    "link": "https://aws.amazon.com/about-aws/whats-new/2025/03/amazon-vpc-ip-address-manager-two-additional-regions/",
    "summary": "AWS Workloads의 IP 주소를보다 쉽게 ​​계획, 추적 및 모니터링 할 수있는 Amazon Virtual Private Cloud IP 주소 관리자 (Amazon VPC IPAM)는 이제 Asia Pacific (Thailand) 및 Mexico (Central) 지역에서 쉽게 사용할 수 있습니다. Amazon VPC IPAM을 사용하면 라우팅 및 보안 요구에 따라 IP 주소를 쉽게 구성하고 IP 주소 할당을 관리하기위한 간단한 비즈니스 규칙을 설정할 수 있습니다. VPC IPAM을 사용하면 IP 주소 할당을 Amazon VPC 및 VPC 서브넷에 자동화하여 스프레드 시트 기반 또는 자체로운 IP 주소 계획 애플리케이션을 사용할 필요가 없어 유지 관리 및 시간 소모가 어려울 수 있습니다. 이러한 확장으로 Amazon VPC IPAM은 중국 (Beijing, Sinnet이 운영) 및 중국 (NWCD가 운영하는 Ningxia) 및 AWS Govcloud (US) 지역을 포함한 모든 AWS 지역에서 제공됩니다. IPAM에 대한 자세한 내용은 IPAM 문서를 참조하십시오. 가격에 대한 자세한 내용은 Amazon VPC 가격 페이지의 IPAM 탭을 참조하십시오."
  },
  {
    "source": "AWS",
    "title": "AWS CloudFormation now supports targeted resource scans in the IaC generator",
    "date": "2025-03-27",
    "content": "Today, AWS CloudFormation introduced a new resource scanning workflow for the CloudFormation IaC generator, further simplifying the process of generating Infrastructure-as-Code (IaC) templates for existing resources in your AWS account. IaC generator allows you to onboard existing resources to CloudFormation in three easy steps. First, you initiate a scan of resources in your AWS account. Second, you select resources for template generation and review suggestions for related resources. Third, a CloudFormation template is generated for selected resources. You can then import resources into a CloudFormation stack, download the template for deployment, or convert the template into a CDK app in your preferred programming language, such as TypeScript or Python. With this launch, you can specify the resource types that IaC generator will cover in the resource scanning step. Instead of scanning all resources by default, you can now focus only on the resources relevant to your workload, reducing scan time and effort. This improves the efficiency of the template generation process and streamlines iterative workflows, such as migration of a prototype workload to CloudFormation. To get started, open the AWS CloudFormation Console and select IaC generator in the navigation panel. You can also use IaC generator from the AWS CLI and AWS SDK. Learn more: User guide The IaC generator is available in AWS Regions where CloudFormation is available. CloudFormation documentation for Partial Scanning",
    "link": "https://aws.amazon.com/about-aws/whats-new/2025/03/aws-cloudformation-targeted-resource-scans-iac-generator/",
    "summary": "오늘 AWS CloudFormation은 CloudFormation IAC 생성기를위한 새로운 리소스 스캔 워크 플로우를 도입하여 AWS 계정의 기존 리소스에 대한 인프라 인프라-코드 (Code) 템플릿을 생성하는 프로세스를 더욱 단순화했습니다. IAC Generator를 사용하면 세 가지 쉬운 단계로 기존 리소스를 클라우드 형식으로 탑승 할 수 있습니다. 먼저 AWS 계정에서 리소스 스캔을 시작합니다. 둘째, 템플릿 생성에 대한 리소스를 선택하고 관련 리소스에 대한 제안을 검토합니다. 셋째, 선택된 자원에 대해 CloudFormation 템플릿이 생성됩니다. 그런 다음 리소스를 CloudFormation 스택으로 가져 오거나 배포를위한 템플릿을 다운로드하거나 TypeScript 또는 Python과 같은 선호하는 프로그래밍 언어에서 CDK 앱으로 템플릿을 변환 할 수 있습니다. 이 시작을 통해 IAC Generator가 자원 스캔 단계에서 다룰 리소스 유형을 지정할 수 있습니다. 기본적으로 모든 리소스를 스캔하는 대신 이제 작업량과 관련된 리소스에만 집중하여 스캔 시간과 노력을 줄일 수 있습니다. 이는 템플릿 생성 프로세스의 효율성을 향상시키고 프로토 타입 워크로드를 CloudFormation으로 마이그레이션하는 것과 같은 반복 워크 플로를 간소화합니다. 시작하려면 AWS CloudFormation 콘솔을 열고 탐색 패널에서 IAC 생성기를 선택하십시오. AWS CLI 및 AWS SDK에서 IAC 생성기를 사용할 수도 있습니다. 자세히 알아보기 : 사용자 안내서 IAC 생성기는 CloudFormation을 사용할 수있는 AWS 지역에서 사용할 수 있습니다. 부분 스캔을위한 CloudFormation 문서"
  },
  {
    "source": "AWS",
    "title": "Amazon Bedrock Custom Model Import introduces real-time cost transparency",
    "date": "2025-03-26",
    "content": "Amazon Bedrock Custom Model Import enables customers to import and run their customized foundation models on-demand without managing the underlying infrastructure. Customers can now get full transparency into the compute resources being used and calculate inference costs in real-time. With this launch, customers are able to see the minimum compute resources, custom model units (CMUs), required to run their model prior to model invocation in the Bedrock console and through Bedrock APIs. As the model scales to handle more traffic, CloudWatch metrics provide real-time visibility into the inference costs by showing the total number of CMUs used. This enables customers to better control spend through near-instant cost visibility and take actions like making on-the fly model configuration changes to optimize for costs. This feature is available in all regions where Amazon Bedrock Custom Model Import is supported. To learn more and get started, visit the Amazon Bedrock Custom Model Import page and see the documentation page for more details.",
    "link": "https://aws.amazon.com/about-aws/whats-new/2025/03/amazon-bedrock-custom-model-import-real-time-cost-transparency",
    "summary": "Amazon Bedrock Custom Model Import를 통해 고객은 기본 인프라를 관리하지 않고 주문형 사용자 정의 기초 모델을 수입 및 실행할 수 있습니다. 고객은 이제 사용중인 컴퓨팅 리소스에 대한 전적으로 투명성을 얻고 실시간으로 추론 비용을 계산할 수 있습니다. 이 출시를 통해 고객은 기반암 콘솔 및 기반 API를 통해 모델 호출 전에 모델을 실행하는 데 필요한 최소 Compute Resources, CMU (Custom Model Unit)를 볼 수 있습니다. 모델이 더 많은 트래픽을 처리하기 위해 스케일링함에 따라 CloudWatch 메트릭은 사용 된 총 CMU 수를 보여줌으로써 추론 비용에 대한 실시간 가시성을 제공합니다. 이를 통해 고객은 거의 영향을받는 비용 가시성을 통해 지출을 더 잘 제어 할 수 있으며 플라이 모델 구성을 변경하여 비용을 최적화하는 것과 같은 조치를 취할 수 있습니다. 이 기능은 Amazon Bedrock 사용자 정의 모델 가져 오기가 지원되는 모든 지역에서 사용할 수 있습니다. 자세한 내용을 배우고 시작하려면 Amazon Bedrock 사용자 정의 모델 가져 오기 페이지를 방문하여 자세한 내용은 문서 페이지를 참조하십시오."
  },
  {
    "source": "AWS",
    "title": "Amazon DynamoDB Streams APIs now support AWS PrivateLink",
    "date": "2025-03-26",
    "content": "Amazon DynamoDB Streams now comes with AWS PrivateLink support, allowing you to invoke DynamoDB Streams APIs from within your Amazon Virtual Private Cloud (VPC) without traversing the public internet. With AWS PrivateLink, you can simplify private network connectivity between virtual private clouds (VPCs), DynamoDB, and your on-premises data centers using interface VPC endpoints and private IP addresses. AWS PrivateLink is compatible with AWS Direct Connect and AWS Virtual Private Network (VPN) to facilitate private network connectivity, and helps you eliminate the need to use public IP addresses, configure firewall rules, or configure an internet gateway to access DynamoDB from your on-premises data centers. As a result, AWS PrivateLink helps you maintain compliance for your DynamoDB workloads over the private network. AWS PrivateLink for Amazon DynamoDB is available in all AWS commercial Regions . You can get started with the feature by using the AWS Management Console, AWS API, AWS CLI, AWS SDK, or AWS CloudFormation. To learn more about using AWS PrivateLink, see the Amazon DynamoDB developer guide and Creating an Interface Endpoint . Please see AWS PrivateLink pricing for pricing details.",
    "link": "https://aws.amazon.com/about-aws/whats-new/2025/03/amazon-dynamodb-streams-apis-aws-privatelink",
    "summary": "Amazon DynamoDB 스트림에는 이제 AWS PrivateLink 지원이 제공되어 공개 인터넷을 통과하지 않고 Amazon Virtual Private Cloud (VPC) 내에서 DynamoDB 스트림 API를 호출 할 수 있습니다. AWS PrivateLink를 사용하면 인터페이스 VPC 엔드 포인트 및 개인 IP 주소를 사용하여 가상 개인 클라우드 (VPC), DynamoDB 및 온 프레미스 데이터 센터 간의 개인 네트워크 연결을 단순화 할 수 있습니다. AWS Privatelink는 AWS Direct Connect 및 AWS Virtual Private Network (VPN)와 호환되어 개인 네트워크 연결을 용이하게하며 공개 IP 주소를 사용하거나 방화벽 규칙을 구성하거나 온 프레미스 데이터 센터에서 DynamODB에 액세스 할 수있는 인터넷 게이트웨이를 구성 할 필요가 없습니다. 결과적으로 AWS PrivateLink는 개인 네트워크를 통한 DynamODB 워크로드에 대한 준수를 유지하는 데 도움이됩니다. Amazon DynamoDB 용 AWS Privatelink는 모든 AWS 상업 지역에서 제공됩니다. AWS Management Console, AWS API, AWS CLI, AWS SDK 또는 AWS CloudFormation을 사용하여 기능을 시작할 수 있습니다. AWS PrivateLink 사용에 대한 자세한 내용은 Amazon DynamoDB 개발자 안내서를 참조하고 인터페이스 엔드 포인트 작성을 참조하십시오. 가격 세부 정보는 AWS Privatelink 가격을 참조하십시오."
  },
  {
    "source": "AWS",
    "title": "Amazon Application Recovery Controller announces AWS FIS recovery action for zonal autoshift",
    "date": "2025-03-26",
    "content": "AWS Fault Injection Service (FIS) now supports a recovery action for Amazon Application Recovery Controller (ARC) zonal autoshift. A recovery action is a new FIS action type that allows customers to demonstrate how AWS responds during an availability incident. For example, when AWS detects potential infrastructure issues in an Availability Zone (AZ), such as power or network disruptions, zonal autoshift automatically shifts traffic away from the AZ. With the new FIS recovery action, customers that have enabled zonal autoshift can run the FIS AZ Availability: Power Interruption scenario to induce the expected symptoms of a complete interruption of power in an AZ and demonstrate how AWS would trigger zonal autoshift. This allows customers to tune their monitoring and recovery process to improve resiliency and application availability. The FIS AZ Availability: Power Interruption scenario now includes the expected recovery from zonal autoshift in addition to the power interruption symptoms, including loss of zonal compute (Amazon EC2, EKS, and ECS), RDS and ElastiCache failover, and more. Running the scenario lets customers test and build confidence that their application responds as intended when an AZ is unavailable. To get started, select the AZ Availability: Power Interruption scenario from the FIS scenario library. The action is available in all AWS Regions where FIS and zonal autoshift are available, including the AWS GovCloud (US) Regions. To learn more, visit the documentation .",
    "link": "https://aws.amazon.com/about-aws/whats-new/2025/03/amazon-application-recovery-controller-fis-recovery-action/",
    "summary": "AWS 결함 분사 서비스 (FIS)는 이제 Amazon Application Recovery Controller (ARC) Zonal AutoShift의 복구 조치를 지원합니다. 복구 조치는 고객이 가용성 사건 중에 AWS가 어떻게 응답하는지 보여줄 수있는 새로운 FIS 액션 유형입니다. 예를 들어, AWS가 전원 또는 네트워크 중단과 같은 가용성 영역 (AZ)의 잠재적 인프라 문제를 감지하면 Zonal AutoShift가 AZ에서 트래픽을 자동으로 이동시킵니다. 새로운 FIS 복구 조치를 통해 Zonal AutoShift를 가능하게 한 고객은 FIS AZ 가용성을 실행할 수 있습니다 : 전력 중단 시나리오는 AZ에서 전력의 완전한 중단의 예상 증상을 유도하고 AWS가 어떻게 구역 AutoShift를 트리거하는지를 보여줍니다. 이를 통해 고객은 모니터링 및 복구 프로세스를 조정하여 탄력성 및 응용 프로그램 가용성을 향상시킬 수 있습니다. FIS AZ 가용성 : 전력 중단 시나리오에는 이제 구역 컴퓨팅 손실 (Amazon EC2, EKS 및 ECS), RDS 및 Elasticache Failover 등을 포함한 전력 중단 증상 외에도 구역 AutoShift의 예상 회복이 포함됩니다. 시나리오를 실행하면 고객은 AZ를 사용할 수없는 경우 응용 프로그램이 응용 프로그램에 응답한다는 신뢰를 테스트하고 구축 할 수 있습니다. 시작하려면 FIS 시나리오 라이브러리에서 AZ 가용성 : 전원 중단 시나리오를 선택하십시오. 이 작업은 AWS Govcloud (US) 지역을 포함하여 FIS 및 Zonal AutoShift를 사용할 수있는 모든 AWS 지역에서 사용할 수 있습니다. 자세한 내용은 문서를 방문하십시오."
  },
  {
    "source": "AWS",
    "title": "New Korean voice for Amazon Polly",
    "date": "2025-03-26",
    "content": "Today, we are excited to announce the general availability of Jihye - new Korean Neural Text-to-Speech (NTTS) female voice for Amazon Polly. Amazon Polly is a fully-managed service that turns text into lifelike speech, allowing you to create applications that talk and to build entirely new categories of speech-enabled products. Jihye is our new Korean voice that has a unique personality and style. We have trained it as a primarily conversational voice using carefully designed text and fully conversational speech recordings. Jihye can be adopted for a variety of speech products depending on the customer needs. It will perform at the highest quality in the interactive voice response (IVR) use cases, and will be most suitable for customer service, marketing, or education purposes. Jihye and all the other NTTS voices are available in AWS regions supporting Neural TTS . For more details, please read the Amazon Polly documentation and visit our pricing page .",
    "link": "https://aws.amazon.com/about-aws/whats-new/2025/03/new-korean-voice-amazon-polly",
    "summary": "오늘, 우리는 Amazon Polly의 NTTS (New Korean Neural Text-Steech) 여성 음성 인 Jihye의 일반적인 가용성을 발표하게되어 기쁩니다. Amazon Polly는 텍스트를 생생한 연설로 바꾸는 완전 관리 서비스로, 대화하는 응용 프로그램을 만들고 완전히 새로운 카테고리의 음성 지원 제품을 구축 할 수 있습니다. Jihye는 독특한 성격과 스타일을 가진 새로운 한국의 목소리입니다. 우리는 신중하게 디자인 된 텍스트와 완전히 대화적인 음성 녹음을 사용하여 주로 대화하는 목소리로 훈련했습니다. Jihye는 고객의 요구에 따라 다양한 음성 제품에 채택 할 수 있습니다. 대화식 음성 응답 (IVR) 사용 사례에서 최고 품질로 성능을 발휘할 수 있으며 고객 서비스, 마케팅 또는 교육 목적에 가장 적합합니다. Jihye와 다른 모든 NTT 목소리는 신경 TT를 지원하는 AWS 지역에서 제공됩니다. 자세한 내용은 Amazon Polly 문서를 읽고 가격 페이지를 방문하십시오."
  },
  {
    "source": "AWS",
    "title": "Database Insights adds support for customization of its metrics dashboard",
    "date": "2025-03-26",
    "content": "CloudWatch Database Insights announces support for customization of its metrics dashboard, allowing users to add or remove any database metric to the default dashboard provided. Database Insights is a database observability solution that provides a curated experience designed for DevOps engineers, application developers, and database administrators to expedite database troubleshooting and gain a holistic view into their database fleet health. Database Insights consolidates logs and metrics from your applications, your databases, and the operating systems on which they run into a unified view in the console. Using its pre-built dashboards, recommended alarms, and automated telemetry collection, you can monitor the health of your database fleets and use a guided troubleshooting experience to drill down to individual instances for root-cause analysis. Now users can customize the Database Insights preset metrics dashboard by incorporating or removing metrics according to their preferences. To customize the default metrics dashboard, navigate to the Database Instance Dashboard. From there, navigate to Database Telemetry and click on the Metrics tab. The new “Create widget” button that allows you to choose from a list of database, operating system, and CloudWatch metrics to add. You can also edit or remove existing metric widgets. The ability to customize the metrics dashboard is now available for all Aurora and RDS database engines that Database Insights supports and in all regions where Database Insights is available, at no additional cost. For further information, visit the Database Insights documentation.",
    "link": "https://aws.amazon.com/about-aws/whats-new/2025/03/database-insights-customization-metrics-dashboard/",
    "summary": "CloudWatch Database Insights는 메트릭 대시 보드의 사용자 정의 지원을 발표하여 사용자가 제공된 기본 대시 보드에 데이터베이스 메트릭을 추가하거나 제거 할 수 있습니다. Database Insights는 DevOps 엔지니어, 응용 프로그램 개발자 및 데이터베이스 관리자를 위해 설계된 선별 된 경험을 제공하여 데이터베이스 문제 해결을 신속하게하고 데이터베이스 차량 건강에 대한 전체 론적보기를 제공하는 데이터베이스 관찰 가능성 솔루션입니다. 데이터베이스 Insights는 응용 프로그램, 데이터베이스 및 콘솔에서 통합 된보기로 실행되는 운영 체제의 로그 및 메트릭을 통합합니다. 사전 구축 된 대시 보드, 권장 알람 및 자동화 된 원격 측정 컬렉션을 사용하여 데이터베이스 차량의 건강을 모니터링하고 유도 문제 해결 경험을 사용하여 루트 원인 분석을 위해 개별 인스턴스로 드릴링 할 수 있습니다. 이제 사용자는 선호도에 따라 메트릭을 통합하거나 제거하여 데이터베이스 통찰력 사전 설정 메트릭 대시 보드를 사용자 정의 할 수 있습니다. 기본 메트릭 대시 보드를 사용자 정의하려면 데이터베이스 인스턴스 대시 보드로 이동하십시오. 여기에서 데이터베이스 원격 측정으로 이동하여 메트릭 탭을 클릭하십시오. 데이터베이스, 운영 체제 및 CloudWatch 메트릭을 추가 할 수있는 새로운 \"위젯 만들기\"버튼을 추가 할 수 있습니다. 기존 메트릭 위젯을 편집하거나 제거 할 수도 있습니다. 데이터베이스 통찰력이 지원하는 모든 Aurora 및 RDS 데이터베이스 엔진과 데이터베이스 통찰력이 제공되는 모든 지역에서 추가 비용없이 메트릭 대시 보드를 사용자 정의 할 수있는 기능을 사용할 수 있습니다. 자세한 내용은 데이터베이스 통찰력 문서를 방문하십시오."
  },
  {
    "source": "AWS",
    "title": "Amazon CloudWatch RUM is now generally available in 2 additional AWS regions",
    "date": "2025-03-26",
    "content": "Amazon CloudWatch RUM, which enables customers to monitor their web applications by collecting client side performance and error data in real time, is additionally available in the following AWS Regions starting today: Israel (Tel Aviv), and Asia Pacific (Hong Kong). CloudWatch RUM provides curated dashboards for web application performance experienced by real end users including anomalies in page load steps, core web vitals, and JavaScript and Http errors across different geolocations, browsers, and devices. Custom events and metrics sent to CloudWatch RUM can be easily configured to monitor specific parts of the application for real user interactions, troubleshoot issues, and get alerted for anomalies. CloudWatch RUM comes integrated with the application performance monitoring (APM) capability, CloudWatch Application Signals . As a result, client-side data from your application can easily be correlated with performance metrics such as errors, faults, and latency observed in your APIs (service operations) and dependencies to address the root cause. To get started, see the RUM User Guide . Usage of CloudWatch RUM is charged on the number of collected RUM events, which refers to each data item collected by the RUM web client, as detailed here .",
    "link": "https://aws.amazon.com/about-aws/whats-new/2025/03/amazon-cloudwatch-rum-2-additional-aws-regions/",
    "summary": "고객이 클라이언트 측면 성능 및 오류 데이터를 실시간으로 수집하여 웹 애플리케이션을 모니터링 할 수있는 Amazon CloudWatch Rum은 오늘부터 이스라엘 (Tel Aviv) 및 아시아 태평양 (홍콩)에서 다음 AWS 지역에서 추가로 제공됩니다. CloudWatch Rum은 페이지로드 단계의 이상, 핵심 웹 생명체, 다양한 지오 로이션, 브라우저 및 장치의 JavaScript 및 HTTP 오류를 포함한 실제 최종 사용자가 경험 한 웹 애플리케이션 성능을위한 선별 된 대시 보드를 제공합니다. CloudWatch Rum으로 전송 된 사용자 정의 이벤트 및 메트릭은 실제 사용자 상호 작용에 대한 응용 프로그램의 특정 부분을 모니터링하고 문제를 해결하고 이상에 대해 경고하기 위해 쉽게 구성 할 수 있습니다. CloudWatch Rum은 APM (Application Performance Monitoring) 기능, CloudWatch 응용 프로그램 신호와 통합됩니다. 결과적으로 애플리케이션의 클라이언트 측 데이터는 API (서비스 운영)에서 관찰 된 오류, 결함 및 대기 시간과 같은 성능 메트릭 및 근본 원인을 해결하기위한 종속성과 쉽게 상관 관계가있을 수 있습니다. 시작하려면 럼 사용자 안내서를 참조하십시오. CloudWatch Rum의 사용은 수집 된 RUM 이벤트 수에 대해 청구되며 여기에 자세히 설명 된 것처럼 RUM Web 클라이언트가 수집 한 각 데이터 항목을 나타냅니다."
  },
  {
    "source": "AWS",
    "title": "Announcing multi-head node support in Slurm for Amazon SageMaker HyperPod clusters",
    "date": "2025-03-26",
    "content": "We’re excited to introduce multi-head node support for Amazon SageMaker HyperPod clusters. This new capability enhances fault tolerance and availability for large scale generative AI model development workloads. When a single head node manages job scheduling and resource allocation, it can become a critical bottleneck for customers running large scale AI workloads. When this node fails or becomes unresponsive, it can lead to job failures and downtime ultimately impacting the time to train. With this launch, customers can now configure multiple head nodes within a single HyperPod Slurm cluster—one primary head (controller) node to control all compute (worker) nodes and manage Slurm operations, and additional backup head nodes in standby. If the primary head node fails, Slurm automatically transitions cluster operations to a backup node minimizing downtime and ensuring continuous workload availability. Additionally, customers can still manage their own accounting databases and Slurm configuration while ensuring workloads remain continuously available. This capability is available in all regions where HyperPod is generally available. To learn more about the new multi-head node feature and set up your first HyperPod cluster with multiple head nodes, visit the Amazon SageMaker HyperPod documentation .",
    "link": "https://aws.amazon.com/about-aws/whats-new/2025/03/multi-head-node-slurm-amazon-sagemaker-hyperpod-clusters",
    "summary": "Amazon Sagemaker Hyperpod 클러스터에 대한 멀티 헤드 노드 지원을 도입하게되어 기쁩니다. 이 새로운 기능은 대규모 생성 AI 모델 개발 워크로드의 결함 공차 및 가용성을 향상시킵니다. 단일 헤드 노드가 작업 일정 및 리소스 할당을 관리하면 대규모 AI 워크로드를 실행하는 고객에게 중요한 병목 현상이 될 수 있습니다. 이 노드가 실패하거나 응답하지 않으면 작업 실패와 다운 타임이 궁극적으로 훈련 시간에 영향을 줄 수 있습니다. 이 출시를 통해 고객은 이제 단일 하이퍼 포드 슬러 름 클러스터 (컨트롤러) 노드 내에서 여러 헤드 노드를 구성하여 모든 컴퓨팅 (작업자) 노드를 제어하고 SLURM 작업을 관리하고 추가 백업 헤드 노드를 대기로 구성 할 수 있습니다. 기본 헤드 노드가 실패하면 SLURM은 클러스터 작업을 백업 노드로 자동으로 전환하여 다운 타임을 최소화하고 지속적인 워크로드 가용성을 보장합니다. 또한 고객은 여전히 ​​자체 계정 데이터베이스 및 SLURM 구성을 관리하면서 작업량을 지속적으로 사용할 수 있도록 할 수 있습니다. 이 기능은 HyperPOD를 일반적으로 사용할 수있는 모든 지역에서 사용할 수 있습니다. 새로운 멀티 헤드 노드 기능에 대한 자세한 내용은 여러 헤드 노드로 첫 번째 하이퍼 포드 클러스터를 설정하려면 Amazon Sagemaker HyperPod 문서를 방문하십시오."
  },
  {
    "source": "AWS",
    "title": "Amazon Route 53 Profiles now supports Internet Protocol Version 6 (IPv6) Service Endpoints",
    "date": "2025-03-26",
    "content": "Amazon Route 53 Profiles introduces dual stack support for the Route 53 Profiles API endpoints, enabling you to connect using Internet Protocol Version 6 (IPv6), Internet Protocol Version 4 (IPv4), or dual stack clients. The existing Route 53 Profiles endpoints supporting IPv4 will remain available for backwards compatibility. Route 53 Profiles makes it easy for you can create one or more configurations for VPC-related DNS settings, such as private hosted zones and Route 53 Resolver rules, and share them across VPCs and AWS accounts. The urgency to transition to Internet Protocol version 6 (IPv6) is driven by the continued growth of internet, which is exhausting available Internet Protocol version 4 (IPv4) addresses. With simultaneous support for both IPv4 and IPv6 clients on Route 53 Profiles endpoints, you are able to gradually transition from IPv4 to IPv6 based systems and applications, without needing to switch all over at once. This enables you to meet IPv6 compliance requirements and removes the need for expensive networking equipment to handle the address translation between IPv4 and IPv6. Support for IPv6 on Route 53 Profiles is available in all AWS Commercial and AWS GovCloud (US) Regions where Route 53 Profiles is available. See here for a full listing of our Regions. You can get started with the feature through AWS CLI or AWS Management Console . To learn more about Route 53 Profiles, visit the Route 53 documentation . To learn more about pricing, you can visit the Route 53 pricing page .",
    "link": "https://aws.amazon.com/about-aws/whats-new/2025/03/amazon-route-53-profiles-ipv6-service-endpoints",
    "summary": "Amazon Route 53 프로파일은 Route 53 프로파일 API 엔드 포인트에 대한 듀얼 스택 지원을 소개하여 인터넷 프로토콜 버전 6 (IPv6), 인터넷 프로토콜 버전 4 (IPv4) 또는 듀얼 스택 클라이언트를 사용하여 연결할 수 있습니다. 기존 Route 53 프로파일 IPv4를 지원하는 엔드 포인트는 역 호환성을 위해 사용할 수 있습니다. Route 53 프로파일을 사용하면 개인 호스팅 영역 및 Route 53 Resolver 규칙과 같은 VPC 관련 DNS 설정에 대한 하나 이상의 구성을 쉽게 만들 수 있으며 VPC 및 AWS 계정에서 공유 할 수 있습니다. 인터넷 프로토콜 버전 6 (IPV6)으로의 전환에 대한 긴급 성은 인터넷의 지속적인 성장에 의해 주도되며, 이는 Internet Protocol 버전 ​​4 (IPV4) 주소를 소진하고 있습니다. Route 53 프로파일 엔드 포인트에서 IPv4 및 IPv6 클라이언트 모두에 대한 동시 지원을 통해 IPv4에서 IPv6 기반 시스템 및 애플리케이션으로 점차 전환 할 수 있으며 한 번에 전환 할 필요없이 점차적으로 전환 할 수 있습니다. 이를 통해 IPv6 규정 준수 요구 사항을 충족하고 IPv4와 IPv6 간의 주소 변환을 처리하기 위해 고가의 네트워킹 장비가 필요하지 않습니다. Route 53 프로파일에 대한 IPv6 지원은 Route 53 프로파일을 사용할 수있는 모든 AWS Commercial 및 AWS Govcloud (US) 지역에서 제공됩니다. 지역의 전체 목록은 여기를 참조하십시오. AWS CLI 또는 AWS 관리 콘솔을 통해 기능을 시작할 수 있습니다. Route 53 프로필에 대한 자세한 내용은 Route 53 문서를 방문하십시오. 가격에 대한 자세한 내용은 Route 53 가격 페이지를 방문하십시오."
  },
  {
    "source": "AWS",
    "title": "Deploy Storage Browser for Amazon S3 quickly with AWS sample applications",
    "date": "2025-03-26",
    "content": "You can now easily deploy pre-configured sample applications to connect your users to data in Amazon S3 using Storage Browser for S3. Once you select and deploy one of the sample apps, users can browse, download, upload, copy, and delete data they have access to in S3 through an intuitive file browser experience. You can host these sample apps with Amplify Hosting or any hosting provider of your choice. Each sample application comes with preset integrations of AWS identity services with Storage Browser for S3 to help you quickly connect authorized end users to data in S3. Use these sample apps to accelerate cloud adoption for your organization without custom development work. Visit the documentation to learn more and get started.",
    "link": "https://aws.amazon.com/about-aws/whats-new/2025/03/deploy-storage-browser-amazon-s3-sample-applications/",
    "summary": "이제 사전 구성된 샘플 애플리케이션을 쉽게 배포하여 S3 용 스토리지 브라우저를 사용하여 Amazon S3의 데이터에 사용자를 연결할 수 있습니다. 샘플 앱 중 하나를 선택하고 배포하면 사용자는 직관적 인 파일 브라우저 경험을 통해 S3에서 액세스 할 수있는 데이터를 탐색, 다운로드, 업로드, 복사 및 삭제할 수 있습니다. Amplify 호스팅 또는 선택한 호스팅 제공 업체로 이러한 샘플 앱을 호스팅 할 수 있습니다. 각 샘플 애플리케이션에는 S3 용 스토리지 브라우저와 AWS Identity 서비스의 사전 설정된 통합이 제공되어 공인 된 최종 사용자를 S3의 데이터에 신속하게 연결합니다. 이 샘플 앱을 사용하여 맞춤형 개발 작업없이 조직의 클라우드 채택을 가속화하십시오. 자세한 내용을 배우고 시작하려면 문서를 방문하십시오."
  },
  {
    "source": "AWS",
    "title": "AWS Network Firewall is now available in the Asia Pacific (Thailand) and Mexico (Central) Regions",
    "date": "2025-03-26",
    "content": "Starting today, AWS Network Firewall is available in the Asia Pacific (Thailand) and Mexico (Central) regions, enabling customers to deploy essential network protections for all their Amazon Virtual Private Clouds (VPCs). AWS Network Firewall is a managed firewall service that is easy to deploy. The service automatically scales with network traffic volume to provide high-availability protections without the need to set up and maintain the underlying infrastructure. It is integrated with AWS Firewall Manager to provide you with central visibility and control over your firewall policies across multiple AWS accounts. To see which regions AWS Network Firewall is available in, visit the AWS Region Table . For more information, please see the AWS Network Firewall product page and the service documentation .",
    "link": "https://aws.amazon.com/about-aws/whats-new/2025/03/aws-network-firewall-thailand-mexico-central-regions/",
    "summary": "오늘부터 AWS 네트워크 방화벽은 아시아 태평양 (태국) 및 멕시코 (중앙) 지역에서 제공되므로 고객이 모든 Amazon 가상 개인 클라우드 (VPC)에 대한 필수 네트워크 보호를 배포 할 수 있습니다. AWS 네트워크 방화벽은 배포하기 쉬운 관리 방화벽 서비스입니다. 이 서비스는 네트워크 트래픽 볼륨으로 자동 조정하여 기본 인프라를 설정하고 유지할 필요없이 고용성 보호 기능을 제공합니다. AWS 방화벽 관리자와 통합되어 여러 AWS 계정에서 중심 가시성과 방화벽 정책을 제어 할 수 있습니다. AWS 네트워크 방화벽이 어떤 지역에 있는지 확인하려면 AWS 지역 테이블을 방문하십시오. 자세한 내용은 AWS 네트워크 방화벽 제품 페이지 및 서비스 문서를 참조하십시오."
  },
  {
    "source": "AWS",
    "title": "AWS Amplify Hosting announces Web Application Firewall Protection in general availability",
    "date": "2025-03-26",
    "content": "Today, we are announcing the general availability of our Web Application Firewall Protection for AWS Amplify Hosting . This new feature allows customers to easily attach a web application firewall to their AWS Amplify apps, enhancing the security of their hosted applications. With this integration, customers can implement robust security measures without additional configuration steps or management overhead. The AWS WAF integration with Amplify Hosting provides access to a full range of AWS WAF capabilities. Customers can now use managed rules to protect against common web exploits and vulnerabilities such as SQL injection and cross-site scripting (XSS). Additionally, they can create custom rules based on their specific application needs, implement rate-based rules to protect against DDoS attacks, and use geo-blocking to restrict access from specific countries. This integration enables customers to implement in-depth security strategies for their web applications to help safeguard against threats. This new feature is available in all AWS Regions where Amplify Hosting operates . Customers can attach AWS WAF to their Amplify apps through a simple one-click integration in the Amplify console or by using infrastructure as code (IaC). Amplify Hosting will charge a $15/month per app fee to use this feature, plus any costs incurred by the AWS WAF service. To get started with AWS WAF integration for Amplify Hosting, visit the Amplify console and navigate to your app settings. Select the Firewall tab to choose predefined rules or create custom configurations. Or you can refer to the documentation .",
    "link": "https://aws.amazon.com/about-aws/whats-new/2025/03/aws-amplify-hosting-web-application-firewall-protection/",
    "summary": "오늘 우리는 AWS Amplify 호스팅을위한 웹 애플리케이션 방화벽 보호의 일반적인 가용성을 발표하고 있습니다. 이 새로운 기능을 통해 고객은 웹 애플리케이션 방화벽을 AWS Amplify 앱에 쉽게 첨부하여 호스팅 된 응용 프로그램의 보안을 향상시킬 수 있습니다. 이러한 통합을 통해 고객은 추가 구성 단계 나 관리 오버 헤드없이 강력한 보안 조치를 구현할 수 있습니다. Amplify Hosting과 AWS WAF 통합은 모든 AWS WAF 기능에 대한 액세스를 제공합니다. 고객은 이제 관리되는 규칙을 사용하여 공통 웹 익스플로잇 및 SQL 주입 및 XSS (Cross-Site Scripting)와 같은 취약점으로부터 보호 할 수 있습니다. 또한 특정 응용 프로그램 요구에 따라 사용자 정의 규칙을 작성하고 DDOS 공격으로부터 보호하기 위해 요금 기반 규칙을 구현하며 지리적 차단을 사용하여 특정 국가의 액세스를 제한 할 수 있습니다. 이 통합을 통해 고객은 웹 애플리케이션에 대한 심층적 인 보안 전략을 구현하여 위협으로부터 보호 할 수 있도록 도와줍니다. 이 새로운 기능은 Amplify 호스팅이 작동하는 모든 AWS 지역에서 사용할 수 있습니다. 고객은 Amplify 콘솔의 간단한 원 클릭 통합 또는 인프라를 코드 (IAC)로 사용하여 AWS WAF를 증폭 앱에 첨부 할 수 있습니다. Amplify Hosting 은이 기능을 사용하기 위해 앱당 $ 15/월 $ 15와 AWS WAF 서비스에서 발생하는 모든 비용을 청구합니다. Almplify 호스팅을 위해 AWS WAF 통합을 시작하려면 Amplify 콘솔을 방문하여 앱 설정으로 이동하십시오. 방화벽 탭을 선택하여 사전 정의 된 규칙을 선택하거나 사용자 정의 구성을 만듭니다. 또는 문서를 참조 할 수 있습니다."
  },
  {
    "source": "AWS",
    "title": "Amazon RDS for SQL Server supports linked servers to Teradata databases",
    "date": "2025-03-25",
    "content": "Amazon Relational Database Service (Amazon RDS) for SQL Server now supports linked servers to Teradata databases. Linked server is a SQL Server feature that enables customers to read data and execute commands on remote database servers outside of the SQL Server instance. With this launch, customers can link their RDS for SQL Server instance to a Teradata database running on AWS or on premises. To start setting up a linked server for Teradata, add the ODBC_TERADATA option to your RDS for SQL Server instance's Option Group. Amazon RDS automatically installs and configures the Teradata ODBC driver, enabling you to run distributed queries, and execute SQL commands on your Teradata database from your RDS for SQL Server instance. Linked servers on RDS support distributed transactions through Microsoft Distributed Transaction Coordinator (MSDTC) and use TLS (Transport Layer Security) encryption for secure connections. To learn more about setting up and using Teradata linked servers, refer to the Amazon RDS for SQL Server User Guide . This feature is available in all AWS Regions where Amazon RDS for SQL Server is available. See Amazon RDS for SQL Server Pricing for pricing details and regional availability.",
    "link": "https://aws.amazon.com/about-aws/whats-new/2025/03/amazon-rds-sql-server-linked-servers-teradata-databases",
    "summary": "SQL Server의 Amazon Relational Database Service (Amazon RDS)는 이제 링크 된 서버를 Teradata 데이터베이스에 지원합니다. Linked Server는 고객이 SQL Server 인스턴스 외부의 원격 데이터베이스 서버에서 데이터를 읽고 명령을 실행할 수있는 SQL Server 기능입니다. 이 출시를 통해 고객은 SQL Server 인스턴스 용 RDS를 AWS 또는 구내에서 실행하는 Teradata 데이터베이스에 연결할 수 있습니다. Teradata 용 링크 서버를 설정하려면 SQL Server 인스턴스 옵션 그룹의 RDS에 ODBC_Teradata 옵션을 추가하십시오. Amazon RDS는 Teradata ODBC 드라이버를 자동으로 설치하고 구성하여 분산 쿼리를 실행하고 SQL Server 인스턴스 용 RDS에서 Teradata 데이터베이스에서 SQL 명령을 실행할 수 있도록합니다. RDS의 연결된 서버는 MSDTC (Microsoft Distributed Transaction Coordinator)를 통해 분산 트랜잭션을 지원하고 보안 연결을 위해 TLS (Transport Layer Security) 암호화를 사용합니다. Teradata 링크 서버 설정 및 사용에 대한 자세한 내용은 SQL Server 사용자 안내서의 Amazon RDS를 참조하십시오. 이 기능은 SQL Server 용 Amazon RDS를 사용할 수있는 모든 AWS 지역에서 사용할 수 있습니다. 가격 세부 정보 및 지역 가용성은 SQL Server 가격에 대한 Amazon RDS를 참조하십시오."
  },
  {
    "source": "AWS",
    "title": "Amazon Keyspaces expands Multi-Region Replication to support all AWS Regions",
    "date": "2025-03-25",
    "content": "Amazon Keyspaces (for Apache Cassandra) has expanded its Multi-Region Replication capabilities, now enabling you to replicate your tables beyond the previous quota of six AWS Regions to all available AWS Regions. This enhancement to the existing multi-Region Replication provides even greater flexibility for organizations requiring broader global presence and data distribution. Customers can now automatically replicate their data across any number of AWS Regions supported within Amazon Keyspaces. With multi-Region replication, Amazon Keyspaces asynchronously replicates data between Regions, and data is typically propagated across Regions within a second. The expanded regional support helps you to better serve your global user base, meet regional compliance requirements, and implement more robust disaster recovery strategies. Getting started is easy through the AWS Management Console, AWS CLI, or AWS SDKs by selecting your desired destination AWS Regions. There are no upfront commitments; you only pay for the resources used in each Region. To learn more about the enhanced Multi-Region Replication capabilities in Amazon Keyspaces, refer to the Multi-Region replication documentation. To get started with Amazon Keyspaces (for Apache Cassandra), please refer to the Amazon Keyspaces Developer Guide .",
    "link": "https://aws.amazon.com/about-aws/whats-new/2025/03/amazon-keyspaces-multi-region-replication-aws-regions",
    "summary": "Amazon Keyspaces (Apache Cassandra의 경우)는 다중 지역 복제 기능을 확장하여 이제 6 개의 AWS 지역의 이전 할당량을 넘어 사용 가능한 모든 AWS 지역으로 테이블을 복제 할 수 있습니다. 기존 멀티 지역 복제에 대한 이러한 향상은 더 넓은 글로벌 입지 및 데이터 배포가 필요한 조직에 훨씬 더 큰 유연성을 제공합니다. 고객은 이제 Amazon Keyspaces 내에서 지원되는 여러 AWS 지역에서 데이터를 자동으로 복제 할 수 있습니다. 다중 지역 복제를 통해 Amazon Keyspaces는 지역 간 데이터를 비동기로 복제하며 데이터는 일반적으로 1 초 이내에 영역에 걸쳐 전파됩니다. 확장 된 지역 지원을 통해 글로벌 사용자 기반에 더 나은 서비스를 제공하고 지역 준수 요구 사항을 충족하며보다 강력한 재해 복구 전략을 구현할 수 있습니다. 원하는 대상 AWS 지역을 선택하여 AWS 관리 콘솔, AWS CLI 또는 AWS SDK를 통해 시작하는 것은 쉬운 일입니다. 선불 약속은 없습니다. 각 지역에서 사용되는 자원에 대해서만 비용을 지불합니다. Amazon Keyspaces의 향상된 다중 지역 복제 기능에 대한 자세한 내용은 멀티 지역 복제 문서를 참조하십시오. Amazon Keyspaces (Apache Cassandra의 경우)를 시작하려면 Amazon Keyspaces Developer Guide를 참조하십시오."
  },
  {
    "source": "AWS",
    "title": "Amazon RDS for MySQL announces Innovation Release version 9.2 in Amazon RDS Database Preview Environment",
    "date": "2025-03-25",
    "content": "Amazon RDS for MySQL now supports MySQL Innovation Release 9.2 in the Amazon RDS Database Preview Environment , allowing you to evaluate the latest Innovation Release on Amazon RDS for MySQL. You can deploy MySQL 9.2 in the Amazon RDS Database Preview Environment that has the benefits of a fully managed database, making it simpler to set up, operate, and monitor databases. MySQL 9.2 is the latest Innovation Release from the MySQL community. MySQL Innovation releases include bug fixes, security patches, as well as new features. MySQL Innovation releases are supported by the community until the next major & minor release, whereas MySQL Long Term Support (LTS) Releases, such as MySQL 8.0 and MySQL 8.4, are supported by the community for up to eight years. Please refer to the MySQL 9.2 release notes for more details about this release. The Amazon RDS Database Preview Environment supports both Single-AZ and Multi-AZ deployments on the latest generation of instance classes. Amazon RDS Database Preview Environment database instances are retained for a maximum period of 60 days and are automatically deleted after the retention period. Amazon RDS database snapshots that are created in the preview environment can only be used to create or restore database instances within the preview environment. Amazon RDS Database Preview Environment database instances are priced the same as production RDS instances created in the US East (Ohio) Region .",
    "link": "https://aws.amazon.com/about-aws/whats-new/2025/03/amazon-rds-mysql-innovation-release-version-9-2-rds-database-preview-environment",
    "summary": "MySQL 용 Amazon RDS는 이제 Amazon RDS 데이터베이스 미리보기 환경에서 MySQL Innovation Release 9.2를 지원하므로 MySQL 용 Amazon RDS의 최신 혁신 릴리스를 평가할 수 있습니다. 완전히 관리되는 데이터베이스의 이점이있는 Amazon RDS 데이터베이스 미리보기 환경에 MySQL 9.2를 배포 할 수 있으므로 데이터베이스를 설정, 작동 및 모니터링하기가 더 간단합니다. MySQL 9.2는 MySQL 커뮤니티의 최신 혁신 릴리스입니다. MySQL Innovation 릴리스에는 버그 수정, 보안 패치 및 새로운 기능이 포함됩니다. MySQL Innovation Releases는 다음 전공 및 마이너 릴리스까지 커뮤니티가 지원하는 반면 MySQL 8.0 및 MySQL 8.4와 같은 MySQL 장기 지원 (LTS) 릴리스는 최대 8 년 동안 커뮤니티에서 지원됩니다. 이 릴리스에 대한 자세한 내용은 MySQL 9.2 릴리스 노트를 참조하십시오. Amazon RDS 데이터베이스 미리보기 환경은 최신 인스턴스 클래스에서 단일 AAZ 및 Multi-AZ 배포를 지원합니다. Amazon RDS 데이터베이스 미리보기 환경 데이터베이스 인스턴스는 최대 60 일 동안 유지되며 유지 기간 후에 자동으로 삭제됩니다. 미리보기 환경에서 생성 된 Amazon RDS 데이터베이스 스냅 샷은 미리보기 환경 내에서 데이터베이스 인스턴스를 작성하거나 복원하는 데만 사용될 수 있습니다. Amazon RDS 데이터베이스 미리보기 환경 데이터베이스 인스턴스의 가격은 미국 이스트 (OHIO) 지역에서 생성 된 생산 RDS 인스턴스와 동일합니다."
  },
  {
    "source": "AWS",
    "title": "AWS announces OR2 and OM2 instances for Amazon OpenSearch Service",
    "date": "2025-03-25",
    "content": "Amazon OpenSearch Service introduces two new instances- OR2 and OM2, expanding the OpenSearch Optimized Instance family. The new generation OR2 instance delivers up to 26% higher indexing throughput compared to previous OR1 instances and 70% over R7g instances. The new OM2 instance delivers up to 15% higher indexing throughput compared to OR1 instances and 66% over M7g instances in internal benchmarks. The new generation OpenSearch Optimized instances use the same architecture as the OR1 instances, leveraging best-in-class cloud technologies like Amazon S3, to provide high durability, and improved price-performance for higher indexing throughput better for indexing heavy workload. Each OpenSearch Optimized instance is provisioned with compute, local instance storage for caching, and remote Amazon S3-based managed storage. OR2 and OM2 offers pay-as-you-go pricing and reserved instances, with a simple hourly rate for the instance, local instance storage, as well as the managed storage provisioned. OR2 instances come in sizes ‘medium’ through ‘16xlarge’, and offer compute, memory, and storage flexibility. OM2 instances come in sizes ‘large’ through ‘16xlarge’ Please refer to the Amazon OpenSearch Service pricing page for pricing details. OR2 instance family is now available on Amazon OpenSearch Service across 10 regions globally: US East (N. Virginia, Ohio), US West (Oregon), Europe (Ireland, Frankfurt, Stockholm, Spain), and Asia Pacific (Sydney, Tokyo, Mumbai). OM2 instance family is now available on Amazon OpenSearch Service across 6 regions globally: US East (N. Virginia, Ohio), US West (Oregon) and Europe (London, Frankfurt, Stockholm).",
    "link": "https://aws.amazon.com/about-aws/whats-new/2025/03/aws-or2-om2-instances-opensearch-service/",
    "summary": "Amazon OpenSearch Service는 OpenSearch 최적화 인스턴스 패밀리를 확장하여 두 가지 새로운 인스턴스 OR2와 OM2를 소개합니다. 새로운 세대 OR2 인스턴스는 이전 OR1 인스턴스에 비해 최대 26% 더 높은 인덱싱 처리량을, R7G 인스턴스에 비해 70%를 제공합니다. 새로운 OM2 인스턴스는 OR1 인스턴스에 비해 최대 15% 더 높은 인덱싱 처리량을 제공하고 내부 벤치 마크에서 M7G 인스턴스에 비해 66%를 제공합니다. 새로운 세대 OpenSearch 최적화 인스턴스는 OR1 인스턴스와 동일한 아키텍처를 사용하여 Amazon S3와 같은 동급 최고의 클라우드 기술을 활용하여 높은 내구성을 제공하고 인덱스 처리량이 높을수록 높은 작업량을 더 잘 인덱싱하기 위해 더 높은 인덱싱 처리량을 제공합니다. 각 OpenSearch 최적화 인스턴스는 컴퓨팅, 캐싱 용 로컬 인스턴스 스토리지 및 원격 Amazon S3 기반 관리 스토리지로 프로비저닝됩니다. OR2 및 OM2는 인스턴스, 로컬 인스턴스 스토리지 및 관리 된 스토리지 프로비저닝에 대한 간단한 시간당 요금으로 Pay-as-You-Go 가격 및 예약 된 인스턴스를 제공합니다. OR2 인스턴스는 '16xlarge'를 통해 '중간'크기로 제공되며 컴퓨팅, 메모리 및 스토리지 유연성을 제공합니다. OM2 인스턴스는 '16xlarge'를 통해 '큰'크기로 제공됩니다. 가격 세부 정보는 Amazon OpenSearch Service 가격 페이지를 참조하십시오. OR2 인스턴스 패밀리는 이제 전 세계 10 개 지역의 Amazon OpenSearch Service : US East (N. Virginia, Ohio), US West (오레곤), 유럽 (아일랜드, 프랑크푸르트, 스톡홀름, 스페인) 및 아시아 태평양 (시드니, 도쿄, 뭄바이). OM2 인스턴스 패밀리는 이제 전 세계 6 개 지역의 Amazon OpenSearch Service : US East (N. Virginia, Ohio), US West (오레곤) 및 유럽 (런던, 프랑크푸르트, 스톡홀름)에서 제공됩니다."
  },
  {
    "source": "AWS",
    "title": "Amazon EventBridge Scheduler now supports AWS PrivateLink",
    "date": "2025-03-25",
    "content": "Amazon EventBridge Scheduler now supports AWS PrivateLink , providing you access to Scheduler from within your Amazon Virtual Private Cloud (VPC) without using the public internet. This feature eliminates the need for an internet gateway, firewall rules, or proxy servers when accessing EventBridge Scheduler from a private subnet. With Amazon EventBridge Scheduler, you can create billions of scheduled events and tasks that run across more than 270 AWS services, without provisioning or managing infrastructure. You can set up one-time schedules for specific dates and times, or create recurring schedules using cron and rate expressions, with support for time zones and daylight savings. With AWS PrivateLink support in EventBridge Scheduler, you can reduce the infrastructure required to create and manage your schedules when making API calls to Scheduler from within your VPC. AWS PrivateLink support for EventBridge Scheduler is available in all AWS Regions where EventBridge Scheduler is offered. Using this feature incurs no additional cost, but standard AWS PrivateLink pricing applies. For PrivateLink configuration instructions, refer to the AWS PrivateLink documentation . To learn more about Amazon EventBridge Scheduler and its capabilities, see the EventBridge documentation.",
    "link": "https://aws.amazon.com/about-aws/whats-new/2025/03/amazon-eventbridge-scheduler-privatelink/",
    "summary": "Amazon Eventbridge Scheduler는 이제 AWS PrivateLink를 지원하여 공개 인터넷을 사용하지 않고 Amazon Virtual Private Cloud (VPC) 내에서 스케줄러에 액세스 할 수 있도록 제공합니다. 이 기능은 개인 서브넷에서 EventBridge 스케줄러에 액세스 할 때 인터넷 게이트웨이, 방화벽 규칙 또는 프록시 서버가 필요하지 않습니다. Amazon Eventbridge Scheduler를 사용하면 인프라를 프로비저닝하거나 관리하지 않고 270 개 이상의 AWS 서비스에서 실행되는 수십억 개의 예정된 이벤트 및 작업을 만들 수 있습니다. 특정 날짜 및 시간에 대한 일회성 일정을 설정하거나 시간 영역 및 일광 절약을 지원하여 CRON 및 요금 표현을 사용하여 반복 일정을 만들 수 있습니다. EventBridge Scheduler의 AWS PrivateLink 지원을 사용하면 VPC 내에서 Scheduler에 API 호출을 할 때 일정을 작성하고 관리하는 데 필요한 인프라를 줄일 수 있습니다. EventBridge Scheduler가 제공되는 모든 AWS 지역에서는 EventBridge Scheduler에 대한 AWS PrivateLink 지원이 제공됩니다. 이 기능을 사용하려면 추가 비용이 발생하지 않지만 표준 AWS PrivateLink 가격은 적용됩니다. PrivateLink 구성 지침은 AWS Privatelink 문서를 참조하십시오. Amazon Eventbridge Scheduler 및 그 기능에 대한 자세한 내용은 EventBridge 문서를 참조하십시오."
  },
  {
    "source": "AWS",
    "title": "Amazon Redshift Query Editor V2 is now available in AWS Mexico (Central) and Asia Pacific (Thailand) regions",
    "date": "2025-03-25",
    "content": "Amazon Redshift announces the general availability of Query Editor V2 with Amazon Redshift in the AWS Mexico (Central) and Asia Pacific (Thailand) regions. Amazon Redshift Query Editor V2 makes data in your Amazon Redshift data warehouse and data lake more accessible with a web-based tool for SQL users such as data analysts, data scientists, and database developers. With Query Editor V2, users can explore, analyze, and collaborate on data. It reduces the operational costs of managing query tools by providing a web-based application that allows you to focus on exploring your data without managing your infrastructure. The Amazon Redshift Query Editor V2 is a separate web-based SQL client application that you use to author and run queries on your Amazon Redshift data warehouse. You can use it to edit and run queries, visualize results, and share your work with your team. With Amazon Redshift Query Editor V2, you can create databases, schemas, tables, and user-defined functions (UDFs). In a tree-view panel, for each of your databases, you can view its schemas. For each schema, you can view its tables, views, UDFs, and stored procedures. The Amazon Redshift Query Editor V2 comes with sample data and notebooks available for you to be loaded into a sample database and corresponding schema. You can use it to load data into a database in an Amazon Redshift cluster or workgroup. To learn more, see the documentation or the demo .",
    "link": "https://aws.amazon.com/about-aws/whats-new/2025/03/amazon-redshift-query-editor-v2-aws-mexico-central-asia-pacific-thailand-regions",
    "summary": "Amazon Redshift는 AWS Mexico (Central) 및 Asia Pacific (태국) 지역에서 Amazon Redshift와 함께 쿼리 편집기 V2의 일반 가용성을 발표했습니다. Amazon Redshift Query 편집기 V2는 데이터 분석가, 데이터 과학자 및 데이터베이스 개발자와 같은 SQL 사용자를위한 웹 기반 도구를 통해 Amazon Redshift Data Warehouse 및 Data Lake에서 데이터를 더 많이 액세스 할 수 있습니다. 쿼리 편집기 v2를 사용하면 사용자가 데이터를 탐색, 분석 및 협업 할 수 있습니다. 인프라를 관리하지 않고 데이터를 탐색하는 데 집중할 수있는 웹 기반 애플리케이션을 제공하여 쿼리 도구 관리의 운영 비용을 줄입니다. Amazon Redshift Query 편집기 V2는 Amazon Redshift 데이터웨어 하우스에서 쿼리를 작성하고 실행하는 데 사용하는 별도의 웹 기반 SQL 클라이언트 응용 프로그램입니다. 이를 사용하여 쿼리를 편집하고 실행하고 결과를 시각화하며 팀과 작업을 공유 할 수 있습니다. Amazon Redshift 쿼리 편집기 v2를 사용하면 데이터베이스, 스키마, 테이블 및 사용자 정의 기능 (UDF)을 만들 수 있습니다. 트리 뷰 패널에서 각 데이터베이스에 대해 스키마를 볼 수 있습니다. 각 스키마의 경우 테이블, 뷰, UDF 및 저장된 절차를 볼 수 있습니다. Amazon Redshift Query 편집기 V2에는 샘플 데이터베이스 및 해당 스키마에로드 할 수있는 샘플 데이터 및 노트북이 제공됩니다. 이를 사용하여 Amazon Redshift 클러스터 또는 작업 그룹의 데이터베이스에 데이터를로드 할 수 있습니다. 자세한 내용은 문서 또는 데모를 참조하십시오."
  },
  {
    "source": "AWS",
    "title": "The next generation of Amazon SageMaker is now available in two additional regions",
    "date": "2025-03-25",
    "content": "The next generation of Amazon SageMaker is now available in two additional AWS Regions: Asia Pacific (Mumbai), and Europe (Paris). Amazon SageMaker is the center for all your data, analytics, and AI. Users can access all their data and tools from Amazon SageMaker Unified Studio, a single data and AI development environment that brings together the functionality and tools from existing AWS Analytics and AI/ML services, including Amazon EMR, AWS Glue, Amazon Athena, Amazon Redshift, Amazon Bedrock, and Amazon SageMaker AI. Unified access to data is provided by Amazon SageMaker Lakehouse, and catalog and governance features are available via SageMaker Catalog (built on Amazon DataZone) to help you meet enterprise security requirements. For more information on AWS Regions where the next generation of Amazon SageMaker is available, see supported regions . To get started, see the following resources: SageMaker overview SageMaker documentation",
    "link": "https://aws.amazon.com/about-aws/whats-new/2025/03/next-generation-amazon-sagemaker-two-additional-regions/",
    "summary": "차세대 Amazon Sagemaker는 이제 Asia Pacific (Mumbai) 및 Europe (파리)의 2 개의 추가 AWS 지역에서 제공됩니다. Amazon Sagemaker는 모든 데이터, 분석 및 AI의 중심입니다. 사용자는 Amazon EMR, AWS Glue, Amazon Athena, Amazon Redshift, Amazon Bedrock 및 Amazon Sagemaker AI를 포함하여 기존 AWS 분석 및 AI/ML 서비스의 기능과 도구를 모으는 단일 데이터 및 AI 개발 환경 인 Amazon Sagemaker Unified Studio의 모든 데이터 및 도구에 액세스 할 수 있습니다. 데이터에 대한 통합 액세스는 Amazon Sagemaker Lakehouse에서 제공하며 카탈로그 및 거버넌스 기능은 Sagemaker 카탈로그 (Amazon Datazone)를 통해 제공하여 엔터프라이즈 보안 요구 사항을 충족시킬 수 있습니다. 차세대 Amazon Sagemaker를 사용할 수있는 AWS 지역에 대한 자세한 내용은 지원되는 지역을 참조하십시오. 시작하려면 다음 리소스를 참조하십시오. Sagemaker 개요 Sagemaker 문서"
  },
  {
    "source": "AWS",
    "title": "Amazon DataZone is now available in 2 additional commercial regions",
    "date": "2025-03-25",
    "content": "Amazon DataZone is now available in 2 additional commercial regions: Asia Pacific (Mumbai) and Europe (Paris). Amazon DataZone is a fully managed data management service to catalog, discover, analyze, share, and govern data between data producers and consumers in your organization. With Amazon DataZone, data producers populate the business data catalog with structured data assets from AWS Glue Data Catalog and Amazon Redshift tables. Data consumers search and subscribe to data assets in the data catalog and share with other business use case collaborators. Consumers can analyze their subscribed data assets with tools—such as Amazon Redshift or Amazon Athena query editors—that are directly accessed from the Amazon DataZone portal. The integrated publishing-and-subscription workflow provides access-auditing capabilities across projects. For more information on AWS Regions where Amazon DataZone is available in preview, see supported regions . Additionally, Amazon DataZone powers governance in the next generation of Amazon SageMaker, which simplifies the discovery, governance, and collaboration for data and AI across your Lakehouse, AI models, and GenAI applications. With Amazon SageMaker Catalog (built on Amazon DataZone) and SageMaker Unified Studio, users can securely discover and access approved data and models using semantic search with generative AI–created metadata, or you could just ask Amazon Q Developer with natural language to find your data. For more information on AWS Regions where the next generation of SageMaker is available, see supported regions . To learn more about the next generation of SageMaker, visit the product webpage .",
    "link": "https://aws.amazon.com/about-aws/whats-new/2025/03/amazon-datazone-2-additional-commercial-regions/",
    "summary": "Amazon Datazone은 이제 Asia Pacific (뭄바이) 및 유럽 (파리)의 2 개의 추가 상업 지역에서 제공됩니다. Amazon Datazone은 조직의 데이터 생산자와 소비자 간의 데이터를 카탈로그, 발견, 분석, 공유 및 관리하기위한 완전히 관리되는 데이터 관리 서비스입니다. Amazon Datazone을 사용하면 데이터 제작자는 AWS Glue Data Catalog 및 Amazon Redshift 테이블의 구조화 된 데이터 자산으로 비즈니스 데이터 카탈로그를 채 웁니다. 데이터 소비자는 데이터 카탈로그에서 데이터 자산을 검색하고 구독하고 다른 비즈니스 사용 사례 공동 작업자와 공유합니다. 소비자는 Amazon Datazone Portal에서 직접 액세스하는 Amazon Redshift 또는 Amazon Athena Query 편집기와 같은 도구로 가입 데이터 자산을 분석 할 수 있습니다. 통합 게시 및 소독 워크 플로우는 프로젝트에서 액세스 중심 기능을 제공합니다. Amazon Datazone을 미리보기에서 제공하는 AWS 지역에 대한 자세한 내용은 지원되는 지역을 참조하십시오. 또한 Amazon Datazone은 차세대 Amazon Sagemaker의 거버넌스를 권유하며 Lakehouse, AI 모델 및 Genai 응용 프로그램에서 데이터 및 AI에 대한 발견, 거버넌스 및 협업을 단순화합니다. Amazon Sagemaker 카탈로그 (Amazon Datazone에 구축) 및 Sagemaker Unified Studio를 통해 사용자는 생성 AI -Created Metadata와 함께 시맨틱 검색을 사용하여 승인 된 데이터 및 모델을 안전하게 발견하고 액세스 할 수 있습니다. 차세대 Sagemaker를 이용할 수있는 AWS 지역에 대한 자세한 내용은 지원되는 지역을 참조하십시오. 차세대 Sagemaker에 대한 자세한 내용은 제품 웹 페이지를 방문하십시오."
  },
  {
    "source": "AWS",
    "title": "Scenarios capability now generally available for Amazon Q in QuickSight",
    "date": "2025-03-25",
    "content": "Today, AWS announces the general availability of the scenarios capability of Amazon Q in QuickSight. Amazon Q guides you through data analysis by uncovering hidden trends, making recommendations for your business, and intelligently suggesting next steps for deeper exploration—all in response to natural language interactions. Now anyone can explore past trends, forecast future scenarios, and model solutions without needing specialized skill, analyst support, or manual manipulation of data in spreadsheets. With its intuitive interface and step-by-step guidance, the scenarios capability of Amazon Q in QuickSight helps users perform complex data analysis up to 10x faster than spreadsheets. Whether you're optimizing marketing budgets, streamlining supply chains, or analyzing investments, Amazon Q makes advanced data analysis accessible so you can make data-driven decisions across your organization. This capability is accessible from any Amazon QuickSight dashboard, so you can move seamlessly from visualizing data to asking what-if questions and comparing alternatives. Previous analyses can be easily modified, extended, and reused, helping you quickly adapt to changing business needs. The scenarios capability is available to Amazon Q in QuickSight Pro users in the following AWS Regions: US East (N. Virginia), US West (Oregon), Europe (Frankfurt), and Europe (Ireland). To learn more, visit Amazon Q in QuickSight and explore the documentation .",
    "link": "https://aws.amazon.com/about-aws/whats-new/2025/03/scenarios-capability-generally-available-amazon-q-quicksight",
    "summary": "오늘 AWS는 Quicksight에서 Amazon Q의 시나리오 기능의 일반적인 가용성을 발표합니다. Amazon Q는 숨겨진 트렌드를 밝혀 내고, 비즈니스에 대한 권장 사항을 작성하고, 자연어 상호 작용에 대한 반응으로 모두 더 깊은 탐색을위한 다음 단계를 지능적으로 제안함으로써 데이터 분석을 안내합니다. 이제 누구나 스프레드 시트에서 전문 기술, 분석가 지원 또는 수동 데이터 조작없이 과거의 트렌드를 탐색하고 미래 시나리오 및 모델 솔루션을 예측할 수 있습니다. 직관적 인 인터페이스와 단계별 지침을 통해 Amazon Q의 시나리오 기능은 사용자가 스프레드 시트보다 최대 10 배 빠르게 복잡한 데이터 분석을 수행하는 데 도움이됩니다. 마케팅 예산을 최적화하거나 공급망을 간소화하거나 투자 분석에 관계없이 Amazon Q는 고급 데이터 분석에 액세스 할 수 있도록하여 조직 전체에서 데이터 중심 결정을 내릴 수 있습니다. 이 기능은 모든 Amazon Quicksight 대시 보드에서 액세스 할 수 있으므로 데이터 시각화에서 무엇을 요청하고 대안을 비교하는 것까지 완벽하게 이동할 수 있습니다. 이전 분석을 쉽게 수정, 확장 및 재사용하여 변화하는 비즈니스 요구에 신속하게 적응할 수 있습니다. 시나리오 기능은 US East (N. Virginia), US West (Oregon), Europe (Frankfurt) 및 Europe (아일랜드)의 Quicksight Pro 사용자의 Amazon Q에서 사용할 수 있습니다. 자세한 내용은 Amazon Q를 방문하고 문서를 탐색하십시오."
  },
  {
    "source": "AWS",
    "title": "AWS Elemental MediaConnect adds support for NDI® outputs",
    "date": "2025-03-24",
    "content": "Starting today, AWS Elemental MediaConnect will support NDI® (Network Device Interface) outputs from MediaConnect flows. NDI is a high-quality and low-latency video connectivity technology, widely used in live production applications and supported by more than 500 hardware products and 300 software applications. At launch, the MediaConnect support for NDI allows you to take an incoming transport stream source encoded as AVC or HEVC up to 1080p at 60FPS and output it as NDI High Bandwidth to a VPC. NDI enabled flows can simultaneously output NDI as well as transport stream-based outputs. NDI outputs will use the field-proven SpeedHQ codec and allow you to configure the quality between 100% and 200%. With NDI outputs, the process of connecting on-premises sources such as cameras for use in live cloud production is simpler to deploy, more scalable, and cost-effective using a pay-as-you-go pricing model. NDI support is available in all regions where MediaConnect is currently deployed. For more information and details on pricing, please refer to the NDI documentation and the MediaConnect pricing page .",
    "link": "https://aws.amazon.com/about-aws/whats-new/2025/03/aws-elemental-mediaconnect-support-ndi-outputs",
    "summary": "오늘부터 AWS Elemental MediaConnect는 MediaConnect 흐름에서 NDI® (네트워크 장치 인터페이스) 출력을 지원합니다. NDI는 고품질 및 낮은 지연 비디오 연결 기술로 라이브 생산 응용 프로그램에 널리 사용되며 500 개 이상의 하드웨어 제품 및 300 개의 소프트웨어 응용 프로그램에서 지원합니다. 출시시 NDI에 대한 MediaConnect 지원을 통해 60fps에서 최대 1080p로 AVC 또는 HEVC로 인코딩 된 수신 전송 스트림 소스를 VPC로 NDI 높은 대역폭으로 출력 할 수 있습니다. NDI 활성화 흐름은 전송 스트림 기반 출력뿐만 아니라 NDI를 동시에 출력 할 수 있습니다. NDI 출력은 필드가 제공 한 Speedhq 코덱을 사용하여 100%에서 200% 사이의 품질을 구성 할 수 있습니다. NDI 출력을 사용하면 라이브 클라우드 생산에 사용하기위한 카메라와 같은 온-프레미스 소스를 연결하는 프로세스는 배포가 더 간단하고 확장 가능하며 비용 효율적이며 Pay-as-Go 가격 책정 모델을 사용합니다. NDI 지원은 현재 MediaConnect가 배포 된 모든 지역에서 제공됩니다. 가격에 대한 자세한 내용과 세부 정보는 NDI 문서 및 MediaConnect 가격 페이지를 참조하십시오."
  },
  {
    "source": "AWS",
    "title": "Amazon Keyspaces (for Apache Cassandra) adds Multi-Region support for User Defined Types (UDTs)",
    "date": "2025-03-24",
    "content": "Amazon Keyspaces (for Apache Cassandra) is a scalable, serverless, highly available, and fully managed Apache Cassandra-compatible database service that offers 99.999% availability. Today, Amazon Keyspaces supports User Defined Types (UDTs) in Multi-Region. This enhancement allows you to use UDTs consistently across multiple AWS Regions, enabling global applications to maintain consistent data schemas. With Multi-Region UDT support, you can replicate UDT schemas automatically across Regions, maintain consistent data models across your global infrastructure, and scale your Cassandra-compatible applications across geographic boundaries. This feature builds upon the existing UDT capabilities in Amazon Keyspaces, maintaining the ability to use UDTs in primary keys and create nested data structures that match your real-world data hierarchies. Multi-Region UDT support is now available in all commercial AWS Regions where Amazon Keyspaces is offered . To learn more about implementing Multi-Region UDTs, visit the Amazon Keyspaces documentation .",
    "link": "https://aws.amazon.com/about-aws/whats-new/2025/03/amazon-keyspaces-apache-cassandra-multi-region-support-udts",
    "summary": "Amazon Keyspaces (Apache Cassandra의 경우)는 99.999%의 가용성을 제공하는 확장 가능하고 서버리스이며 고도로 사용 가능하며 완전 관리되는 Apache Cassandra 호환 데이터베이스 서비스입니다. 오늘날 Amazon Keyspaces는 다중 지역의 사용자 정의 유형 (UDT)을 지원합니다. 이 향상을 통해 여러 AWS 지역에서 UDT를 일관되게 사용할 수 있으므로 글로벌 응용 프로그램이 일관된 데이터 스키마를 유지할 수 있습니다. 다중 지역 UDT 지원을 통해 지역 전체에서 UDT 스키마를 자동으로 복제하고 글로벌 인프라에서 일관된 데이터 모델을 유지하며 지리적 경계에서 Cassandra 호환 애플리케이션을 확장 할 수 있습니다. 이 기능은 Amazon Keyspaces의 기존 UDT 기능을 기반으로 기본 키에서 UDT를 사용하고 실제 데이터 계층에 맞는 중첩 데이터 구조를 만들 수있는 기능을 유지합니다. Amazon Keyspaces가 제공되는 모든 상업용 AWS 지역에서 다중 지역 UDT 지원이 제공됩니다. 다중 지역 UDT 구현에 대한 자세한 내용은 Amazon Keyspaces 문서를 방문하십시오."
  },
  {
    "source": "AWS",
    "title": "Announcing Terraform support for AWS Parallel Computing Service",
    "date": "2025-03-24",
    "content": "Today, we are announcing Terraform support for AWS Parallel Computing Service (PCS). Customers can now use Terraform to create and manage their PCS clusters. PCS makes it easier to run and scale high performance computing (HPC) workloads and build scientific and engineering models on AWS using Slurm. PCS already supports managing your HPC environments through the AWS Management Console, AWS Command Line Interface (CLI), AWS CloudFormation, and AWS APIs. With this release, customers can now define and deploy their PCS infrastructure using the HashiCorp Terraform Infrastructure as Code (IaC) tool, and manage clusters through their existing Terraform workflows. This integration is enabled through the Terraform AWS Cloud Control Provider . To get started with using Terraform with PCS, please refer to an example PCS implementation recipe , as well as the Terraform Provider documentation . To learn more about PCS overall, please refer to the service documentation .",
    "link": "https://aws.amazon.com/about-aws/whats-new/2025/03/announcing-terraform-parallel-computing-service/",
    "summary": "오늘 우리는 AWS Parallel Computing Service (PCS)에 대한 Terraform 지원을 발표하고 있습니다. 고객은 이제 TerraForm을 사용하여 PC 클러스터를 만들고 관리 할 수 ​​있습니다. PCS를 사용하면 HPC (High Performance Computing) 워크로드를보다 쉽게 ​​실행하고 확장하고 Slurm을 사용하여 AWS에서 과학 및 엔지니어링 모델을 구축 할 수 있습니다. PCS는 이미 AWS 관리 콘솔, AWS 명령 줄 인터페이스 (CLI), AWS CloudFormation 및 AWS API를 통해 HPC 환경 관리를 지원합니다. 이 릴리스를 통해 고객은 이제 Hashicorp Terraform 인프라를 코드 (IAC) 도구로 사용하여 PCS 인프라를 정의하고 배포하고 기존 TerraForm 워크 플로우를 통해 클러스터를 관리 할 수 ​​있습니다. 이 통합은 Terraform AWS Cloud Control 제공 업체를 통해 활성화됩니다. PCS와의 Terraform을 사용하기 시작하려면 PCS 구현 레시피 예제와 TerraForm 제공 업체 문서를 참조하십시오. 전반적으로 PC에 대한 자세한 내용은 서비스 문서를 참조하십시오."
  },
  {
    "source": "AWS",
    "title": "AWS announces new upgrades to the Amazon Q Business Slack and Teams Integrations",
    "date": "2025-03-24",
    "content": "Today, AWS announced upgrades to the Amazon Q Business Slack and Teams integrations. The upgrades include the ability to create multiple Amazon Q Business integrations within a Slack workspace or Teams organization, free text feedback support, improved response and source formatting, and the support for larger file attachments with user queries. With the support for multiple integrations, customers can now deploy and test up to ten integrations at a time in their Slack workspace or Teams organization and maintain separate integrations for testing, production, and different user groups. With the ability to monitor feedback, customers can review their users’ satisfaction and collect valuable feedback to help improve their applications’ performance and accuracy. With the improvements to response and source formatting and larger file attachments, users can enjoy a more seamless experience when accessing Amazon Q Business in the context of their conversations and when sharing Amazon Q Business’s responses through Slack and Teams messages. These new features are available on the Amazon Q Business Slack and Teams integrations in all regions where Amazon Q Business is available. To learn more, visit the Amazon Q Business product page or review the documentation for detailed setup instructions and feature descriptions.",
    "link": "https://aws.amazon.com/about-aws/whats-new/2025/03/upgrades-amazon-q-business-slack-teams-integrations/",
    "summary": "오늘 AWS는 Amazon Q Business Slack 및 팀 통합으로 업그레이드를 발표했습니다. 업그레이드에는 슬랙 작업 공간 또는 팀 조직 내에서 여러 Amazon Q 비즈니스 통합을 생성하는 기능, 무료 텍스트 피드백 지원, 개선 된 응답 및 소스 형식 및 사용자 쿼리를 사용한 더 큰 파일 첨부 파일에 대한 지원이 포함됩니다. 여러 통합을 지원함으로써 고객은 이제 Slack Workspace 또는 Teams 조직에서 한 번에 최대 10 개의 통합을 배포하고 테스트하고 테스트, 생산 및 다양한 사용자 그룹을위한 별도의 통합을 유지할 수 있습니다. 피드백을 모니터링하는 기능을 통해 고객은 사용자의 만족도를 검토하고 귀중한 피드백을 수집하여 응용 프로그램의 성능과 정확성을 향상시킬 수 있습니다. 응답 및 소스 형식의 개선 및 더 큰 파일 첨부 파일로 인해 사용자는 대화의 맥락에서 Amazon Q 비즈니스에 액세스 할 때 그리고 Slack 및 Teams 메시지를 통해 Amazon Q 비즈니스의 응답을 공유 할 때보다 완벽한 경험을 즐길 수 있습니다. 이러한 새로운 기능은 Amazon Q Business Slack에서 제공되며 Amazon Q 비즈니스를 사용할 수있는 모든 지역의 팀 통합. 자세한 내용은 Amazon Q 비즈니스 제품 페이지를 방문하거나 자세한 설정 지침 및 기능 설명을 위해 문서를 검토하십시오."
  },
  {
    "source": "AWS",
    "title": "Amplify Swift launches Shared Keychain support",
    "date": "2025-03-24",
    "content": "Amplify Swift now supports sharing authentication state across multiple apps by leveraging keychain access groups. This new feature allows developers to manage a single authentication session across all Swift-based applications and extensions within the same access group. Developers can now configure Amplify to store authentication information in a shared keychain, with built-in support for migrating existing sessions. Regardless of platform, users only need to sign in once to access any application or extension within the same access group. This feature is particularly valuable for developers creating families of Swift applications that require consistent authentication states across their ecosystem, including iOS, macOS, watchOS, and tvOS apps. This capability is now available for all Swift applications using Amplify Swift. To learn more about implementing shared authentication state using keychain access groups in your Swift applications, visit the Amplify documentation for keychain sharing in Swift .",
    "link": "https://aws.amazon.com/about-aws/whats-new/2025/03/amplify-swift-shared-keychain-support/",
    "summary": "Amplify Swift는 이제 키 체인 액세스 그룹을 활용하여 여러 앱에서 인증 상태 공유를 지원합니다. 이 새로운 기능을 통해 개발자는 동일한 액세스 그룹 내의 모든 SWIFT 기반 응용 프로그램 및 확장에서 단일 인증 세션을 관리 할 수 ​​있습니다. 개발자는 이제 기존 세션 마이그레이션을위한 내장 지원을 통해 공유 키 체인에 인증 정보를 공유 키 체인에 저장하도록 증폭을 구성 할 수 있습니다. 플랫폼에 관계없이 사용자는 동일한 액세스 그룹 내의 응용 프로그램 또는 확장에 액세스하기 위해 한 번만 로그인하면됩니다. 이 기능은 특히 iOS, MacOS, WatchOS 및 TVOS 앱을 포함하여 생태계 전반에 걸쳐 일관된 인증 상태가 필요한 신속한 응용 프로그램 가족을 만드는 개발자에게 특히 가치가 있습니다. 이 기능은 이제 Amplify Swift를 사용하여 모든 Swift 응용 프로그램에 사용할 수 있습니다. Swift 응용 프로그램에서 Keychain Access Group을 사용하여 공유 인증 상태 구현에 대한 자세한 내용은 Swift에서 Keychain 공유에 대한 Amplify 설명서를 방문하십시오."
  },
  {
    "source": "AWS",
    "title": "AWS DMS Schema Conversion now supports conversions from IBM Db2 for z/OS to Amazon RDS for Db2",
    "date": "2025-03-24",
    "content": "AWS Database Migration Service (DMS) Schema Conversion is a fully managed feature of DMS that automatically assesses and converts database schemas to formats compatible with AWS target database services. Today, we are excited to announce that Schema Conversion now supports conversions from IBM Db2 for z/OS to Amazon Relational Database Service (RDS) for Db2 . Using Schema Conversion, you can automatically convert database objects from your IBM Db2 for z/OS source to an Amazon RDS for Db2 target, including stored procedures, functions, views, and other database structures. This is especially valuable for mainframe migrations as it simplifies complex processes by resolving syntax differences and compatibility issues between environments. Schema Conversion also provides detailed assessment reports to help you plan and execute your migration effectively. To learn more refer to using IBM Db2 z/OS as a source for AWS DMS Schema Conversion and using IBM Db2 for z/OS as a source for AWS DMS . For AWS DMS Schema Conversion regional availability, please refer to the AWS Region Table .",
    "link": "https://aws.amazon.com/about-aws/whats-new/2025/03/aws-dms-schema-conversion-ibm-db2-z-os/",
    "summary": "AWS 데이터베이스 마이그레이션 서비스 (DMS) 스키마 변환은 데이터베이스 스키마를 자동으로 평가하고 변환하여 AWS 대상 데이터베이스 서비스와 호환되는 형식으로 자동 평가하고 변환하는 DMS의 완전히 관리되는 기능입니다. 오늘날 우리는 스키마 변환이 이제 Z/OS 용 IBM DB2에서 DB2의 RDS (Amazon Relational Database Service)로 전환을 지원한다는 것을 발표하게되어 기쁩니다. 스키마 변환을 사용하면 Z/OS 소스의 IBM DB2에서 데이터베이스 객체를 저장 프로 시저, 기능, 뷰 및 기타 데이터베이스 구조를 포함하여 DB2 대상의 Amazon RD로 자동 변환 할 수 있습니다. 이는 환경 간의 구문 차이와 호환성 문제를 해결하여 복잡한 프로세스를 단순화하기 때문에 메인 프레임 마이그레이션에 특히 유용합니다. 스키마 변환은 또한 마이그레이션을 효과적으로 계획하고 실행하는 데 도움이되는 세부 평가 보고서를 제공합니다. 자세한 내용은 IBM DB2 Z/OS를 AWS DMS 스키마 변환 소스로 사용하고 Z/OS 용 IBM DB2를 AWS DMS의 소스로 사용하는 것을 참조하십시오. AWS DMS 스키마 전환 지역 가용성은 AWS 지역 테이블을 참조하십시오."
  },
  {
    "source": "AWS",
    "title": "Amazon Corretto 24 is now generally available",
    "date": "2025-03-24",
    "content": "Corretto 24 is now available for download. Amazon Corretto is a no-cost, multi-platform, production-ready distribution of OpenJDK . Corretto 24 is an OpenJDK 24 Feature Release, which will be supported through October, 2025. OpenJDK 24 introduces enhanced performance with two new experimental features: the Generational Shenandoah garbage collector, designed to improve sustainable throughput, load-spike resilience, and memory utilization, and Compact Object Headers, designed to improve heap usage by shrinking object headers from between 96 and 128 bits down to 64 bits on 64-bit architectures. Additionally, this release includes Ahead-of-Time Class Loading & Linking, designed to improve startup time by making the classes of an application instantly available, Synchronize Virtual Threads without Pinning, designed to eliminate nearly all cases of virtual threads being pinned to platform threads, Quantum-Resistant Module-Lattice-Based Key Encapsulation Mechanism, designed to be secure against future quantum computing attacks. For more information about the features in OpenJDK 24, a detailed description can be found on its Project page . Amazon Corretto is distributed by Amazon under an open source license . Click on the Corretto home page to download Corretto 24. You can also get the updates on your Linux system by configuring a Corretto Apt or Yum repo .",
    "link": "https://aws.amazon.com/about-aws/whats-new/2025/03/amazon-corretto-24-available/",
    "summary": "코레토 24를 다운로드 할 수 있습니다. Amazon Corretto는 OpenJDK의 원치 않는 다중 플랫폼, 생산 준비 분포입니다. Corretto 24는 2025 년 10 월까지 지원 될 OpenJDK 24 기능 릴리스입니다. OpenJDK 24는 두 가지 새로운 실험 기능, 즉 세대의 Shenandoah Garbage Collector (지속 가능한 처리량,로드 스파이크 회복 및 메모리 사용 헤더, Commemy Utilization 및 Commemy Object Headers를 개선하도록 설계된 세대의 Shenandoah Garbage Collector)를 통해 향상된 성능을 소개합니다. 64 비트 아키텍처. 또한,이 릴리스에는 애플리케이션 클래스를 즉시 사용할 수 있도록하여 시작 시간을 개선하도록 설계된 미리 클래스로드 및 링크가 포함되어 있으며, 고정되지 않고 가상 스레드를 동기화하여 플랫폼 스레드에 고정되는 거의 모든 가상 스레드 사례, 양자 저항자-격자 기반 키 캡슐화 메커니즘을 제거하도록 설계된 가상 스레드를 동기화합니다. OpenJDK 24의 기능에 대한 자세한 내용은 프로젝트 페이지에서 자세한 설명을 찾을 수 있습니다. Amazon Corretto는 Amazon에 의해 오픈 소스 라이센스로 배포됩니다. Corretto 홈페이지를 클릭하여 Corretto 24를 다운로드하십시오. Corretto Apt 또는 Yum Repo를 구성하여 Linux 시스템에서 업데이트를 얻을 수도 있습니다."
  }
]